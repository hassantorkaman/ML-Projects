{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kfYsVR0v6NIU",
        "bTgvAvYYkCRP",
        "aLpM2Esi6S2N",
        "q5UjFhxpbgSR",
        "DLzPc4_gLYPj",
        "Fd0k22Chednf",
        "xuoVR8oYrBYB",
        "zGdiEW2T5Lhd",
        "BXHf-I1E6cpU",
        "1nlQMvkC8irp",
        "dY8_ChH1gEa6",
        "lkPSqJ_QoS-7",
        "OrB24-zz9_-F",
        "TSewFlWUx1uF"
      ],
      "mount_file_id": "1YaEqPgfxJ-xC1KQcuZQF7cpn79Ir_pW2",
      "authorship_tag": "ABX9TyPwW8ATzWPgORCEjccPf00g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hassantorkaman/ML-Projects/blob/https%2Fgithub.com%2Fhassantorkaman/Amino%20Acids%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries:"
      ],
      "metadata": {
        "id": "PD8gXR_wjCUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "import datetime\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "JmZ1dXCdjALJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1- Data PreProcessing**"
      ],
      "metadata": {
        "id": "BtMv_YavNS6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Merging all datasets into one**\n",
        "\n",
        "\n",
        "There are 6 datasets:\n",
        "\n",
        "1- 20 labeled from 414\n",
        "\n",
        "2- 20 labeled from 622\n",
        "\n",
        "3- 25 labeled from 587\n",
        "\n",
        "4- 21 labeled from 618\n",
        "\n",
        "5- 17 labeled from 441\n",
        "\n",
        "6- 33 labeled from 559\n",
        "\n",
        "Total: 3241 rows\n",
        "\n",
        "Total Labeled: 136\n",
        "\n",
        "Labeled Percentage: 4.19%\n",
        "\n",
        "**Import Datasets and save them on colab:**\n",
        "\n",
        "I have imported these datasets into colab using this code:\n",
        "\n",
        "      from google.colab import files\n",
        "\n",
        "      uploaded = files.upload()\n",
        "\n",
        "# Load Excel files into DataFrames\n",
        "Then I loaded them into 6 different dataframes and finally merged them into one dataframe using this code:\n",
        "\n",
        "\n",
        "    df1 = pd.read_excel('11.xlsx')\n",
        "    df2 = pd.read_excel('22.xlsx')\n",
        "    df3 = pd.read_excel('33.xlsx')\n",
        "    df4 = pd.read_excel('44.xlsx')\n",
        "    df5 = pd.read_excel('55.xlsx')\n",
        "    df6 = pd.read_excel('66.xlsx')\n",
        "\n",
        "    final_df = pd.concat([df1, df2, df3, df4, df5,df6], ignore_index=True)\n",
        "\n",
        "Next Step I filled the empty labels cells with 0 , saved and downloaded this file as new data set which includes all our 6 dataset with labels\n",
        "\n",
        "    final_df['label'] = final_df['label'].fillna(0)\n",
        "\n",
        "# Save merged data to a new Excel file in Colab\n",
        "Finaly I saved new dataset and download it to my comouter\n",
        "\n",
        "    final_df.to_excel('/content/final_df.xlsx', index=False)\n",
        "    files.download('/content/final_df.xlsx')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0jh3G-lXf_Ju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1-1 Mounting Dataset Into Program**"
      ],
      "metadata": {
        "id": "B99w26DpfBZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "final_df = pd.read_csv('/content/drive/MyDrive/reza_datasets/final_csv.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeSCYmKve_d2",
        "outputId": "ad258a09-4160-4804-e392-7b23952208ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1-2 Visualization of the Raw Dataset**:"
      ],
      "metadata": {
        "id": "CAjCU6BGlv-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1-2-1 Take a look at the dataset:**"
      ],
      "metadata": {
        "id": "rMnQMuPgF_2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tRPhhQFRluDh",
        "outputId": "1d44eba2-c26d-4cd3-969d-7b6e35737f4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 Chain Residue Name  AT   DPX         ASA  Average Bfactor  \\\n",
              "0           0     E          VAL   7  0.00   93.199997           27.312   \n",
              "1           1     E          SER   6  0.00   45.600002           31.505   \n",
              "2           2     E          ALA   5  2.69    4.800000           28.328   \n",
              "3           3     E          TYR  12  1.47  118.199997           31.080   \n",
              "4           4     E          LEU   8  8.08   33.299999           25.937   \n",
              "\n",
              "          CX   RMSF  kdHydrophobicity  label  \n",
              "0   6.890000  0.819               4.2      0  \n",
              "1   5.820000  0.525              -0.8      0  \n",
              "2   3.250000  0.763               1.8      0  \n",
              "3  14.290001  0.408              -1.3      0  \n",
              "4   2.710000  0.426               3.8      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cce168ec-a8b7-415a-a21c-7ab29075eaba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Chain</th>\n",
              "      <th>Residue Name</th>\n",
              "      <th>AT</th>\n",
              "      <th>DPX</th>\n",
              "      <th>ASA</th>\n",
              "      <th>Average Bfactor</th>\n",
              "      <th>CX</th>\n",
              "      <th>RMSF</th>\n",
              "      <th>kdHydrophobicity</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>E</td>\n",
              "      <td>VAL</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>93.199997</td>\n",
              "      <td>27.312</td>\n",
              "      <td>6.890000</td>\n",
              "      <td>0.819</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>E</td>\n",
              "      <td>SER</td>\n",
              "      <td>6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>45.600002</td>\n",
              "      <td>31.505</td>\n",
              "      <td>5.820000</td>\n",
              "      <td>0.525</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>E</td>\n",
              "      <td>ALA</td>\n",
              "      <td>5</td>\n",
              "      <td>2.69</td>\n",
              "      <td>4.800000</td>\n",
              "      <td>28.328</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0.763</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>E</td>\n",
              "      <td>TYR</td>\n",
              "      <td>12</td>\n",
              "      <td>1.47</td>\n",
              "      <td>118.199997</td>\n",
              "      <td>31.080</td>\n",
              "      <td>14.290001</td>\n",
              "      <td>0.408</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>E</td>\n",
              "      <td>LEU</td>\n",
              "      <td>8</td>\n",
              "      <td>8.08</td>\n",
              "      <td>33.299999</td>\n",
              "      <td>25.937</td>\n",
              "      <td>2.710000</td>\n",
              "      <td>0.426</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cce168ec-a8b7-415a-a21c-7ab29075eaba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cce168ec-a8b7-415a-a21c-7ab29075eaba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cce168ec-a8b7-415a-a21c-7ab29075eaba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6c36d0d7-d9f7-44fd-8a74-17c3673098f3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c36d0d7-d9f7-44fd-8a74-17c3673098f3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6c36d0d7-d9f7-44fd-8a74-17c3673098f3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1-2-2 :In This visualization we can see the corelation between all attributes and the Label :**"
      ],
      "metadata": {
        "id": "xde4xY65epFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attribute_columns = ['AT', 'DPX', 'ASA', 'Average Bfactor', 'CX', 'RMSF', 'kdHydrophobicity', 'label']\n",
        "\n",
        "correlation_matrix = final_df[attribute_columns].corr()\n",
        "\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap of Attributes')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "J5Ouj5eMmDS4",
        "outputId": "823562c0-55af-4d52-8503-d4478d9f661f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x= final_df.iloc[: ,3:10]\n",
        "y= final_df.iloc[:, -1]"
      ],
      "metadata": {
        "id": "B06dYMwQq-dF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=16, stratify=y)\n"
      ],
      "metadata": {
        "id": "YTzrLSEswUVT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1-3 Normalisation the values**"
      ],
      "metadata": {
        "id": "IGVbV1O_s7Cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc= MinMaxScaler(feature_range = (0,1))\n",
        "X_train_norm= sc.fit_transform(X_train)\n",
        "X_test_norm= sc.fit_transform(X_test)\n"
      ],
      "metadata": {
        "id": "xaxinPkCsmoA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1-4 Imbalance Augmantation Techniques**"
      ],
      "metadata": {
        "id": "bmymvsnlyBjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1-4-1 - SMOTE**"
      ],
      "metadata": {
        "id": "_uUgRZrVyeri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state = 16)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train_norm,y_train)\n"
      ],
      "metadata": {
        "id": "BcdhNIV5x9lS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x))\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(y))\n",
        "print(len(y_train))\n",
        "print(len(X_train_norm))\n",
        "print(len(X_test))\n",
        "print(len(y_test))\n",
        "print(len(X_train_smote))\n",
        "print(len(y_train_smote))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GywJXMbQbxMt",
        "outputId": "ef5d2455-9eec-45c4-84f8-99e9e6bc0ffc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3241\n",
            "2592\n",
            "649\n",
            "3241\n",
            "2592\n",
            "2592\n",
            "649\n",
            "649\n",
            "4966\n",
            "4966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2- Classic Machine Learning Models **"
      ],
      "metadata": {
        "id": "fBs78B805--_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-1 Random Forest**\n",
        "  \n",
        "  **2-1-1 Finding Best hyperparametrs for Random forest classifier**\n",
        "\n",
        "\n",
        "I used Gridsearch to find best hyper parameters for random forest model, becuase this part is time consming, I made it comment and will use these parameters directly in the model in next steps\n",
        "\n",
        "In following you can see the code which has been used for gaining best hyper parameters:\n",
        "\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    rf_classifier = RandomForestClassifier(random_state=16)\n",
        "    # Define the parameter grid to search\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 150],        # Number of trees in the forest\n",
        "        'max_depth': [None, 10, 20, 30],       # Maximum depth of the trees\n",
        "        'min_samples_split': [2, 5, 10],       # Minimum number of samples required to split an internal node\n",
        "        'min_samples_leaf': [1, 2, 4]          # Minimum number of samples required to be at a leaf node\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    # Create GridSearchCV for finding best parameters\n",
        "    grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5)\n",
        "    grid_search.fit(X_train_norm, y_train)\n",
        "\n",
        "    best_params = grid_search.best_params_\n",
        "    best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "    print(\"Best Hyperparameters:\", best_params)"
      ],
      "metadata": {
        "id": "37lma2c66II3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-1-1 With Orginal Data**"
      ],
      "metadata": {
        "id": "kfYsVR0v6NIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trainin Random Forest Classifier**\n",
        "\n",
        "\n",
        "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1,'min_samples_split': 5, 'n_estimators': 150}"
      ],
      "metadata": {
        "id": "a4hMwezb-1QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "rf_classifier = RandomForestClassifier(\n",
        "    max_depth=None,\n",
        "    min_samples_leaf=1,\n",
        "    min_samples_split=5,\n",
        "    n_estimators=150,\n",
        "    random_state=16\n",
        ")\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "rf_classifier_prediction = rf_classifier.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, rf_classifier_prediction)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(y_test, rf_classifier_prediction)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y_test, rf_classifier_prediction)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "f1 = f1_score(y_test, rf_classifier_prediction)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, rf_classifier_prediction)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db5bfc18-7579-414e-947c-680c3c095e1e",
        "id": "gNQwqNcD_AX0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9583975346687211\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n",
            "Confusion Matrix:\n",
            "[[622   0]\n",
            " [ 27   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result Analyzing for random forest with original dataset:**\n",
        "\n",
        "Precision: Precision is 0, which indicates that the model did not correctly predict any positive instances (class 1).\n",
        "\n",
        "Recall: Recall is also 0, indicating that the model did not capture any of the actual positive instances.\n",
        "\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "True Positives (TP): 0\n",
        "True Negatives (TN): 622\n",
        "False Positives (FP): 0\n",
        "False Negatives (FN): 27\n",
        "Given the high accuracy and a confusion matrix with no false positives and true negatives, it shows that the dataset is heavily imbalanced. The model predicted the majority class (class 0) for all samples.\n"
      ],
      "metadata": {
        "id": "1xc915LoD5Yw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-1-2 With Normalized Orginal Data**\n"
      ],
      "metadata": {
        "id": "bTgvAvYYkCRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classifier = RandomForestClassifier(\n",
        "    max_depth=None,\n",
        "    min_samples_leaf=1,\n",
        "    min_samples_split=5,\n",
        "    n_estimators=150,\n",
        "    random_state=16\n",
        ")\n",
        "rf_classifier.fit(X_train_norm, y_train)\n",
        "rf_classifier_prediction = rf_classifier.predict(X_test_norm)\n",
        "\n",
        "accuracy = accuracy_score(y_test, rf_classifier_prediction)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(y_test, rf_classifier_prediction)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y_test, rf_classifier_prediction)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "f1 = f1_score(y_test, rf_classifier_prediction)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, rf_classifier_prediction)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWMdcEY3kOHw",
        "outputId": "75128f93-1f3e-4eba-bb4b-902560fe4b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9583975346687211\n",
            "Precision: 0.0\n",
            "Recall: 0.0\n",
            "F1 Score: 0.0\n",
            "Confusion Matrix:\n",
            "[[622   0]\n",
            " [ 27   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyzing Result:**\n",
        "\n",
        "Rubbish"
      ],
      "metadata": {
        "id": "FgLZKtLRkb0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-1-3 With SMOTE data**"
      ],
      "metadata": {
        "id": "aLpM2Esi6S2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_classifier = RandomForestClassifier(\n",
        "    max_depth=None,\n",
        "    min_samples_leaf=1,\n",
        "    min_samples_split=5,\n",
        "    n_estimators=150,\n",
        "    random_state=16\n",
        ")\n",
        "rf_classifier.fit(X_train_smote, y_train_smote)\n",
        "rf_classifier_prediction_smote = rf_classifier.predict(X_test_norm)\n",
        "\n",
        "accuracy = accuracy_score(y_test, rf_classifier_prediction_smote)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(y_test, rf_classifier_prediction_smote)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y_test, rf_classifier_prediction_smote)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "f1 = f1_score(y_test, rf_classifier_prediction_smote)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, rf_classifier_prediction_smote)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, rf_classifier_prediction_smote)\n",
        "\n",
        "TP = conf_matrix[1, 1]\n",
        "FP = conf_matrix[0, 1]\n",
        "TN = conf_matrix[0, 0]\n",
        "FN = conf_matrix[1, 0]\n",
        "\n",
        "print(\"True Positives (TP):\", TP)\n",
        "print(\"False Positives (FP):\", FP)\n",
        "print(\"True Negatives (TN):\", TN)\n",
        "print(\"False Negatives (FN):\", FN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVSnV2CaF5H_",
        "outputId": "8269f9f8-90a8-4142-f063-94e63f1826fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8551617873651772\n",
            "Precision: 0.05333333333333334\n",
            "Recall: 0.14814814814814814\n",
            "F1 Score: 0.0784313725490196\n",
            "Confusion Matrix:\n",
            "[[551  71]\n",
            " [ 23   4]]\n",
            "True Positives (TP): 4\n",
            "False Positives (FP): 71\n",
            "True Negatives (TN): 551\n",
            "False Negatives (FN): 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyzing the result : Still same shit**\n",
        "\n",
        "Precision: Precision is very low at 5%. This means that out of all instances predicted as positive, only 5% are actually positive. This low precision suggests a high number of false positives.\n",
        "\n",
        "Recall: Recall is 14.81%. This metric indicates that the model identified 11.11% of all the actual positive instances. In other words, the model missed 88.89% of the positive instances, which is quite high.\n",
        "\n",
        "F1 Score: The F1 score is a harmonic mean of precision and recall. it's low at 7.83%. This indicates that the model's ability to balance precision and recall is poor.\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "True Positives (TP): 4 instances were correctly classified as positive.\n",
        "False Positives (FP): 71 instances were incorrectly classified as positive.\n",
        "True Negatives (TN): 551 instances were correctly classified as negative.\n",
        "False Negatives (FN): 23 instances were incorrectly classified as negative.\n"
      ],
      "metadata": {
        "id": "kXxmc8lLJk3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-1-4 -Random Undersampling**  \n",
        "\n"
      ],
      "metadata": {
        "id": "q5UjFhxpbgSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Apply Random Undersampling to the training data\n",
        "\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_train_undersampled, y_train_undersampled = undersampler.fit_resample(X_train_norm, y_train)\n",
        "\n",
        "\n",
        "rf_classifier = RandomForestClassifier(max_depth=None,\n",
        "                                       min_samples_leaf=1,\n",
        "                                       min_samples_split=5,\n",
        "                                       n_estimators=150,\n",
        "                                       random_state=16\n",
        "                                       )\n",
        "rf_classifier.fit(X_train_undersampled, y_train_undersampled)\n",
        "\n",
        "\n",
        "predictions = rf_classifier.predict(X_test_norm)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "TP = conf_matrix[1, 1]\n",
        "FP = conf_matrix[0, 1]\n",
        "TN = conf_matrix[0, 0]\n",
        "FN = conf_matrix[1, 0]\n",
        "\n",
        "print(\"True Positives (TP):\", TP)\n",
        "print(\"False Positives (FP):\", FP)\n",
        "print(\"True Negatives (TN):\", TN)\n",
        "print(\"False Negatives (FN):\", FN)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO0TD3iyJ2bc",
        "outputId": "76d06dc4-dd8b-45df-a7c3-9e130ce23bb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.576271186440678\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.57      0.72       622\n",
            "           1       0.08      0.81      0.14        27\n",
            "\n",
            "    accuracy                           0.58       649\n",
            "   macro avg       0.53      0.69      0.43       649\n",
            "weighted avg       0.95      0.58      0.69       649\n",
            "\n",
            "True Positives (TP): 22\n",
            "False Positives (FP): 270\n",
            "True Negatives (TN): 352\n",
            "False Negatives (FN): 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyzing Result:**\n",
        "This Mother fucker doesnt want to show something to us\n",
        "with Random Undersampling we didn't get good result again as you can see, becuase the false positive increased exteremly"
      ],
      "metadata": {
        "id": "OjaaXm-8oOT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-1-5 SMOTE with raw data without normalization**"
      ],
      "metadata": {
        "id": "DLzPc4_gLYPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote2, y_train_smote2 = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "rf_classifier = RandomForestClassifier(max_depth=None,\n",
        "                                       min_samples_leaf=1,\n",
        "                                       min_samples_split=5,\n",
        "                                       n_estimators=150,\n",
        "                                       random_state=16\n",
        "                                       )\n",
        "\n",
        "rf_classifier.fit(X_train_smote2,y_train_smote2)\n",
        "predictions = rf_classifier.predict(X_test)\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "TP = conf_matrix[1, 1]\n",
        "FP = conf_matrix[0, 1]\n",
        "TN = conf_matrix[0, 0]\n",
        "FN = conf_matrix[1, 0]\n",
        "\n",
        "print(\"True Positives (TP):\", TP)\n",
        "print(\"False Positives (FP):\", FP)\n",
        "print(\"True Negatives (TN):\", TN)\n",
        "print(\"False Negatives (FN):\", FN)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awCQvVJ-Tls5",
        "outputId": "eeaedff1-f794-4100-bdf6-ac7449a157eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.9152542372881356\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.96       622\n",
            "           1       0.03      0.04      0.04        27\n",
            "\n",
            "    accuracy                           0.92       649\n",
            "   macro avg       0.50      0.50      0.50       649\n",
            "weighted avg       0.92      0.92      0.92       649\n",
            "\n",
            "True Positives (TP): 1\n",
            "False Positives (FP): 29\n",
            "True Negatives (TN): 593\n",
            "False Negatives (FN): 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anylizing:**\n",
        "\n",
        "Same shit as before"
      ],
      "metadata": {
        "id": "iHAZrbTJqDSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict label for new values:"
      ],
      "metadata": {
        "id": "Fd0k22Chednf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_label(AT, DPX, ASA, Average_Bfactor, CX, RMSF, kdHydrophobicity):\n",
        "    # Create a DataFrame with user input\n",
        "    user_input = pd.DataFrame({\n",
        "        'AT': [AT],\n",
        "        'DPX': [DPX],\n",
        "        'ASA': [ASA],\n",
        "        'Average Bfactor': [Average_Bfactor],\n",
        "        'CX': [CX],\n",
        "        'RMSF': [RMSF],\n",
        "        'kdHydrophobicity': [kdHydrophobicity]\n",
        "    })\n",
        "\n",
        "    # Use the trained model for prediction\n",
        "    prediction = best_rf_classifier.predict(user_input)\n",
        "\n",
        "    # Output the prediction\n",
        "    if prediction[0] == 1:\n",
        "        print(\"The model predicts a positive label (1).\")\n",
        "    else:\n",
        "        print(\"The model predicts a negative label (0).\")\n",
        "\n",
        "# Example usage\n",
        "AT = float(input(\"Enter AT value: \"))\n",
        "DPX = float(input(\"Enter DPX value: \"))\n",
        "ASA = float(input(\"Enter ASA value: \"))\n",
        "Average_Bfactor = float(input(\"Enter Average Bfactor value: \"))\n",
        "CX = float(input(\"Enter CX value: \"))\n",
        "RMSF = float(input(\"Enter RMSF value: \"))\n",
        "kdHydrophobicity = float(input(\"Enter kdHydrophobicity value: \"))\n",
        "\n",
        "# Predict label based on user input\n",
        "predict_label(AT, DPX, ASA, Average_Bfactor, CX, RMSF, kdHydrophobicity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_l9xQIiekd2",
        "outputId": "8813e3b0-333b-4e3c-b2aa-2919953cdb2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter AT value: 4\n",
            "Enter DPX value: 15\n",
            "Enter ASA value: 432\n",
            "Enter Average Bfactor value: 42\n",
            "Enter CX value: 4\n",
            "Enter RMSF value: 0.3\n",
            "Enter kdHydrophobicity value: 4\n",
            "The model predicts a negative label (0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-2- SVM **"
      ],
      "metadata": {
        "id": "LqZ192oNqmWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-2-1 SVM with SMOTE**"
      ],
      "metadata": {
        "id": "xuoVR8oYrBYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_classifier = SVC(class_weight='balanced', random_state=16)\n",
        "svm_classifier.fit(X_train_smote, y_train_smote)\n",
        "svm_prediction = svm_classifier.predict(X_test_norm )\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, svm_prediction)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(y_test, svm_prediction)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y_test, svm_prediction)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "f1 = f1_score(y_test, svm_prediction)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, svm_prediction)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, svm_prediction)\n",
        "\n",
        "TP = conf_matrix[1, 1]\n",
        "FP = conf_matrix[0, 1]\n",
        "TN = conf_matrix[0, 0]\n",
        "FN = conf_matrix[1, 0]\n",
        "\n",
        "print(\"True Positives (TP):\", TP)\n",
        "print(\"False Positives (FP):\", FP)\n",
        "print(\"True Negatives (TN):\", TN)\n",
        "print(\"False Negatives (FN):\", FN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qzcqhL5ql0F",
        "outputId": "5fce791c-6f7d-442a-e1d7-04c047101e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6563944530046225\n",
            "Precision: 0.046296296296296294\n",
            "Recall: 0.37037037037037035\n",
            "F1 Score: 0.0823045267489712\n",
            "Confusion Matrix:\n",
            "[[416 206]\n",
            " [ 17  10]]\n",
            "True Positives (TP): 10\n",
            "False Positives (FP): 206\n",
            "True Negatives (TN): 416\n",
            "False Negatives (FN): 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysing the result:**\n",
        "Better than random forest but still is not good enough"
      ],
      "metadata": {
        "id": "h-04EDae46c2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-2-2 SVM with ADASYN**"
      ],
      "metadata": {
        "id": "zGdiEW2T5Lhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "\n",
        "adasyn = ADASYN(random_state=16)\n",
        "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)\n",
        "\n",
        "svm_classifier_adasyn = SVC(class_weight='balanced', random_state=16)\n",
        "svm_classifier_adasyn.fit(X_train_adasyn, y_train_adasyn)\n",
        "svm_prediction_adasyn = svm_classifier_adasyn.predict(X_test )\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, svm_prediction_adasyn)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(y_test, svm_prediction_adasyn)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y_test, svm_prediction_adasyn)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "f1 = f1_score(y_test, svm_prediction_adasyn)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, svm_prediction_adasyn)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, svm_prediction_adasyn)\n",
        "\n",
        "TP = conf_matrix[1, 1]\n",
        "FP = conf_matrix[0, 1]\n",
        "TN = conf_matrix[0, 0]\n",
        "FN = conf_matrix[1, 0]\n",
        "\n",
        "print(\"True Positives (TP):\", TP)\n",
        "print(\"False Positives (FP):\", FP)\n",
        "print(\"True Negatives (TN):\", TN)\n",
        "print(\"False Negatives (FN):\", FN)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaCRlBqf5VqU",
        "outputId": "07ed2ba3-e8bc-4b8e-b5f4-096944d3ee5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5115562403697997\n",
            "Precision: 0.06325301204819277\n",
            "Recall: 0.7777777777777778\n",
            "F1 Score: 0.11699164345403898\n",
            "Confusion Matrix:\n",
            "[[311 311]\n",
            " [  6  21]]\n",
            "True Positives (TP): 21\n",
            "False Positives (FP): 311\n",
            "True Negatives (TN): 311\n",
            "False Negatives (FN): 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Result:**\n",
        "terrible result in false positives"
      ],
      "metadata": {
        "id": "EqOnAVSS6VKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-2-3 SVM ADASYN with normalization**"
      ],
      "metadata": {
        "id": "BXHf-I1E6cpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc_adasyn= MinMaxScaler(feature_range = (0,1))\n",
        "X_train_norm_adasyn= sc.fit_transform(X_train_adasyn)\n",
        "X_test_norm_adasyn= sc.fit_transform(X_test)\n",
        "\n",
        "svm_classifier_adasyn_norm = SVC(class_weight='balanced', random_state=16)\n",
        "svm_classifier_adasyn_norm.fit(X_train_norm_adasyn, y_train_adasyn)\n",
        "svm_prediction_adasyn_norm = svm_classifier_adasyn_norm.predict(X_test_norm_adasyn )\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, svm_prediction_adasyn_norm)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(y_test, svm_prediction_adasyn_norm)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y_test, svm_prediction_adasyn_norm)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "f1 = f1_score(y_test, svm_prediction_adasyn_norm)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, svm_prediction_adasyn_norm)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, svm_prediction_adasyn_norm)\n",
        "\n",
        "TP = conf_matrix[1, 1]\n",
        "FP = conf_matrix[0, 1]\n",
        "TN = conf_matrix[0, 0]\n",
        "FN = conf_matrix[1, 0]\n",
        "\n",
        "print(\"True Positives (TP):\", TP)\n",
        "print(\"False Positives (FP):\", FP)\n",
        "print(\"True Negatives (TN):\", TN)\n",
        "print(\"False Negatives (FN):\", FN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rilQlqd16nwS",
        "outputId": "c30d9e4c-4dd9-4193-de21-81afb30dfa59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6640986132511556\n",
            "Precision: 0.05581395348837209\n",
            "Recall: 0.4444444444444444\n",
            "F1 Score: 0.09917355371900825\n",
            "Confusion Matrix:\n",
            "[[419 203]\n",
            " [ 15  12]]\n",
            "True Positives (TP): 12\n",
            "False Positives (FP): 203\n",
            "True Negatives (TN): 419\n",
            "False Negatives (FN): 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyzin Result:** better than ADASYN with raw original data but still worthless"
      ],
      "metadata": {
        "id": "BeRPN0EV8FTN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-2-4 SVM - combining SMOTE with undersampling - ENN edited Nearest neighbor**"
      ],
      "metadata": {
        "id": "1nlQMvkC8irp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.combine import SMOTEENN\n",
        "\n",
        "smote_enn = SMOTEENN(random_state=16)\n",
        "X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train_norm, y_train)\n",
        "\n",
        "svm_smoteen = SVC(class_weight='balanced', random_state=16)\n",
        "svm_smoteen.fit(X_train_resampled, y_train_resampled)\n",
        "svm_smoteen_prediction = svm_smoteen.predict(X_test_norm)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, svm_smoteen_prediction)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(y_test, svm_smoteen_prediction)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y_test, svm_smoteen_prediction)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "f1 = f1_score(y_test, svm_smoteen_prediction)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, svm_smoteen_prediction)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, svm_smoteen_prediction)\n",
        "\n",
        "TP = conf_matrix[1, 1]\n",
        "FP = conf_matrix[0, 1]\n",
        "TN = conf_matrix[0, 0]\n",
        "FN = conf_matrix[1, 0]\n",
        "\n",
        "print(\"True Positives (TP):\", TP)\n",
        "print(\"False Positives (FP):\", FP)\n",
        "print(\"True Negatives (TN):\", TN)\n",
        "print(\"False Negatives (FN):\", FN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3d8Mp3Z8Sfc",
        "outputId": "694fe254-b273-408f-f77d-ea42ad3a1ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6425269645608629\n",
            "Precision: 0.05627705627705628\n",
            "Recall: 0.48148148148148145\n",
            "F1 Score: 0.10077519379844961\n",
            "Confusion Matrix:\n",
            "[[404 218]\n",
            " [ 14  13]]\n",
            "True Positives (TP): 13\n",
            "False Positives (FP): 218\n",
            "True Negatives (TN): 404\n",
            "False Negatives (FN): 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2-3- Cost Sensitive ADAboost (ADABoosttClassifier)**"
      ],
      "metadata": {
        "id": "dY8_ChH1gEa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "\n",
        "adaboost_classifier = AdaBoostClassifier(n_estimators=50, random_state=42, algorithm='SAMME.R', learning_rate=1.0)\n",
        "\n",
        "adaboost_classifier.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "predictions = adaboost_classifier.predict(X_test_norm)\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "precision = precision_score(y_test, predictions)\n",
        "print(\"Precision:\", precision)\n",
        "\n",
        "recall = recall_score(y_test, predictions)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "f1 = f1_score(y_test, predictions)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "TP = conf_matrix[1, 1]\n",
        "FP = conf_matrix[0, 1]\n",
        "TN = conf_matrix[0, 0]\n",
        "FN = conf_matrix[1, 0]\n",
        "\n",
        "print(\"True Positives (TP):\", TP)\n",
        "print(\"False Positives (FP):\", FP)\n",
        "print(\"True Negatives (TN):\", TN)\n",
        "print(\"False Negatives (FN):\", FN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmDH7btWgQvL",
        "outputId": "576bca22-d191-4cd4-d02e-d75897c987b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.65      0.78       622\n",
            "           1       0.06      0.56      0.12        27\n",
            "\n",
            "    accuracy                           0.65       649\n",
            "   macro avg       0.52      0.60      0.45       649\n",
            "weighted avg       0.93      0.65      0.75       649\n",
            "\n",
            "Accuracy: 0.6471494607087828\n",
            "Precision: 0.06465517241379311\n",
            "Recall: 0.5555555555555556\n",
            "F1 Score: 0.11583011583011583\n",
            "Confusion Matrix:\n",
            "[[405 217]\n",
            " [ 12  15]]\n",
            "True Positives (TP): 15\n",
            "False Positives (FP): 217\n",
            "True Negatives (TN): 405\n",
            "False Negatives (FN): 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3- Deep Neural Networks Approaches**"
      ],
      "metadata": {
        "id": "3iP6dZkZoMNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3-1 ANN**"
      ],
      "metadata": {
        "id": "lkPSqJ_QoS-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from seaborn.axisgrid import annotations\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=6,activation = 'relu'))\n",
        "#ann.add(Dropout(rate=0.3))\n",
        "ann.add(tf.keras.layers.Dense(units=50,activation = 'relu'))\n",
        "#ann.add(Dropout(rate=0.3))\n",
        "ann.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
        "#ann.add(Dropout(rate=0.3))\n",
        "ann.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
        "#ann.add(Dropout(rate=0.3))\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "#ann.add(Dropout(rate=0.3))\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "ann.fit(X_train_smote,y_train_smote, batch_size=12,epochs=500, validation_data=(X_test_norm, y_test))\n",
        "\n",
        "prediction = ann.predict(X_test_norm)\n",
        "prediction_f = [1 if p > 0.5 else 0 for p in prediction]\n",
        "\n",
        "\n",
        "\n",
        "#prediction_f_array = prediction_f.to_numpy()\n",
        "print(classification_report(y_test, prediction_f))\n",
        "#concatenated_array = np.concatenate((prediction_f_array, y_test))\n",
        "#print(concatenated_array)\n",
        "\n",
        "#cm= confusion_matrix(y_test, prediction_f)\n",
        "#print(cm)\n",
        "accuracy_score(y_test, prediction_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzZYSNKnB0Q6",
        "outputId": "37092f92-1f75-4d34-bb82-4b4055695c63"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "414/414 [==============================] - 4s 6ms/step - loss: 0.6332 - accuracy: 0.6283 - val_loss: 0.4903 - val_accuracy: 0.6441\n",
            "Epoch 2/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.5502 - accuracy: 0.7054 - val_loss: 0.4655 - val_accuracy: 0.6287\n",
            "Epoch 3/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.5341 - accuracy: 0.7135 - val_loss: 0.5232 - val_accuracy: 0.5701\n",
            "Epoch 4/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.5256 - accuracy: 0.7201 - val_loss: 0.5071 - val_accuracy: 0.5732\n",
            "Epoch 5/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.5175 - accuracy: 0.7265 - val_loss: 0.6088 - val_accuracy: 0.5331\n",
            "Epoch 6/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.5014 - accuracy: 0.7376 - val_loss: 0.5943 - val_accuracy: 0.6055\n",
            "Epoch 7/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.4924 - accuracy: 0.7521 - val_loss: 0.6826 - val_accuracy: 0.5547\n",
            "Epoch 8/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.4796 - accuracy: 0.7567 - val_loss: 0.5070 - val_accuracy: 0.6610\n",
            "Epoch 9/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.7654 - val_loss: 0.7006 - val_accuracy: 0.5963\n",
            "Epoch 10/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.4525 - accuracy: 0.7729 - val_loss: 0.4935 - val_accuracy: 0.7134\n",
            "Epoch 11/500\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.4469 - accuracy: 0.7833 - val_loss: 0.4768 - val_accuracy: 0.7288\n",
            "Epoch 12/500\n",
            "414/414 [==============================] - 3s 8ms/step - loss: 0.4340 - accuracy: 0.7880 - val_loss: 0.7103 - val_accuracy: 0.6086\n",
            "Epoch 13/500\n",
            "414/414 [==============================] - 3s 8ms/step - loss: 0.4234 - accuracy: 0.7992 - val_loss: 0.4601 - val_accuracy: 0.7565\n",
            "Epoch 14/500\n",
            "414/414 [==============================] - 4s 10ms/step - loss: 0.4197 - accuracy: 0.7914 - val_loss: 0.7620 - val_accuracy: 0.6148\n",
            "Epoch 15/500\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.4084 - accuracy: 0.8087 - val_loss: 0.5690 - val_accuracy: 0.7180\n",
            "Epoch 16/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4043 - accuracy: 0.8083 - val_loss: 0.4383 - val_accuracy: 0.8105\n",
            "Epoch 17/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.3973 - accuracy: 0.8109 - val_loss: 0.5692 - val_accuracy: 0.7350\n",
            "Epoch 18/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.3897 - accuracy: 0.8166 - val_loss: 0.5094 - val_accuracy: 0.7627\n",
            "Epoch 19/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3832 - accuracy: 0.8198 - val_loss: 0.7204 - val_accuracy: 0.6533\n",
            "Epoch 20/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.3828 - accuracy: 0.8208 - val_loss: 0.5876 - val_accuracy: 0.7381\n",
            "Epoch 21/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.3772 - accuracy: 0.8268 - val_loss: 0.5147 - val_accuracy: 0.7858\n",
            "Epoch 22/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3702 - accuracy: 0.8242 - val_loss: 0.6953 - val_accuracy: 0.6965\n",
            "Epoch 23/500\n",
            "414/414 [==============================] - 4s 11ms/step - loss: 0.3643 - accuracy: 0.8325 - val_loss: 0.6657 - val_accuracy: 0.6965\n",
            "Epoch 24/500\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.3638 - accuracy: 0.8317 - val_loss: 0.6419 - val_accuracy: 0.7026\n",
            "Epoch 25/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3629 - accuracy: 0.8266 - val_loss: 0.6261 - val_accuracy: 0.7334\n",
            "Epoch 26/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.3503 - accuracy: 0.8363 - val_loss: 0.5922 - val_accuracy: 0.7488\n",
            "Epoch 27/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.3443 - accuracy: 0.8427 - val_loss: 0.6444 - val_accuracy: 0.7550\n",
            "Epoch 28/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.3405 - accuracy: 0.8439 - val_loss: 0.5989 - val_accuracy: 0.7627\n",
            "Epoch 29/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.3410 - accuracy: 0.8407 - val_loss: 0.7581 - val_accuracy: 0.6764\n",
            "Epoch 30/500\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.3338 - accuracy: 0.8508 - val_loss: 0.6840 - val_accuracy: 0.7196\n",
            "Epoch 31/500\n",
            "414/414 [==============================] - 3s 8ms/step - loss: 0.3317 - accuracy: 0.8492 - val_loss: 0.6236 - val_accuracy: 0.7858\n",
            "Epoch 32/500\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.3279 - accuracy: 0.8506 - val_loss: 0.7272 - val_accuracy: 0.7365\n",
            "Epoch 33/500\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.3219 - accuracy: 0.8522 - val_loss: 0.8237 - val_accuracy: 0.6764\n",
            "Epoch 34/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3226 - accuracy: 0.8500 - val_loss: 0.7994 - val_accuracy: 0.7119\n",
            "Epoch 35/500\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.3205 - accuracy: 0.8542 - val_loss: 0.6250 - val_accuracy: 0.7951\n",
            "Epoch 36/500\n",
            "414/414 [==============================] - 4s 9ms/step - loss: 0.3114 - accuracy: 0.8600 - val_loss: 0.6780 - val_accuracy: 0.7550\n",
            "Epoch 37/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3089 - accuracy: 0.8621 - val_loss: 0.6866 - val_accuracy: 0.7596\n",
            "Epoch 38/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2974 - accuracy: 0.8675 - val_loss: 0.6468 - val_accuracy: 0.7874\n",
            "Epoch 39/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3008 - accuracy: 0.8679 - val_loss: 0.6450 - val_accuracy: 0.8213\n",
            "Epoch 40/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2995 - accuracy: 0.8645 - val_loss: 0.6837 - val_accuracy: 0.7843\n",
            "Epoch 41/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.3006 - accuracy: 0.8645 - val_loss: 0.6484 - val_accuracy: 0.7766\n",
            "Epoch 42/500\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.2921 - accuracy: 0.8729 - val_loss: 0.6373 - val_accuracy: 0.8182\n",
            "Epoch 43/500\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.2924 - accuracy: 0.8685 - val_loss: 0.6975 - val_accuracy: 0.7504\n",
            "Epoch 44/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2820 - accuracy: 0.8778 - val_loss: 0.7418 - val_accuracy: 0.7627\n",
            "Epoch 45/500\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2799 - accuracy: 0.8790 - val_loss: 0.7972 - val_accuracy: 0.7504\n",
            "Epoch 46/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2851 - accuracy: 0.8733 - val_loss: 0.7667 - val_accuracy: 0.7750\n",
            "Epoch 47/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2788 - accuracy: 0.8774 - val_loss: 0.7533 - val_accuracy: 0.7720\n",
            "Epoch 48/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2740 - accuracy: 0.8790 - val_loss: 0.7252 - val_accuracy: 0.8012\n",
            "Epoch 49/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2692 - accuracy: 0.8808 - val_loss: 0.7515 - val_accuracy: 0.8059\n",
            "Epoch 50/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2717 - accuracy: 0.8814 - val_loss: 0.8074 - val_accuracy: 0.7720\n",
            "Epoch 51/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2659 - accuracy: 0.8880 - val_loss: 0.8678 - val_accuracy: 0.7627\n",
            "Epoch 52/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2612 - accuracy: 0.8848 - val_loss: 0.7854 - val_accuracy: 0.8166\n",
            "Epoch 53/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2668 - accuracy: 0.8880 - val_loss: 0.7671 - val_accuracy: 0.7735\n",
            "Epoch 54/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2655 - accuracy: 0.8911 - val_loss: 0.8360 - val_accuracy: 0.8012\n",
            "Epoch 55/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2555 - accuracy: 0.8882 - val_loss: 0.7603 - val_accuracy: 0.8213\n",
            "Epoch 56/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2502 - accuracy: 0.8931 - val_loss: 0.8493 - val_accuracy: 0.7874\n",
            "Epoch 57/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2475 - accuracy: 0.8933 - val_loss: 0.7988 - val_accuracy: 0.8074\n",
            "Epoch 58/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2458 - accuracy: 0.8987 - val_loss: 0.7641 - val_accuracy: 0.8182\n",
            "Epoch 59/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2517 - accuracy: 0.8965 - val_loss: 0.8525 - val_accuracy: 0.7658\n",
            "Epoch 60/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2463 - accuracy: 0.8985 - val_loss: 0.8918 - val_accuracy: 0.8028\n",
            "Epoch 61/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2494 - accuracy: 0.8981 - val_loss: 0.8552 - val_accuracy: 0.8136\n",
            "Epoch 62/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2521 - accuracy: 0.8937 - val_loss: 0.8925 - val_accuracy: 0.8089\n",
            "Epoch 63/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2436 - accuracy: 0.8975 - val_loss: 0.8546 - val_accuracy: 0.8166\n",
            "Epoch 64/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2412 - accuracy: 0.9027 - val_loss: 0.8125 - val_accuracy: 0.8043\n",
            "Epoch 65/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2436 - accuracy: 0.8981 - val_loss: 0.7705 - val_accuracy: 0.8305\n",
            "Epoch 66/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2421 - accuracy: 0.9041 - val_loss: 0.8584 - val_accuracy: 0.8089\n",
            "Epoch 67/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2356 - accuracy: 0.8999 - val_loss: 0.8603 - val_accuracy: 0.8028\n",
            "Epoch 68/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2357 - accuracy: 0.9064 - val_loss: 0.8743 - val_accuracy: 0.7889\n",
            "Epoch 69/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2449 - accuracy: 0.8955 - val_loss: 0.9232 - val_accuracy: 0.7781\n",
            "Epoch 70/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2377 - accuracy: 0.8993 - val_loss: 0.8355 - val_accuracy: 0.8136\n",
            "Epoch 71/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2318 - accuracy: 0.9046 - val_loss: 0.8998 - val_accuracy: 0.8089\n",
            "Epoch 72/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2223 - accuracy: 0.9068 - val_loss: 0.9576 - val_accuracy: 0.7951\n",
            "Epoch 73/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2341 - accuracy: 0.9001 - val_loss: 0.8400 - val_accuracy: 0.8243\n",
            "Epoch 74/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2260 - accuracy: 0.9098 - val_loss: 0.9086 - val_accuracy: 0.8336\n",
            "Epoch 75/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2235 - accuracy: 0.9072 - val_loss: 0.9703 - val_accuracy: 0.7966\n",
            "Epoch 76/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2260 - accuracy: 0.9046 - val_loss: 1.0391 - val_accuracy: 0.7889\n",
            "Epoch 77/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2287 - accuracy: 0.9066 - val_loss: 0.8840 - val_accuracy: 0.8166\n",
            "Epoch 78/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2234 - accuracy: 0.9122 - val_loss: 1.0193 - val_accuracy: 0.7797\n",
            "Epoch 79/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2159 - accuracy: 0.9116 - val_loss: 0.9349 - val_accuracy: 0.8320\n",
            "Epoch 80/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2247 - accuracy: 0.9058 - val_loss: 0.9398 - val_accuracy: 0.8351\n",
            "Epoch 81/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2193 - accuracy: 0.9084 - val_loss: 0.9160 - val_accuracy: 0.8367\n",
            "Epoch 82/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2125 - accuracy: 0.9134 - val_loss: 1.0307 - val_accuracy: 0.7935\n",
            "Epoch 83/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2195 - accuracy: 0.9112 - val_loss: 1.0221 - val_accuracy: 0.7858\n",
            "Epoch 84/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2194 - accuracy: 0.9098 - val_loss: 0.9535 - val_accuracy: 0.8213\n",
            "Epoch 85/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2118 - accuracy: 0.9134 - val_loss: 1.1433 - val_accuracy: 0.7427\n",
            "Epoch 86/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2100 - accuracy: 0.9128 - val_loss: 0.9748 - val_accuracy: 0.8166\n",
            "Epoch 87/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2176 - accuracy: 0.9122 - val_loss: 1.0844 - val_accuracy: 0.7858\n",
            "Epoch 88/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1993 - accuracy: 0.9201 - val_loss: 0.9902 - val_accuracy: 0.8259\n",
            "Epoch 89/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2049 - accuracy: 0.9154 - val_loss: 1.0229 - val_accuracy: 0.8105\n",
            "Epoch 90/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2011 - accuracy: 0.9184 - val_loss: 1.0182 - val_accuracy: 0.8012\n",
            "Epoch 91/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2100 - accuracy: 0.9146 - val_loss: 1.0948 - val_accuracy: 0.7874\n",
            "Epoch 92/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2034 - accuracy: 0.9164 - val_loss: 0.9617 - val_accuracy: 0.8367\n",
            "Epoch 93/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1955 - accuracy: 0.9217 - val_loss: 1.2082 - val_accuracy: 0.7843\n",
            "Epoch 94/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2028 - accuracy: 0.9223 - val_loss: 0.9946 - val_accuracy: 0.8320\n",
            "Epoch 95/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1934 - accuracy: 0.9217 - val_loss: 1.0240 - val_accuracy: 0.8182\n",
            "Epoch 96/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1960 - accuracy: 0.9249 - val_loss: 1.1818 - val_accuracy: 0.7812\n",
            "Epoch 97/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1964 - accuracy: 0.9219 - val_loss: 1.1038 - val_accuracy: 0.8166\n",
            "Epoch 98/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1997 - accuracy: 0.9182 - val_loss: 1.0800 - val_accuracy: 0.8367\n",
            "Epoch 99/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1965 - accuracy: 0.9235 - val_loss: 1.1281 - val_accuracy: 0.8028\n",
            "Epoch 100/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1921 - accuracy: 0.9241 - val_loss: 1.1010 - val_accuracy: 0.7889\n",
            "Epoch 101/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1935 - accuracy: 0.9205 - val_loss: 1.1623 - val_accuracy: 0.8012\n",
            "Epoch 102/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1904 - accuracy: 0.9243 - val_loss: 1.0413 - val_accuracy: 0.8136\n",
            "Epoch 103/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1943 - accuracy: 0.9241 - val_loss: 1.1295 - val_accuracy: 0.8367\n",
            "Epoch 104/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1964 - accuracy: 0.9227 - val_loss: 1.0339 - val_accuracy: 0.8613\n",
            "Epoch 105/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1867 - accuracy: 0.9269 - val_loss: 1.0455 - val_accuracy: 0.8382\n",
            "Epoch 106/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1829 - accuracy: 0.9277 - val_loss: 1.1979 - val_accuracy: 0.8043\n",
            "Epoch 107/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1803 - accuracy: 0.9325 - val_loss: 1.1152 - val_accuracy: 0.8382\n",
            "Epoch 108/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1785 - accuracy: 0.9281 - val_loss: 1.0903 - val_accuracy: 0.8382\n",
            "Epoch 109/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1844 - accuracy: 0.9257 - val_loss: 1.1236 - val_accuracy: 0.8120\n",
            "Epoch 110/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1775 - accuracy: 0.9303 - val_loss: 1.1435 - val_accuracy: 0.8274\n",
            "Epoch 111/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1801 - accuracy: 0.9267 - val_loss: 1.0920 - val_accuracy: 0.8505\n",
            "Epoch 112/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1811 - accuracy: 0.9265 - val_loss: 1.2487 - val_accuracy: 0.8043\n",
            "Epoch 113/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1762 - accuracy: 0.9297 - val_loss: 1.1687 - val_accuracy: 0.8336\n",
            "Epoch 114/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1774 - accuracy: 0.9279 - val_loss: 1.1837 - val_accuracy: 0.8243\n",
            "Epoch 115/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1709 - accuracy: 0.9319 - val_loss: 1.1775 - val_accuracy: 0.8213\n",
            "Epoch 116/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1691 - accuracy: 0.9356 - val_loss: 1.2163 - val_accuracy: 0.8074\n",
            "Epoch 117/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1770 - accuracy: 0.9305 - val_loss: 1.2007 - val_accuracy: 0.8320\n",
            "Epoch 118/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1722 - accuracy: 0.9293 - val_loss: 1.2852 - val_accuracy: 0.7920\n",
            "Epoch 119/500\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1721 - accuracy: 0.9313 - val_loss: 1.2811 - val_accuracy: 0.8105\n",
            "Epoch 120/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1665 - accuracy: 0.9331 - val_loss: 1.3389 - val_accuracy: 0.8428\n",
            "Epoch 121/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1609 - accuracy: 0.9356 - val_loss: 1.2813 - val_accuracy: 0.8367\n",
            "Epoch 122/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1735 - accuracy: 0.9299 - val_loss: 1.3075 - val_accuracy: 0.8151\n",
            "Epoch 123/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1681 - accuracy: 0.9327 - val_loss: 1.4334 - val_accuracy: 0.7920\n",
            "Epoch 124/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1661 - accuracy: 0.9325 - val_loss: 1.3698 - val_accuracy: 0.8213\n",
            "Epoch 125/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1715 - accuracy: 0.9317 - val_loss: 1.4570 - val_accuracy: 0.7874\n",
            "Epoch 126/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1616 - accuracy: 0.9356 - val_loss: 1.3783 - val_accuracy: 0.8382\n",
            "Epoch 127/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1581 - accuracy: 0.9366 - val_loss: 1.2505 - val_accuracy: 0.8521\n",
            "Epoch 128/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1651 - accuracy: 0.9325 - val_loss: 1.2949 - val_accuracy: 0.8490\n",
            "Epoch 129/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1578 - accuracy: 0.9368 - val_loss: 1.4280 - val_accuracy: 0.8305\n",
            "Epoch 130/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1548 - accuracy: 0.9408 - val_loss: 1.5030 - val_accuracy: 0.7874\n",
            "Epoch 131/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1531 - accuracy: 0.9392 - val_loss: 1.4364 - val_accuracy: 0.8336\n",
            "Epoch 132/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1639 - accuracy: 0.9350 - val_loss: 1.4037 - val_accuracy: 0.8182\n",
            "Epoch 133/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1584 - accuracy: 0.9356 - val_loss: 1.3647 - val_accuracy: 0.8320\n",
            "Epoch 134/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1567 - accuracy: 0.9360 - val_loss: 1.4829 - val_accuracy: 0.8228\n",
            "Epoch 135/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1682 - accuracy: 0.9366 - val_loss: 1.3690 - val_accuracy: 0.8336\n",
            "Epoch 136/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1585 - accuracy: 0.9404 - val_loss: 1.4762 - val_accuracy: 0.8444\n",
            "Epoch 137/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1563 - accuracy: 0.9356 - val_loss: 1.4123 - val_accuracy: 0.8105\n",
            "Epoch 138/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1609 - accuracy: 0.9348 - val_loss: 1.4287 - val_accuracy: 0.8259\n",
            "Epoch 139/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1532 - accuracy: 0.9352 - val_loss: 1.4839 - val_accuracy: 0.8290\n",
            "Epoch 140/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1525 - accuracy: 0.9406 - val_loss: 1.4836 - val_accuracy: 0.8336\n",
            "Epoch 141/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1567 - accuracy: 0.9392 - val_loss: 1.4274 - val_accuracy: 0.8243\n",
            "Epoch 142/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1508 - accuracy: 0.9372 - val_loss: 1.4793 - val_accuracy: 0.8598\n",
            "Epoch 143/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1554 - accuracy: 0.9386 - val_loss: 1.5240 - val_accuracy: 0.8367\n",
            "Epoch 144/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1416 - accuracy: 0.9448 - val_loss: 1.5951 - val_accuracy: 0.8336\n",
            "Epoch 145/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1540 - accuracy: 0.9368 - val_loss: 1.5248 - val_accuracy: 0.8336\n",
            "Epoch 146/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1369 - accuracy: 0.9499 - val_loss: 1.5183 - val_accuracy: 0.8552\n",
            "Epoch 147/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1519 - accuracy: 0.9398 - val_loss: 1.6690 - val_accuracy: 0.8105\n",
            "Epoch 148/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1331 - accuracy: 0.9487 - val_loss: 1.5922 - val_accuracy: 0.8320\n",
            "Epoch 149/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1463 - accuracy: 0.9408 - val_loss: 1.4895 - val_accuracy: 0.8120\n",
            "Epoch 150/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1436 - accuracy: 0.9430 - val_loss: 1.5744 - val_accuracy: 0.8213\n",
            "Epoch 151/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1449 - accuracy: 0.9448 - val_loss: 1.6166 - val_accuracy: 0.8290\n",
            "Epoch 152/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1521 - accuracy: 0.9372 - val_loss: 1.6152 - val_accuracy: 0.8228\n",
            "Epoch 153/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1396 - accuracy: 0.9420 - val_loss: 1.6795 - val_accuracy: 0.8444\n",
            "Epoch 154/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1476 - accuracy: 0.9414 - val_loss: 1.6494 - val_accuracy: 0.8490\n",
            "Epoch 155/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1366 - accuracy: 0.9452 - val_loss: 1.5753 - val_accuracy: 0.8336\n",
            "Epoch 156/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1483 - accuracy: 0.9408 - val_loss: 1.5928 - val_accuracy: 0.8166\n",
            "Epoch 157/500\n",
            "414/414 [==============================] - 3s 8ms/step - loss: 0.1455 - accuracy: 0.9420 - val_loss: 1.7474 - val_accuracy: 0.8059\n",
            "Epoch 158/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1645 - accuracy: 0.9348 - val_loss: 1.6059 - val_accuracy: 0.8213\n",
            "Epoch 159/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1358 - accuracy: 0.9448 - val_loss: 1.6127 - val_accuracy: 0.8444\n",
            "Epoch 160/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1296 - accuracy: 0.9476 - val_loss: 1.7804 - val_accuracy: 0.8243\n",
            "Epoch 161/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1336 - accuracy: 0.9472 - val_loss: 1.7363 - val_accuracy: 0.8089\n",
            "Epoch 162/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1406 - accuracy: 0.9448 - val_loss: 1.6544 - val_accuracy: 0.8305\n",
            "Epoch 163/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1408 - accuracy: 0.9414 - val_loss: 1.6581 - val_accuracy: 0.8166\n",
            "Epoch 164/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1280 - accuracy: 0.9482 - val_loss: 1.6258 - val_accuracy: 0.8336\n",
            "Epoch 165/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1402 - accuracy: 0.9434 - val_loss: 1.6691 - val_accuracy: 0.8475\n",
            "Epoch 166/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1326 - accuracy: 0.9484 - val_loss: 1.7297 - val_accuracy: 0.8490\n",
            "Epoch 167/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1346 - accuracy: 0.9509 - val_loss: 1.6908 - val_accuracy: 0.8398\n",
            "Epoch 168/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1456 - accuracy: 0.9434 - val_loss: 1.7896 - val_accuracy: 0.8274\n",
            "Epoch 169/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1219 - accuracy: 0.9503 - val_loss: 1.8883 - val_accuracy: 0.8320\n",
            "Epoch 170/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1227 - accuracy: 0.9503 - val_loss: 1.8854 - val_accuracy: 0.8398\n",
            "Epoch 171/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1291 - accuracy: 0.9466 - val_loss: 1.8644 - val_accuracy: 0.8320\n",
            "Epoch 172/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1380 - accuracy: 0.9460 - val_loss: 1.7105 - val_accuracy: 0.8552\n",
            "Epoch 173/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1593 - accuracy: 0.9404 - val_loss: 1.6299 - val_accuracy: 0.8243\n",
            "Epoch 174/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1221 - accuracy: 0.9495 - val_loss: 1.7093 - val_accuracy: 0.8336\n",
            "Epoch 175/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1251 - accuracy: 0.9509 - val_loss: 1.7403 - val_accuracy: 0.8398\n",
            "Epoch 176/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1285 - accuracy: 0.9472 - val_loss: 1.7229 - val_accuracy: 0.8398\n",
            "Epoch 177/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1235 - accuracy: 0.9507 - val_loss: 1.7390 - val_accuracy: 0.8444\n",
            "Epoch 178/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1391 - accuracy: 0.9448 - val_loss: 1.7579 - val_accuracy: 0.8536\n",
            "Epoch 179/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1191 - accuracy: 0.9549 - val_loss: 1.7745 - val_accuracy: 0.8490\n",
            "Epoch 180/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1262 - accuracy: 0.9503 - val_loss: 1.8372 - val_accuracy: 0.8259\n",
            "Epoch 181/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1358 - accuracy: 0.9480 - val_loss: 1.7247 - val_accuracy: 0.8598\n",
            "Epoch 182/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1099 - accuracy: 0.9559 - val_loss: 1.9165 - val_accuracy: 0.8305\n",
            "Epoch 183/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1248 - accuracy: 0.9478 - val_loss: 1.7943 - val_accuracy: 0.8444\n",
            "Epoch 184/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1235 - accuracy: 0.9525 - val_loss: 1.7971 - val_accuracy: 0.8290\n",
            "Epoch 185/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1309 - accuracy: 0.9493 - val_loss: 1.8201 - val_accuracy: 0.8490\n",
            "Epoch 186/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1202 - accuracy: 0.9535 - val_loss: 1.8109 - val_accuracy: 0.8382\n",
            "Epoch 187/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1224 - accuracy: 0.9487 - val_loss: 1.8070 - val_accuracy: 0.8413\n",
            "Epoch 188/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1234 - accuracy: 0.9482 - val_loss: 1.8776 - val_accuracy: 0.8582\n",
            "Epoch 189/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1231 - accuracy: 0.9480 - val_loss: 1.8032 - val_accuracy: 0.8505\n",
            "Epoch 190/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1378 - accuracy: 0.9480 - val_loss: 1.8510 - val_accuracy: 0.8428\n",
            "Epoch 191/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1173 - accuracy: 0.9527 - val_loss: 1.9956 - val_accuracy: 0.8490\n",
            "Epoch 192/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1167 - accuracy: 0.9537 - val_loss: 1.8768 - val_accuracy: 0.8259\n",
            "Epoch 193/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1170 - accuracy: 0.9547 - val_loss: 1.8908 - val_accuracy: 0.8475\n",
            "Epoch 194/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1240 - accuracy: 0.9495 - val_loss: 1.9189 - val_accuracy: 0.8521\n",
            "Epoch 195/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1164 - accuracy: 0.9579 - val_loss: 2.0166 - val_accuracy: 0.8459\n",
            "Epoch 196/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1230 - accuracy: 0.9517 - val_loss: 1.9607 - val_accuracy: 0.8228\n",
            "Epoch 197/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1160 - accuracy: 0.9555 - val_loss: 1.9149 - val_accuracy: 0.8706\n",
            "Epoch 198/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1142 - accuracy: 0.9561 - val_loss: 2.0881 - val_accuracy: 0.8382\n",
            "Epoch 199/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1171 - accuracy: 0.9511 - val_loss: 1.9640 - val_accuracy: 0.8659\n",
            "Epoch 200/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1093 - accuracy: 0.9595 - val_loss: 2.1279 - val_accuracy: 0.8382\n",
            "Epoch 201/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1148 - accuracy: 0.9543 - val_loss: 2.1248 - val_accuracy: 0.8367\n",
            "Epoch 202/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1133 - accuracy: 0.9557 - val_loss: 2.0014 - val_accuracy: 0.8582\n",
            "Epoch 203/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1201 - accuracy: 0.9543 - val_loss: 1.9681 - val_accuracy: 0.8351\n",
            "Epoch 204/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1159 - accuracy: 0.9511 - val_loss: 2.1278 - val_accuracy: 0.8767\n",
            "Epoch 205/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1237 - accuracy: 0.9511 - val_loss: 1.9783 - val_accuracy: 0.8459\n",
            "Epoch 206/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1143 - accuracy: 0.9561 - val_loss: 2.1725 - val_accuracy: 0.8182\n",
            "Epoch 207/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1057 - accuracy: 0.9591 - val_loss: 2.0450 - val_accuracy: 0.8166\n",
            "Epoch 208/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1008 - accuracy: 0.9573 - val_loss: 2.2061 - val_accuracy: 0.8228\n",
            "Epoch 209/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1222 - accuracy: 0.9557 - val_loss: 2.0768 - val_accuracy: 0.8505\n",
            "Epoch 210/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1071 - accuracy: 0.9563 - val_loss: 1.9595 - val_accuracy: 0.8706\n",
            "Epoch 211/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1124 - accuracy: 0.9557 - val_loss: 2.0385 - val_accuracy: 0.8367\n",
            "Epoch 212/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1113 - accuracy: 0.9561 - val_loss: 2.0199 - val_accuracy: 0.8505\n",
            "Epoch 213/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1168 - accuracy: 0.9531 - val_loss: 2.0192 - val_accuracy: 0.8536\n",
            "Epoch 214/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1002 - accuracy: 0.9597 - val_loss: 2.1565 - val_accuracy: 0.8367\n",
            "Epoch 215/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0992 - accuracy: 0.9609 - val_loss: 2.0368 - val_accuracy: 0.8613\n",
            "Epoch 216/500\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1396 - accuracy: 0.9456 - val_loss: 2.0992 - val_accuracy: 0.8274\n",
            "Epoch 217/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1075 - accuracy: 0.9563 - val_loss: 2.2075 - val_accuracy: 0.8274\n",
            "Epoch 218/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1096 - accuracy: 0.9571 - val_loss: 2.0405 - val_accuracy: 0.8398\n",
            "Epoch 219/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1085 - accuracy: 0.9559 - val_loss: 2.0340 - val_accuracy: 0.8490\n",
            "Epoch 220/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1102 - accuracy: 0.9585 - val_loss: 2.2510 - val_accuracy: 0.8213\n",
            "Epoch 221/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1034 - accuracy: 0.9601 - val_loss: 2.1444 - val_accuracy: 0.8475\n",
            "Epoch 222/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1028 - accuracy: 0.9585 - val_loss: 2.2631 - val_accuracy: 0.8228\n",
            "Epoch 223/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1026 - accuracy: 0.9591 - val_loss: 2.4128 - val_accuracy: 0.8197\n",
            "Epoch 224/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1233 - accuracy: 0.9557 - val_loss: 2.0876 - val_accuracy: 0.8351\n",
            "Epoch 225/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0996 - accuracy: 0.9601 - val_loss: 2.2111 - val_accuracy: 0.8243\n",
            "Epoch 226/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1068 - accuracy: 0.9557 - val_loss: 2.1495 - val_accuracy: 0.8644\n",
            "Epoch 227/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1077 - accuracy: 0.9599 - val_loss: 2.1785 - val_accuracy: 0.8398\n",
            "Epoch 228/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1058 - accuracy: 0.9575 - val_loss: 2.0882 - val_accuracy: 0.8367\n",
            "Epoch 229/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1027 - accuracy: 0.9613 - val_loss: 2.0799 - val_accuracy: 0.8659\n",
            "Epoch 230/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9627 - val_loss: 2.2242 - val_accuracy: 0.8521\n",
            "Epoch 231/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1044 - accuracy: 0.9587 - val_loss: 2.0812 - val_accuracy: 0.8428\n",
            "Epoch 232/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1031 - accuracy: 0.9565 - val_loss: 2.1919 - val_accuracy: 0.8629\n",
            "Epoch 233/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1282 - accuracy: 0.9495 - val_loss: 1.9246 - val_accuracy: 0.8737\n",
            "Epoch 234/500\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.0917 - accuracy: 0.9619 - val_loss: 2.2148 - val_accuracy: 0.8521\n",
            "Epoch 235/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1070 - accuracy: 0.9561 - val_loss: 2.0651 - val_accuracy: 0.8228\n",
            "Epoch 236/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1060 - accuracy: 0.9579 - val_loss: 2.0691 - val_accuracy: 0.8567\n",
            "Epoch 237/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0947 - accuracy: 0.9617 - val_loss: 2.1022 - val_accuracy: 0.8721\n",
            "Epoch 238/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1048 - accuracy: 0.9579 - val_loss: 2.1289 - val_accuracy: 0.8213\n",
            "Epoch 239/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1122 - accuracy: 0.9563 - val_loss: 2.2917 - val_accuracy: 0.8182\n",
            "Epoch 240/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1079 - accuracy: 0.9543 - val_loss: 2.2338 - val_accuracy: 0.8336\n",
            "Epoch 241/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1067 - accuracy: 0.9567 - val_loss: 2.0517 - val_accuracy: 0.8243\n",
            "Epoch 242/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0988 - accuracy: 0.9634 - val_loss: 2.1775 - val_accuracy: 0.8367\n",
            "Epoch 243/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0956 - accuracy: 0.9640 - val_loss: 2.2488 - val_accuracy: 0.8444\n",
            "Epoch 244/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1029 - accuracy: 0.9591 - val_loss: 2.2338 - val_accuracy: 0.8398\n",
            "Epoch 245/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0858 - accuracy: 0.9676 - val_loss: 2.2229 - val_accuracy: 0.8382\n",
            "Epoch 246/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1257 - accuracy: 0.9535 - val_loss: 2.2420 - val_accuracy: 0.8552\n",
            "Epoch 247/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9625 - val_loss: 2.3584 - val_accuracy: 0.8475\n",
            "Epoch 248/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1090 - accuracy: 0.9565 - val_loss: 2.2159 - val_accuracy: 0.8182\n",
            "Epoch 249/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9627 - val_loss: 2.3584 - val_accuracy: 0.8243\n",
            "Epoch 250/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0887 - accuracy: 0.9662 - val_loss: 2.3599 - val_accuracy: 0.8413\n",
            "Epoch 251/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1038 - accuracy: 0.9619 - val_loss: 2.2048 - val_accuracy: 0.8567\n",
            "Epoch 252/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0995 - accuracy: 0.9595 - val_loss: 2.1662 - val_accuracy: 0.8444\n",
            "Epoch 253/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1079 - accuracy: 0.9597 - val_loss: 2.1679 - val_accuracy: 0.8259\n",
            "Epoch 254/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0959 - accuracy: 0.9609 - val_loss: 2.3578 - val_accuracy: 0.8644\n",
            "Epoch 255/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0998 - accuracy: 0.9613 - val_loss: 2.3418 - val_accuracy: 0.8398\n",
            "Epoch 256/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0917 - accuracy: 0.9648 - val_loss: 2.2157 - val_accuracy: 0.8798\n",
            "Epoch 257/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1037 - accuracy: 0.9623 - val_loss: 2.2917 - val_accuracy: 0.8552\n",
            "Epoch 258/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0848 - accuracy: 0.9670 - val_loss: 2.3686 - val_accuracy: 0.8413\n",
            "Epoch 259/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1024 - accuracy: 0.9583 - val_loss: 2.3059 - val_accuracy: 0.8459\n",
            "Epoch 260/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1012 - accuracy: 0.9617 - val_loss: 2.3953 - val_accuracy: 0.8459\n",
            "Epoch 261/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9601 - val_loss: 2.4162 - val_accuracy: 0.8613\n",
            "Epoch 262/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0853 - accuracy: 0.9662 - val_loss: 2.2850 - val_accuracy: 0.8536\n",
            "Epoch 263/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0979 - accuracy: 0.9629 - val_loss: 2.3493 - val_accuracy: 0.8629\n",
            "Epoch 264/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0903 - accuracy: 0.9621 - val_loss: 2.3275 - val_accuracy: 0.8475\n",
            "Epoch 265/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1007 - accuracy: 0.9593 - val_loss: 2.2818 - val_accuracy: 0.8644\n",
            "Epoch 266/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.9631 - val_loss: 2.4206 - val_accuracy: 0.8629\n",
            "Epoch 267/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1045 - accuracy: 0.9581 - val_loss: 2.3837 - val_accuracy: 0.8598\n",
            "Epoch 268/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0898 - accuracy: 0.9640 - val_loss: 2.5374 - val_accuracy: 0.8459\n",
            "Epoch 269/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1008 - accuracy: 0.9619 - val_loss: 2.4366 - val_accuracy: 0.8521\n",
            "Epoch 270/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0853 - accuracy: 0.9648 - val_loss: 2.3400 - val_accuracy: 0.8305\n",
            "Epoch 271/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0878 - accuracy: 0.9656 - val_loss: 2.4963 - val_accuracy: 0.8320\n",
            "Epoch 272/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0966 - accuracy: 0.9623 - val_loss: 2.3609 - val_accuracy: 0.8582\n",
            "Epoch 273/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0832 - accuracy: 0.9662 - val_loss: 2.3568 - val_accuracy: 0.8490\n",
            "Epoch 274/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0933 - accuracy: 0.9634 - val_loss: 2.4899 - val_accuracy: 0.8475\n",
            "Epoch 275/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1012 - accuracy: 0.9605 - val_loss: 2.4572 - val_accuracy: 0.8582\n",
            "Epoch 276/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0868 - accuracy: 0.9670 - val_loss: 2.4881 - val_accuracy: 0.8444\n",
            "Epoch 277/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0887 - accuracy: 0.9652 - val_loss: 2.5547 - val_accuracy: 0.8490\n",
            "Epoch 278/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1173 - accuracy: 0.9573 - val_loss: 2.4293 - val_accuracy: 0.8536\n",
            "Epoch 279/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0829 - accuracy: 0.9642 - val_loss: 2.4667 - val_accuracy: 0.8475\n",
            "Epoch 280/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1109 - accuracy: 0.9561 - val_loss: 2.4825 - val_accuracy: 0.8552\n",
            "Epoch 281/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0797 - accuracy: 0.9680 - val_loss: 2.5048 - val_accuracy: 0.8552\n",
            "Epoch 282/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0877 - accuracy: 0.9615 - val_loss: 2.5192 - val_accuracy: 0.8690\n",
            "Epoch 283/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0774 - accuracy: 0.9684 - val_loss: 2.5998 - val_accuracy: 0.8505\n",
            "Epoch 284/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0887 - accuracy: 0.9666 - val_loss: 2.4347 - val_accuracy: 0.8598\n",
            "Epoch 285/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9627 - val_loss: 2.2307 - val_accuracy: 0.8582\n",
            "Epoch 286/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0799 - accuracy: 0.9678 - val_loss: 2.4268 - val_accuracy: 0.8613\n",
            "Epoch 287/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1056 - accuracy: 0.9601 - val_loss: 2.4261 - val_accuracy: 0.8675\n",
            "Epoch 288/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0755 - accuracy: 0.9698 - val_loss: 2.3445 - val_accuracy: 0.8737\n",
            "Epoch 289/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0764 - accuracy: 0.9714 - val_loss: 2.5160 - val_accuracy: 0.8428\n",
            "Epoch 290/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1176 - accuracy: 0.9563 - val_loss: 2.1646 - val_accuracy: 0.8505\n",
            "Epoch 291/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1066 - accuracy: 0.9553 - val_loss: 2.3798 - val_accuracy: 0.8490\n",
            "Epoch 292/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0884 - accuracy: 0.9658 - val_loss: 2.3477 - val_accuracy: 0.8459\n",
            "Epoch 293/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0805 - accuracy: 0.9684 - val_loss: 2.5322 - val_accuracy: 0.8536\n",
            "Epoch 294/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0910 - accuracy: 0.9617 - val_loss: 2.5309 - val_accuracy: 0.8490\n",
            "Epoch 295/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0981 - accuracy: 0.9623 - val_loss: 2.5526 - val_accuracy: 0.8336\n",
            "Epoch 296/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.9662 - val_loss: 2.4900 - val_accuracy: 0.8690\n",
            "Epoch 297/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0856 - accuracy: 0.9650 - val_loss: 2.5468 - val_accuracy: 0.8582\n",
            "Epoch 298/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0822 - accuracy: 0.9684 - val_loss: 2.5918 - val_accuracy: 0.8290\n",
            "Epoch 299/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0884 - accuracy: 0.9648 - val_loss: 2.3364 - val_accuracy: 0.8475\n",
            "Epoch 300/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0839 - accuracy: 0.9660 - val_loss: 2.4664 - val_accuracy: 0.8659\n",
            "Epoch 301/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0777 - accuracy: 0.9684 - val_loss: 2.6984 - val_accuracy: 0.8582\n",
            "Epoch 302/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0778 - accuracy: 0.9672 - val_loss: 2.5989 - val_accuracy: 0.8459\n",
            "Epoch 303/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0941 - accuracy: 0.9644 - val_loss: 2.6272 - val_accuracy: 0.8752\n",
            "Epoch 304/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1063 - accuracy: 0.9603 - val_loss: 2.5645 - val_accuracy: 0.8598\n",
            "Epoch 305/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0728 - accuracy: 0.9712 - val_loss: 2.7511 - val_accuracy: 0.8613\n",
            "Epoch 306/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0769 - accuracy: 0.9720 - val_loss: 2.6353 - val_accuracy: 0.8305\n",
            "Epoch 307/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0828 - accuracy: 0.9676 - val_loss: 2.6445 - val_accuracy: 0.8475\n",
            "Epoch 308/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0857 - accuracy: 0.9672 - val_loss: 2.6293 - val_accuracy: 0.8444\n",
            "Epoch 309/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9634 - val_loss: 2.6046 - val_accuracy: 0.8475\n",
            "Epoch 310/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0766 - accuracy: 0.9702 - val_loss: 2.5127 - val_accuracy: 0.8675\n",
            "Epoch 311/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0831 - accuracy: 0.9680 - val_loss: 2.4737 - val_accuracy: 0.8536\n",
            "Epoch 312/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0873 - accuracy: 0.9658 - val_loss: 2.3856 - val_accuracy: 0.8706\n",
            "Epoch 313/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0886 - accuracy: 0.9670 - val_loss: 2.2177 - val_accuracy: 0.8613\n",
            "Epoch 314/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0890 - accuracy: 0.9640 - val_loss: 2.4117 - val_accuracy: 0.8598\n",
            "Epoch 315/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0724 - accuracy: 0.9714 - val_loss: 2.5874 - val_accuracy: 0.8521\n",
            "Epoch 316/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0747 - accuracy: 0.9718 - val_loss: 2.5540 - val_accuracy: 0.8475\n",
            "Epoch 317/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0800 - accuracy: 0.9674 - val_loss: 2.6084 - val_accuracy: 0.8567\n",
            "Epoch 318/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0712 - accuracy: 0.9706 - val_loss: 2.5780 - val_accuracy: 0.8598\n",
            "Epoch 319/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0864 - accuracy: 0.9652 - val_loss: 2.5671 - val_accuracy: 0.8659\n",
            "Epoch 320/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0865 - accuracy: 0.9670 - val_loss: 2.4494 - val_accuracy: 0.8552\n",
            "Epoch 321/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0894 - accuracy: 0.9670 - val_loss: 2.3991 - val_accuracy: 0.8629\n",
            "Epoch 322/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0912 - accuracy: 0.9664 - val_loss: 2.5802 - val_accuracy: 0.8675\n",
            "Epoch 323/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0740 - accuracy: 0.9718 - val_loss: 2.6295 - val_accuracy: 0.8613\n",
            "Epoch 324/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9646 - val_loss: 2.7762 - val_accuracy: 0.8659\n",
            "Epoch 325/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0699 - accuracy: 0.9706 - val_loss: 2.7324 - val_accuracy: 0.8598\n",
            "Epoch 326/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0916 - accuracy: 0.9640 - val_loss: 2.7396 - val_accuracy: 0.8351\n",
            "Epoch 327/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0919 - accuracy: 0.9640 - val_loss: 2.4603 - val_accuracy: 0.8659\n",
            "Epoch 328/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0685 - accuracy: 0.9728 - val_loss: 2.6119 - val_accuracy: 0.8351\n",
            "Epoch 329/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0654 - accuracy: 0.9738 - val_loss: 2.5381 - val_accuracy: 0.8459\n",
            "Epoch 330/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0686 - accuracy: 0.9742 - val_loss: 2.6616 - val_accuracy: 0.8413\n",
            "Epoch 331/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0894 - accuracy: 0.9652 - val_loss: 2.5663 - val_accuracy: 0.8875\n",
            "Epoch 332/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0682 - accuracy: 0.9730 - val_loss: 2.4695 - val_accuracy: 0.8706\n",
            "Epoch 333/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0851 - accuracy: 0.9698 - val_loss: 2.5112 - val_accuracy: 0.8567\n",
            "Epoch 334/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0793 - accuracy: 0.9680 - val_loss: 2.7678 - val_accuracy: 0.8382\n",
            "Epoch 335/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0757 - accuracy: 0.9706 - val_loss: 2.8466 - val_accuracy: 0.8505\n",
            "Epoch 336/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0988 - accuracy: 0.9648 - val_loss: 2.4005 - val_accuracy: 0.8274\n",
            "Epoch 337/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0852 - accuracy: 0.9690 - val_loss: 2.7253 - val_accuracy: 0.8582\n",
            "Epoch 338/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0752 - accuracy: 0.9688 - val_loss: 2.6804 - val_accuracy: 0.8521\n",
            "Epoch 339/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0738 - accuracy: 0.9730 - val_loss: 2.6714 - val_accuracy: 0.8706\n",
            "Epoch 340/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0781 - accuracy: 0.9704 - val_loss: 2.6962 - val_accuracy: 0.8613\n",
            "Epoch 341/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1124 - accuracy: 0.9605 - val_loss: 2.6173 - val_accuracy: 0.8536\n",
            "Epoch 342/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0933 - accuracy: 0.9670 - val_loss: 2.5872 - val_accuracy: 0.8521\n",
            "Epoch 343/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0672 - accuracy: 0.9748 - val_loss: 2.7090 - val_accuracy: 0.8521\n",
            "Epoch 344/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0752 - accuracy: 0.9722 - val_loss: 2.6190 - val_accuracy: 0.8629\n",
            "Epoch 345/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0729 - accuracy: 0.9698 - val_loss: 2.5100 - val_accuracy: 0.8644\n",
            "Epoch 346/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0650 - accuracy: 0.9752 - val_loss: 2.7031 - val_accuracy: 0.8475\n",
            "Epoch 347/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0630 - accuracy: 0.9764 - val_loss: 2.6049 - val_accuracy: 0.8552\n",
            "Epoch 348/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0980 - accuracy: 0.9638 - val_loss: 2.6307 - val_accuracy: 0.8552\n",
            "Epoch 349/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0702 - accuracy: 0.9738 - val_loss: 2.6482 - val_accuracy: 0.8644\n",
            "Epoch 350/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0843 - accuracy: 0.9690 - val_loss: 2.9169 - val_accuracy: 0.8582\n",
            "Epoch 351/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0632 - accuracy: 0.9750 - val_loss: 2.7155 - val_accuracy: 0.8659\n",
            "Epoch 352/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0641 - accuracy: 0.9746 - val_loss: 2.7328 - val_accuracy: 0.8598\n",
            "Epoch 353/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1000 - accuracy: 0.9613 - val_loss: 2.6317 - val_accuracy: 0.8721\n",
            "Epoch 354/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0652 - accuracy: 0.9746 - val_loss: 2.7327 - val_accuracy: 0.8629\n",
            "Epoch 355/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0726 - accuracy: 0.9716 - val_loss: 2.5615 - val_accuracy: 0.8783\n",
            "Epoch 356/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0781 - accuracy: 0.9706 - val_loss: 2.6692 - val_accuracy: 0.8613\n",
            "Epoch 357/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0779 - accuracy: 0.9664 - val_loss: 2.6889 - val_accuracy: 0.8490\n",
            "Epoch 358/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0832 - accuracy: 0.9660 - val_loss: 2.7288 - val_accuracy: 0.8552\n",
            "Epoch 359/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0847 - accuracy: 0.9674 - val_loss: 2.8322 - val_accuracy: 0.8690\n",
            "Epoch 360/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0709 - accuracy: 0.9716 - val_loss: 3.1169 - val_accuracy: 0.8382\n",
            "Epoch 361/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0737 - accuracy: 0.9718 - val_loss: 2.5936 - val_accuracy: 0.8475\n",
            "Epoch 362/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0673 - accuracy: 0.9722 - val_loss: 2.7614 - val_accuracy: 0.8582\n",
            "Epoch 363/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0827 - accuracy: 0.9682 - val_loss: 2.7537 - val_accuracy: 0.8521\n",
            "Epoch 364/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0655 - accuracy: 0.9748 - val_loss: 2.6950 - val_accuracy: 0.8567\n",
            "Epoch 365/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0726 - accuracy: 0.9720 - val_loss: 2.9817 - val_accuracy: 0.8475\n",
            "Epoch 366/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0691 - accuracy: 0.9756 - val_loss: 2.8291 - val_accuracy: 0.8413\n",
            "Epoch 367/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0701 - accuracy: 0.9738 - val_loss: 2.8028 - val_accuracy: 0.8675\n",
            "Epoch 368/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0792 - accuracy: 0.9696 - val_loss: 2.8358 - val_accuracy: 0.8398\n",
            "Epoch 369/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0712 - accuracy: 0.9718 - val_loss: 2.9016 - val_accuracy: 0.8444\n",
            "Epoch 370/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0806 - accuracy: 0.9710 - val_loss: 2.7098 - val_accuracy: 0.8752\n",
            "Epoch 371/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0623 - accuracy: 0.9734 - val_loss: 2.9285 - val_accuracy: 0.8490\n",
            "Epoch 372/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0659 - accuracy: 0.9754 - val_loss: 2.9543 - val_accuracy: 0.8505\n",
            "Epoch 373/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0902 - accuracy: 0.9672 - val_loss: 2.7035 - val_accuracy: 0.8659\n",
            "Epoch 374/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0808 - accuracy: 0.9684 - val_loss: 2.6354 - val_accuracy: 0.8536\n",
            "Epoch 375/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0566 - accuracy: 0.9781 - val_loss: 2.6453 - val_accuracy: 0.8582\n",
            "Epoch 376/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0576 - accuracy: 0.9774 - val_loss: 2.6944 - val_accuracy: 0.8675\n",
            "Epoch 377/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0958 - accuracy: 0.9629 - val_loss: 2.6914 - val_accuracy: 0.8706\n",
            "Epoch 378/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0622 - accuracy: 0.9760 - val_loss: 2.6894 - val_accuracy: 0.8783\n",
            "Epoch 379/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0594 - accuracy: 0.9760 - val_loss: 2.7021 - val_accuracy: 0.8675\n",
            "Epoch 380/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0682 - accuracy: 0.9722 - val_loss: 2.6703 - val_accuracy: 0.8382\n",
            "Epoch 381/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0938 - accuracy: 0.9672 - val_loss: 2.9911 - val_accuracy: 0.8629\n",
            "Epoch 382/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0663 - accuracy: 0.9742 - val_loss: 3.0853 - val_accuracy: 0.8475\n",
            "Epoch 383/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0582 - accuracy: 0.9781 - val_loss: 3.0662 - val_accuracy: 0.8552\n",
            "Epoch 384/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0849 - accuracy: 0.9704 - val_loss: 2.9054 - val_accuracy: 0.8505\n",
            "Epoch 385/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0956 - accuracy: 0.9650 - val_loss: 2.8048 - val_accuracy: 0.8552\n",
            "Epoch 386/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0560 - accuracy: 0.9776 - val_loss: 2.7781 - val_accuracy: 0.8690\n",
            "Epoch 387/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0601 - accuracy: 0.9762 - val_loss: 2.9037 - val_accuracy: 0.8459\n",
            "Epoch 388/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0907 - accuracy: 0.9648 - val_loss: 2.7126 - val_accuracy: 0.8721\n",
            "Epoch 389/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9629 - val_loss: 2.6995 - val_accuracy: 0.8536\n",
            "Epoch 390/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0589 - accuracy: 0.9774 - val_loss: 2.7817 - val_accuracy: 0.8475\n",
            "Epoch 391/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0588 - accuracy: 0.9768 - val_loss: 2.8495 - val_accuracy: 0.8521\n",
            "Epoch 392/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0672 - accuracy: 0.9744 - val_loss: 2.7486 - val_accuracy: 0.8598\n",
            "Epoch 393/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0548 - accuracy: 0.9781 - val_loss: 2.9558 - val_accuracy: 0.8860\n",
            "Epoch 394/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0712 - accuracy: 0.9718 - val_loss: 2.8590 - val_accuracy: 0.8521\n",
            "Epoch 395/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1037 - accuracy: 0.9609 - val_loss: 2.9000 - val_accuracy: 0.8428\n",
            "Epoch 396/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0801 - accuracy: 0.9708 - val_loss: 2.7739 - val_accuracy: 0.8521\n",
            "Epoch 397/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0562 - accuracy: 0.9752 - val_loss: 2.8865 - val_accuracy: 0.8536\n",
            "Epoch 398/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0665 - accuracy: 0.9740 - val_loss: 2.6152 - val_accuracy: 0.8798\n",
            "Epoch 399/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0631 - accuracy: 0.9760 - val_loss: 2.7261 - val_accuracy: 0.8582\n",
            "Epoch 400/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0588 - accuracy: 0.9766 - val_loss: 3.0717 - val_accuracy: 0.8444\n",
            "Epoch 401/500\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.0856 - accuracy: 0.9698 - val_loss: 2.7685 - val_accuracy: 0.8629\n",
            "Epoch 402/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0716 - accuracy: 0.9724 - val_loss: 2.8000 - val_accuracy: 0.8737\n",
            "Epoch 403/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0757 - accuracy: 0.9720 - val_loss: 2.8104 - val_accuracy: 0.8552\n",
            "Epoch 404/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0669 - accuracy: 0.9726 - val_loss: 2.9603 - val_accuracy: 0.8613\n",
            "Epoch 405/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0556 - accuracy: 0.9778 - val_loss: 2.9805 - val_accuracy: 0.8475\n",
            "Epoch 406/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0636 - accuracy: 0.9742 - val_loss: 2.9629 - val_accuracy: 0.8567\n",
            "Epoch 407/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1090 - accuracy: 0.9605 - val_loss: 2.8299 - val_accuracy: 0.8505\n",
            "Epoch 408/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0695 - accuracy: 0.9732 - val_loss: 2.9048 - val_accuracy: 0.8659\n",
            "Epoch 409/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0552 - accuracy: 0.9783 - val_loss: 2.9494 - val_accuracy: 0.8582\n",
            "Epoch 410/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0572 - accuracy: 0.9789 - val_loss: 3.0123 - val_accuracy: 0.8459\n",
            "Epoch 411/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0625 - accuracy: 0.9764 - val_loss: 2.7791 - val_accuracy: 0.8659\n",
            "Epoch 412/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0685 - accuracy: 0.9744 - val_loss: 2.9424 - val_accuracy: 0.8336\n",
            "Epoch 413/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0620 - accuracy: 0.9760 - val_loss: 2.9342 - val_accuracy: 0.8613\n",
            "Epoch 414/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0734 - accuracy: 0.9712 - val_loss: 2.7799 - val_accuracy: 0.8629\n",
            "Epoch 415/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0780 - accuracy: 0.9688 - val_loss: 2.9371 - val_accuracy: 0.8567\n",
            "Epoch 416/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0686 - accuracy: 0.9746 - val_loss: 2.9250 - val_accuracy: 0.8336\n",
            "Epoch 417/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0641 - accuracy: 0.9744 - val_loss: 2.8377 - val_accuracy: 0.8613\n",
            "Epoch 418/500\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.0597 - accuracy: 0.9778 - val_loss: 2.8907 - val_accuracy: 0.8552\n",
            "Epoch 419/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0634 - accuracy: 0.9754 - val_loss: 2.9087 - val_accuracy: 0.8659\n",
            "Epoch 420/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0599 - accuracy: 0.9770 - val_loss: 2.8473 - val_accuracy: 0.8598\n",
            "Epoch 421/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0589 - accuracy: 0.9774 - val_loss: 3.0938 - val_accuracy: 0.8398\n",
            "Epoch 422/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0672 - accuracy: 0.9742 - val_loss: 3.0322 - val_accuracy: 0.8444\n",
            "Epoch 423/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0573 - accuracy: 0.9748 - val_loss: 2.8417 - val_accuracy: 0.8613\n",
            "Epoch 424/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0950 - accuracy: 0.9658 - val_loss: 2.8897 - val_accuracy: 0.8413\n",
            "Epoch 425/500\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.0657 - accuracy: 0.9750 - val_loss: 2.8904 - val_accuracy: 0.8706\n",
            "Epoch 426/500\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.0586 - accuracy: 0.9776 - val_loss: 2.8823 - val_accuracy: 0.8598\n",
            "Epoch 427/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0669 - accuracy: 0.9748 - val_loss: 2.8177 - val_accuracy: 0.8552\n",
            "Epoch 428/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0817 - accuracy: 0.9674 - val_loss: 2.7115 - val_accuracy: 0.8536\n",
            "Epoch 429/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0600 - accuracy: 0.9776 - val_loss: 2.8099 - val_accuracy: 0.8644\n",
            "Epoch 430/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0569 - accuracy: 0.9776 - val_loss: 2.9831 - val_accuracy: 0.8690\n",
            "Epoch 431/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0560 - accuracy: 0.9785 - val_loss: 2.9725 - val_accuracy: 0.8536\n",
            "Epoch 432/500\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.0635 - accuracy: 0.9736 - val_loss: 2.8992 - val_accuracy: 0.8613\n",
            "Epoch 433/500\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.0776 - accuracy: 0.9704 - val_loss: 2.7793 - val_accuracy: 0.8505\n",
            "Epoch 434/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0627 - accuracy: 0.9754 - val_loss: 2.8003 - val_accuracy: 0.8783\n",
            "Epoch 435/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0629 - accuracy: 0.9742 - val_loss: 3.0617 - val_accuracy: 0.8567\n",
            "Epoch 436/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0667 - accuracy: 0.9732 - val_loss: 3.0900 - val_accuracy: 0.8490\n",
            "Epoch 437/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0629 - accuracy: 0.9744 - val_loss: 2.9878 - val_accuracy: 0.8644\n",
            "Epoch 438/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0607 - accuracy: 0.9762 - val_loss: 2.8410 - val_accuracy: 0.8382\n",
            "Epoch 439/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0614 - accuracy: 0.9742 - val_loss: 2.8491 - val_accuracy: 0.8675\n",
            "Epoch 440/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0575 - accuracy: 0.9776 - val_loss: 3.1575 - val_accuracy: 0.8598\n",
            "Epoch 441/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0771 - accuracy: 0.9706 - val_loss: 3.0928 - val_accuracy: 0.8783\n",
            "Epoch 442/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0645 - accuracy: 0.9791 - val_loss: 2.9508 - val_accuracy: 0.8659\n",
            "Epoch 443/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0749 - accuracy: 0.9736 - val_loss: 2.8351 - val_accuracy: 0.8521\n",
            "Epoch 444/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0554 - accuracy: 0.9803 - val_loss: 2.9876 - val_accuracy: 0.8567\n",
            "Epoch 445/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0612 - accuracy: 0.9766 - val_loss: 2.8748 - val_accuracy: 0.8228\n",
            "Epoch 446/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0822 - accuracy: 0.9694 - val_loss: 3.0669 - val_accuracy: 0.8567\n",
            "Epoch 447/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0527 - accuracy: 0.9787 - val_loss: 2.9788 - val_accuracy: 0.8659\n",
            "Epoch 448/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0730 - accuracy: 0.9730 - val_loss: 2.6318 - val_accuracy: 0.8783\n",
            "Epoch 449/500\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.0644 - accuracy: 0.9736 - val_loss: 2.8057 - val_accuracy: 0.8706\n",
            "Epoch 450/500\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.0548 - accuracy: 0.9797 - val_loss: 2.8432 - val_accuracy: 0.8706\n",
            "Epoch 451/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.9785 - val_loss: 2.9800 - val_accuracy: 0.8536\n",
            "Epoch 452/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0659 - accuracy: 0.9734 - val_loss: 3.3083 - val_accuracy: 0.8274\n",
            "Epoch 453/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0677 - accuracy: 0.9730 - val_loss: 2.8767 - val_accuracy: 0.8567\n",
            "Epoch 454/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0638 - accuracy: 0.9760 - val_loss: 2.9283 - val_accuracy: 0.8521\n",
            "Epoch 455/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0564 - accuracy: 0.9789 - val_loss: 3.0508 - val_accuracy: 0.8582\n",
            "Epoch 456/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0510 - accuracy: 0.9803 - val_loss: 3.1390 - val_accuracy: 0.8521\n",
            "Epoch 457/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0991 - accuracy: 0.9682 - val_loss: 2.8936 - val_accuracy: 0.8320\n",
            "Epoch 458/500\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.0636 - accuracy: 0.9760 - val_loss: 2.7500 - val_accuracy: 0.8706\n",
            "Epoch 459/500\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.0468 - accuracy: 0.9815 - val_loss: 2.8146 - val_accuracy: 0.8505\n",
            "Epoch 460/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0579 - accuracy: 0.9783 - val_loss: 2.7163 - val_accuracy: 0.8644\n",
            "Epoch 461/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0925 - accuracy: 0.9690 - val_loss: 2.6220 - val_accuracy: 0.8536\n",
            "Epoch 462/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0576 - accuracy: 0.9758 - val_loss: 2.7810 - val_accuracy: 0.8721\n",
            "Epoch 463/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0447 - accuracy: 0.9831 - val_loss: 2.7885 - val_accuracy: 0.8737\n",
            "Epoch 464/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0574 - accuracy: 0.9778 - val_loss: 2.7577 - val_accuracy: 0.8644\n",
            "Epoch 465/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0698 - accuracy: 0.9740 - val_loss: 3.0639 - val_accuracy: 0.8567\n",
            "Epoch 466/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0683 - accuracy: 0.9768 - val_loss: 2.8381 - val_accuracy: 0.8536\n",
            "Epoch 467/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0576 - accuracy: 0.9783 - val_loss: 2.9522 - val_accuracy: 0.8644\n",
            "Epoch 468/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0457 - accuracy: 0.9825 - val_loss: 2.9103 - val_accuracy: 0.8505\n",
            "Epoch 469/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0453 - accuracy: 0.9813 - val_loss: 3.0256 - val_accuracy: 0.8737\n",
            "Epoch 470/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0929 - accuracy: 0.9668 - val_loss: 2.6266 - val_accuracy: 0.8644\n",
            "Epoch 471/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0635 - accuracy: 0.9748 - val_loss: 2.7687 - val_accuracy: 0.8582\n",
            "Epoch 472/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0480 - accuracy: 0.9801 - val_loss: 2.8595 - val_accuracy: 0.8567\n",
            "Epoch 473/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0547 - accuracy: 0.9799 - val_loss: 2.8512 - val_accuracy: 0.8629\n",
            "Epoch 474/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0641 - accuracy: 0.9724 - val_loss: 2.7666 - val_accuracy: 0.8814\n",
            "Epoch 475/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0525 - accuracy: 0.9793 - val_loss: 2.8665 - val_accuracy: 0.8644\n",
            "Epoch 476/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0445 - accuracy: 0.9831 - val_loss: 2.9436 - val_accuracy: 0.8675\n",
            "Epoch 477/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0925 - accuracy: 0.9644 - val_loss: 2.9029 - val_accuracy: 0.8413\n",
            "Epoch 478/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0547 - accuracy: 0.9807 - val_loss: 3.0957 - val_accuracy: 0.8413\n",
            "Epoch 479/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0540 - accuracy: 0.9799 - val_loss: 3.0805 - val_accuracy: 0.8475\n",
            "Epoch 480/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0807 - accuracy: 0.9684 - val_loss: 2.9846 - val_accuracy: 0.8521\n",
            "Epoch 481/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0559 - accuracy: 0.9778 - val_loss: 3.0141 - val_accuracy: 0.8521\n",
            "Epoch 482/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0479 - accuracy: 0.9821 - val_loss: 3.1497 - val_accuracy: 0.8521\n",
            "Epoch 483/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9811 - val_loss: 3.0062 - val_accuracy: 0.8644\n",
            "Epoch 484/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0606 - accuracy: 0.9760 - val_loss: 3.1341 - val_accuracy: 0.8613\n",
            "Epoch 485/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0543 - accuracy: 0.9795 - val_loss: 3.0274 - val_accuracy: 0.8737\n",
            "Epoch 486/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0613 - accuracy: 0.9762 - val_loss: 3.1484 - val_accuracy: 0.8521\n",
            "Epoch 487/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0578 - accuracy: 0.9752 - val_loss: 3.2396 - val_accuracy: 0.8567\n",
            "Epoch 488/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0451 - accuracy: 0.9795 - val_loss: 3.1340 - val_accuracy: 0.8459\n",
            "Epoch 489/500\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0719 - accuracy: 0.9742 - val_loss: 3.1289 - val_accuracy: 0.8505\n",
            "Epoch 490/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0475 - accuracy: 0.9833 - val_loss: 3.3241 - val_accuracy: 0.8552\n",
            "Epoch 491/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0657 - accuracy: 0.9760 - val_loss: 2.8759 - val_accuracy: 0.8166\n",
            "Epoch 492/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0713 - accuracy: 0.9758 - val_loss: 3.0524 - val_accuracy: 0.8675\n",
            "Epoch 493/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0438 - accuracy: 0.9823 - val_loss: 3.2037 - val_accuracy: 0.8783\n",
            "Epoch 494/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0546 - accuracy: 0.9791 - val_loss: 3.1861 - val_accuracy: 0.8536\n",
            "Epoch 495/500\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.0709 - accuracy: 0.9734 - val_loss: 3.0795 - val_accuracy: 0.8613\n",
            "Epoch 496/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0534 - accuracy: 0.9799 - val_loss: 3.1090 - val_accuracy: 0.8767\n",
            "Epoch 497/500\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0563 - accuracy: 0.9795 - val_loss: 3.0298 - val_accuracy: 0.8675\n",
            "Epoch 498/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 0.9768 - val_loss: 2.9852 - val_accuracy: 0.8675\n",
            "Epoch 499/500\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.0481 - accuracy: 0.9817 - val_loss: 3.0123 - val_accuracy: 0.8644\n",
            "Epoch 500/500\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.0540 - accuracy: 0.9793 - val_loss: 3.3081 - val_accuracy: 0.8659\n",
            "21/21 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.89      0.93       622\n",
            "           1       0.09      0.26      0.14        27\n",
            "\n",
            "    accuracy                           0.87       649\n",
            "   macro avg       0.53      0.58      0.53       649\n",
            "weighted avg       0.93      0.87      0.89       649\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8659476117103235"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3-2 ANN - Combination SMOTE with PCA **"
      ],
      "metadata": {
        "id": "NqKzaZCxA9nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "smote = SMOTE(random_state=16)\n",
        "X_smote_dnn, y_smote_dnn = smote.fit_resample(x, y)\n",
        "\n",
        "# Standardize the data before applying PCA\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "X_scaled = scaler.fit_transform(X_smote_dnn)\n",
        "\n",
        "\n",
        "# Applying PCA\n",
        "num_components = 4\n",
        "pca = PCA(n_components=num_components)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "#X_test_pca = pca.fit_transform(X_test_dnn)\n",
        "# X_pca now contains the transformed features after applying SMOTE and PCA\n",
        "\n",
        "X_train_pca, X_test_pca, y_train_dnn, y_test_dnn = train_test_split(X_pca,y_smote_dnn,test_size=0.2, random_state=16)\n",
        "\n",
        "\n",
        "\n",
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=6,activation = 'relu'))\n",
        "#ann.add(Dropout(rate=0.3))\n",
        "ann.add(tf.keras.layers.Dense(units=50,activation = 'relu'))\n",
        "#ann.add(Dropout(rate=0.3))\n",
        "ann.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
        "#ann.add(Dropout(rate=0.3))\n",
        "ann.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
        "#ann.add(Dropout(rate=0.3))\n",
        "ann.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
        "#ann.add(Dropout(rate=0.3))\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "#ann.add(Dropout(rate=0.3))\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "ann.fit(X_train_pca,y_train_dnn, batch_size=12,epochs=750, validation_data=(X_test_pca, y_test_dnn))\n",
        "\n",
        "prediction = ann.predict(X_test_pca)\n",
        "prediction_dnn = [1 if p > 0.5 else 0 for p in prediction]\n",
        "\n",
        "print(classification_report(y_test_dnn, prediction_dnn))\n",
        "accuracy_score(y_test_dnn, prediction_dnn)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2dmHT7zwOPf",
        "outputId": "183a12f5-8685-4719-e185-943c31188f1b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/750\n",
            "414/414 [==============================] - 3s 4ms/step - loss: 0.5848 - accuracy: 0.6765 - val_loss: 0.5337 - val_accuracy: 0.7110\n",
            "Epoch 2/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.5243 - accuracy: 0.7250 - val_loss: 0.5136 - val_accuracy: 0.7182\n",
            "Epoch 3/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.5146 - accuracy: 0.7295 - val_loss: 0.5023 - val_accuracy: 0.7424\n",
            "Epoch 4/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.5036 - accuracy: 0.7369 - val_loss: 0.5178 - val_accuracy: 0.7182\n",
            "Epoch 5/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4996 - accuracy: 0.7353 - val_loss: 0.4917 - val_accuracy: 0.7383\n",
            "Epoch 6/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4927 - accuracy: 0.7395 - val_loss: 0.4884 - val_accuracy: 0.7488\n",
            "Epoch 7/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4902 - accuracy: 0.7413 - val_loss: 0.5025 - val_accuracy: 0.7206\n",
            "Epoch 8/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4834 - accuracy: 0.7454 - val_loss: 0.4745 - val_accuracy: 0.7689\n",
            "Epoch 9/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4804 - accuracy: 0.7462 - val_loss: 0.4711 - val_accuracy: 0.7625\n",
            "Epoch 10/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.4731 - accuracy: 0.7536 - val_loss: 0.4645 - val_accuracy: 0.7560\n",
            "Epoch 11/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.4686 - accuracy: 0.7564 - val_loss: 0.4689 - val_accuracy: 0.7625\n",
            "Epoch 12/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4680 - accuracy: 0.7522 - val_loss: 0.4802 - val_accuracy: 0.7560\n",
            "Epoch 13/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4678 - accuracy: 0.7532 - val_loss: 0.4625 - val_accuracy: 0.7520\n",
            "Epoch 14/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4606 - accuracy: 0.7605 - val_loss: 0.4927 - val_accuracy: 0.7335\n",
            "Epoch 15/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4586 - accuracy: 0.7615 - val_loss: 0.4692 - val_accuracy: 0.7528\n",
            "Epoch 16/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4553 - accuracy: 0.7645 - val_loss: 0.4725 - val_accuracy: 0.7625\n",
            "Epoch 17/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4549 - accuracy: 0.7528 - val_loss: 0.4473 - val_accuracy: 0.7657\n",
            "Epoch 18/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.4517 - accuracy: 0.7655 - val_loss: 0.4423 - val_accuracy: 0.7697\n",
            "Epoch 19/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.4483 - accuracy: 0.7673 - val_loss: 0.4541 - val_accuracy: 0.7617\n",
            "Epoch 20/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4469 - accuracy: 0.7701 - val_loss: 0.4661 - val_accuracy: 0.7689\n",
            "Epoch 21/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4471 - accuracy: 0.7643 - val_loss: 0.4379 - val_accuracy: 0.7738\n",
            "Epoch 22/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4422 - accuracy: 0.7715 - val_loss: 0.4452 - val_accuracy: 0.7536\n",
            "Epoch 23/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4423 - accuracy: 0.7637 - val_loss: 0.4383 - val_accuracy: 0.7552\n",
            "Epoch 24/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4376 - accuracy: 0.7754 - val_loss: 0.4451 - val_accuracy: 0.7593\n",
            "Epoch 25/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.4359 - accuracy: 0.7691 - val_loss: 0.4453 - val_accuracy: 0.7601\n",
            "Epoch 26/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.4339 - accuracy: 0.7792 - val_loss: 0.4683 - val_accuracy: 0.7448\n",
            "Epoch 27/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4314 - accuracy: 0.7776 - val_loss: 0.4516 - val_accuracy: 0.7738\n",
            "Epoch 28/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4323 - accuracy: 0.7782 - val_loss: 0.4532 - val_accuracy: 0.7641\n",
            "Epoch 29/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4283 - accuracy: 0.7814 - val_loss: 0.4542 - val_accuracy: 0.7504\n",
            "Epoch 30/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4253 - accuracy: 0.7798 - val_loss: 0.4468 - val_accuracy: 0.7713\n",
            "Epoch 31/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4227 - accuracy: 0.7824 - val_loss: 0.4677 - val_accuracy: 0.7391\n",
            "Epoch 32/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4272 - accuracy: 0.7764 - val_loss: 0.4578 - val_accuracy: 0.7536\n",
            "Epoch 33/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.4182 - accuracy: 0.7844 - val_loss: 0.4321 - val_accuracy: 0.7721\n",
            "Epoch 34/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.4186 - accuracy: 0.7860 - val_loss: 0.4456 - val_accuracy: 0.7617\n",
            "Epoch 35/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.4128 - accuracy: 0.7941 - val_loss: 0.4472 - val_accuracy: 0.7705\n",
            "Epoch 36/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4109 - accuracy: 0.7931 - val_loss: 0.4287 - val_accuracy: 0.7738\n",
            "Epoch 37/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4114 - accuracy: 0.7880 - val_loss: 0.4342 - val_accuracy: 0.7770\n",
            "Epoch 38/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4055 - accuracy: 0.7919 - val_loss: 0.4462 - val_accuracy: 0.7689\n",
            "Epoch 39/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4054 - accuracy: 0.7911 - val_loss: 0.4688 - val_accuracy: 0.7617\n",
            "Epoch 40/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.4034 - accuracy: 0.8005 - val_loss: 0.4385 - val_accuracy: 0.7705\n",
            "Epoch 41/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.3976 - accuracy: 0.8013 - val_loss: 0.4354 - val_accuracy: 0.7721\n",
            "Epoch 42/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.3992 - accuracy: 0.8007 - val_loss: 0.4533 - val_accuracy: 0.7585\n",
            "Epoch 43/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3958 - accuracy: 0.8025 - val_loss: 0.4876 - val_accuracy: 0.7560\n",
            "Epoch 44/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3877 - accuracy: 0.8066 - val_loss: 0.4339 - val_accuracy: 0.7681\n",
            "Epoch 45/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3904 - accuracy: 0.8064 - val_loss: 0.4317 - val_accuracy: 0.7786\n",
            "Epoch 46/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3887 - accuracy: 0.8033 - val_loss: 0.4492 - val_accuracy: 0.7649\n",
            "Epoch 47/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3871 - accuracy: 0.8068 - val_loss: 0.4431 - val_accuracy: 0.7625\n",
            "Epoch 48/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.3848 - accuracy: 0.8082 - val_loss: 0.4316 - val_accuracy: 0.7899\n",
            "Epoch 49/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.3775 - accuracy: 0.8120 - val_loss: 0.4136 - val_accuracy: 0.7858\n",
            "Epoch 50/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.3810 - accuracy: 0.8110 - val_loss: 0.4119 - val_accuracy: 0.7971\n",
            "Epoch 51/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3762 - accuracy: 0.8120 - val_loss: 0.4275 - val_accuracy: 0.7778\n",
            "Epoch 52/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3778 - accuracy: 0.8112 - val_loss: 0.4144 - val_accuracy: 0.7899\n",
            "Epoch 53/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3753 - accuracy: 0.8205 - val_loss: 0.4039 - val_accuracy: 0.8011\n",
            "Epoch 54/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3727 - accuracy: 0.8158 - val_loss: 0.4210 - val_accuracy: 0.7874\n",
            "Epoch 55/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3725 - accuracy: 0.8158 - val_loss: 0.4324 - val_accuracy: 0.7770\n",
            "Epoch 56/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.3686 - accuracy: 0.8211 - val_loss: 0.4101 - val_accuracy: 0.7963\n",
            "Epoch 57/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.3643 - accuracy: 0.8287 - val_loss: 0.4190 - val_accuracy: 0.7995\n",
            "Epoch 58/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.3639 - accuracy: 0.8237 - val_loss: 0.4076 - val_accuracy: 0.8092\n",
            "Epoch 59/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3614 - accuracy: 0.8249 - val_loss: 0.3999 - val_accuracy: 0.8011\n",
            "Epoch 60/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3602 - accuracy: 0.8241 - val_loss: 0.4206 - val_accuracy: 0.8035\n",
            "Epoch 61/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3573 - accuracy: 0.8200 - val_loss: 0.4225 - val_accuracy: 0.7834\n",
            "Epoch 62/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.8297 - val_loss: 0.3993 - val_accuracy: 0.8092\n",
            "Epoch 63/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.3541 - accuracy: 0.8261 - val_loss: 0.4810 - val_accuracy: 0.7786\n",
            "Epoch 64/750\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.3519 - accuracy: 0.8277 - val_loss: 0.4015 - val_accuracy: 0.8052\n",
            "Epoch 65/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3568 - accuracy: 0.8271 - val_loss: 0.3922 - val_accuracy: 0.8196\n",
            "Epoch 66/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3534 - accuracy: 0.8241 - val_loss: 0.4020 - val_accuracy: 0.8148\n",
            "Epoch 67/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3442 - accuracy: 0.8291 - val_loss: 0.4163 - val_accuracy: 0.7931\n",
            "Epoch 68/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3431 - accuracy: 0.8376 - val_loss: 0.4161 - val_accuracy: 0.7955\n",
            "Epoch 69/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3462 - accuracy: 0.8323 - val_loss: 0.3850 - val_accuracy: 0.8068\n",
            "Epoch 70/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3443 - accuracy: 0.8331 - val_loss: 0.3940 - val_accuracy: 0.8196\n",
            "Epoch 71/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.3385 - accuracy: 0.8355 - val_loss: 0.3919 - val_accuracy: 0.8205\n",
            "Epoch 72/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.3385 - accuracy: 0.8388 - val_loss: 0.3893 - val_accuracy: 0.8205\n",
            "Epoch 73/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3348 - accuracy: 0.8349 - val_loss: 0.3828 - val_accuracy: 0.8148\n",
            "Epoch 74/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3384 - accuracy: 0.8323 - val_loss: 0.4124 - val_accuracy: 0.7979\n",
            "Epoch 75/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3389 - accuracy: 0.8335 - val_loss: 0.4043 - val_accuracy: 0.8084\n",
            "Epoch 76/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3357 - accuracy: 0.8434 - val_loss: 0.3890 - val_accuracy: 0.8164\n",
            "Epoch 77/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3381 - accuracy: 0.8353 - val_loss: 0.3899 - val_accuracy: 0.8156\n",
            "Epoch 78/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.3254 - accuracy: 0.8450 - val_loss: 0.3983 - val_accuracy: 0.8124\n",
            "Epoch 79/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.3284 - accuracy: 0.8448 - val_loss: 0.4067 - val_accuracy: 0.8003\n",
            "Epoch 80/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3289 - accuracy: 0.8404 - val_loss: 0.3826 - val_accuracy: 0.8188\n",
            "Epoch 81/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3257 - accuracy: 0.8446 - val_loss: 0.4081 - val_accuracy: 0.8132\n",
            "Epoch 82/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3226 - accuracy: 0.8456 - val_loss: 0.3925 - val_accuracy: 0.8261\n",
            "Epoch 83/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.3203 - accuracy: 0.8416 - val_loss: 0.3616 - val_accuracy: 0.8269\n",
            "Epoch 84/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.3202 - accuracy: 0.8502 - val_loss: 0.3947 - val_accuracy: 0.8132\n",
            "Epoch 85/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3173 - accuracy: 0.8494 - val_loss: 0.3902 - val_accuracy: 0.8293\n",
            "Epoch 86/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.3194 - accuracy: 0.8468 - val_loss: 0.3719 - val_accuracy: 0.8196\n",
            "Epoch 87/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.3169 - accuracy: 0.8480 - val_loss: 0.3688 - val_accuracy: 0.8325\n",
            "Epoch 88/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3188 - accuracy: 0.8464 - val_loss: 0.3753 - val_accuracy: 0.8221\n",
            "Epoch 89/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3136 - accuracy: 0.8468 - val_loss: 0.3694 - val_accuracy: 0.8205\n",
            "Epoch 90/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3166 - accuracy: 0.8488 - val_loss: 0.3756 - val_accuracy: 0.8269\n",
            "Epoch 91/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3067 - accuracy: 0.8492 - val_loss: 0.3798 - val_accuracy: 0.8229\n",
            "Epoch 92/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3146 - accuracy: 0.8496 - val_loss: 0.3554 - val_accuracy: 0.8374\n",
            "Epoch 93/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.3028 - accuracy: 0.8537 - val_loss: 0.3767 - val_accuracy: 0.8293\n",
            "Epoch 94/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.3087 - accuracy: 0.8523 - val_loss: 0.3767 - val_accuracy: 0.8221\n",
            "Epoch 95/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.3087 - accuracy: 0.8521 - val_loss: 0.3691 - val_accuracy: 0.8333\n",
            "Epoch 96/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.3064 - accuracy: 0.8547 - val_loss: 0.3890 - val_accuracy: 0.8180\n",
            "Epoch 97/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.3099 - accuracy: 0.8549 - val_loss: 0.3949 - val_accuracy: 0.8180\n",
            "Epoch 98/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.3096 - accuracy: 0.8490 - val_loss: 0.3994 - val_accuracy: 0.8116\n",
            "Epoch 99/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.3010 - accuracy: 0.8593 - val_loss: 0.3848 - val_accuracy: 0.8301\n",
            "Epoch 100/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.3025 - accuracy: 0.8603 - val_loss: 0.4027 - val_accuracy: 0.8124\n",
            "Epoch 101/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.3015 - accuracy: 0.8539 - val_loss: 0.3690 - val_accuracy: 0.8317\n",
            "Epoch 102/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2986 - accuracy: 0.8541 - val_loss: 0.3659 - val_accuracy: 0.8261\n",
            "Epoch 103/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2922 - accuracy: 0.8605 - val_loss: 0.3797 - val_accuracy: 0.8237\n",
            "Epoch 104/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2990 - accuracy: 0.8559 - val_loss: 0.3654 - val_accuracy: 0.8333\n",
            "Epoch 105/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2970 - accuracy: 0.8553 - val_loss: 0.4125 - val_accuracy: 0.8164\n",
            "Epoch 106/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2936 - accuracy: 0.8617 - val_loss: 0.3757 - val_accuracy: 0.8357\n",
            "Epoch 107/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2962 - accuracy: 0.8563 - val_loss: 0.3920 - val_accuracy: 0.8188\n",
            "Epoch 108/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2954 - accuracy: 0.8603 - val_loss: 0.3712 - val_accuracy: 0.8333\n",
            "Epoch 109/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2912 - accuracy: 0.8609 - val_loss: 0.3576 - val_accuracy: 0.8398\n",
            "Epoch 110/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2936 - accuracy: 0.8639 - val_loss: 0.3734 - val_accuracy: 0.8285\n",
            "Epoch 111/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2919 - accuracy: 0.8619 - val_loss: 0.3825 - val_accuracy: 0.8253\n",
            "Epoch 112/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2838 - accuracy: 0.8619 - val_loss: 0.3947 - val_accuracy: 0.8277\n",
            "Epoch 113/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2905 - accuracy: 0.8617 - val_loss: 0.3809 - val_accuracy: 0.8229\n",
            "Epoch 114/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2821 - accuracy: 0.8684 - val_loss: 0.3981 - val_accuracy: 0.8164\n",
            "Epoch 115/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2894 - accuracy: 0.8641 - val_loss: 0.3904 - val_accuracy: 0.8253\n",
            "Epoch 116/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2822 - accuracy: 0.8674 - val_loss: 0.3916 - val_accuracy: 0.8205\n",
            "Epoch 117/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2896 - accuracy: 0.8601 - val_loss: 0.3551 - val_accuracy: 0.8414\n",
            "Epoch 118/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2868 - accuracy: 0.8621 - val_loss: 0.3665 - val_accuracy: 0.8317\n",
            "Epoch 119/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2802 - accuracy: 0.8698 - val_loss: 0.3712 - val_accuracy: 0.8196\n",
            "Epoch 120/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2796 - accuracy: 0.8653 - val_loss: 0.3678 - val_accuracy: 0.8301\n",
            "Epoch 121/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2839 - accuracy: 0.8639 - val_loss: 0.3913 - val_accuracy: 0.8205\n",
            "Epoch 122/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2824 - accuracy: 0.8601 - val_loss: 0.3537 - val_accuracy: 0.8406\n",
            "Epoch 123/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2784 - accuracy: 0.8633 - val_loss: 0.3567 - val_accuracy: 0.8309\n",
            "Epoch 124/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2769 - accuracy: 0.8659 - val_loss: 0.3731 - val_accuracy: 0.8253\n",
            "Epoch 125/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.8629 - val_loss: 0.3889 - val_accuracy: 0.8164\n",
            "Epoch 126/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2712 - accuracy: 0.8724 - val_loss: 0.4058 - val_accuracy: 0.8293\n",
            "Epoch 127/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2841 - accuracy: 0.8635 - val_loss: 0.3485 - val_accuracy: 0.8494\n",
            "Epoch 128/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2707 - accuracy: 0.8714 - val_loss: 0.3691 - val_accuracy: 0.8317\n",
            "Epoch 129/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2695 - accuracy: 0.8736 - val_loss: 0.4605 - val_accuracy: 0.8084\n",
            "Epoch 130/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2756 - accuracy: 0.8700 - val_loss: 0.3616 - val_accuracy: 0.8382\n",
            "Epoch 131/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2733 - accuracy: 0.8716 - val_loss: 0.3682 - val_accuracy: 0.8374\n",
            "Epoch 132/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2692 - accuracy: 0.8698 - val_loss: 0.3601 - val_accuracy: 0.8325\n",
            "Epoch 133/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2724 - accuracy: 0.8720 - val_loss: 0.3797 - val_accuracy: 0.8213\n",
            "Epoch 134/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2647 - accuracy: 0.8762 - val_loss: 0.4031 - val_accuracy: 0.8108\n",
            "Epoch 135/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2740 - accuracy: 0.8718 - val_loss: 0.3490 - val_accuracy: 0.8470\n",
            "Epoch 136/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2668 - accuracy: 0.8706 - val_loss: 0.3941 - val_accuracy: 0.8374\n",
            "Epoch 137/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2729 - accuracy: 0.8746 - val_loss: 0.4479 - val_accuracy: 0.8019\n",
            "Epoch 138/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2674 - accuracy: 0.8734 - val_loss: 0.3970 - val_accuracy: 0.8285\n",
            "Epoch 139/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2658 - accuracy: 0.8722 - val_loss: 0.3756 - val_accuracy: 0.8333\n",
            "Epoch 140/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2567 - accuracy: 0.8762 - val_loss: 0.3944 - val_accuracy: 0.8374\n",
            "Epoch 141/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2643 - accuracy: 0.8748 - val_loss: 0.4071 - val_accuracy: 0.8293\n",
            "Epoch 142/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2604 - accuracy: 0.8772 - val_loss: 0.3926 - val_accuracy: 0.8317\n",
            "Epoch 143/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2576 - accuracy: 0.8772 - val_loss: 0.3701 - val_accuracy: 0.8374\n",
            "Epoch 144/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2549 - accuracy: 0.8790 - val_loss: 0.3940 - val_accuracy: 0.8349\n",
            "Epoch 145/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2734 - accuracy: 0.8716 - val_loss: 0.3829 - val_accuracy: 0.8414\n",
            "Epoch 146/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2501 - accuracy: 0.8784 - val_loss: 0.4000 - val_accuracy: 0.8333\n",
            "Epoch 147/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2557 - accuracy: 0.8752 - val_loss: 0.3902 - val_accuracy: 0.8366\n",
            "Epoch 148/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2588 - accuracy: 0.8778 - val_loss: 0.3851 - val_accuracy: 0.8374\n",
            "Epoch 149/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2539 - accuracy: 0.8774 - val_loss: 0.3888 - val_accuracy: 0.8245\n",
            "Epoch 150/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2607 - accuracy: 0.8762 - val_loss: 0.3681 - val_accuracy: 0.8462\n",
            "Epoch 151/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2527 - accuracy: 0.8780 - val_loss: 0.3794 - val_accuracy: 0.8374\n",
            "Epoch 152/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2493 - accuracy: 0.8806 - val_loss: 0.3705 - val_accuracy: 0.8551\n",
            "Epoch 153/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2608 - accuracy: 0.8788 - val_loss: 0.3639 - val_accuracy: 0.8422\n",
            "Epoch 154/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2420 - accuracy: 0.8879 - val_loss: 0.3996 - val_accuracy: 0.8478\n",
            "Epoch 155/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2517 - accuracy: 0.8794 - val_loss: 0.3882 - val_accuracy: 0.8502\n",
            "Epoch 156/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2480 - accuracy: 0.8798 - val_loss: 0.3895 - val_accuracy: 0.8414\n",
            "Epoch 157/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2601 - accuracy: 0.8782 - val_loss: 0.3725 - val_accuracy: 0.8382\n",
            "Epoch 158/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2431 - accuracy: 0.8833 - val_loss: 0.3768 - val_accuracy: 0.8454\n",
            "Epoch 159/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2461 - accuracy: 0.8794 - val_loss: 0.3633 - val_accuracy: 0.8543\n",
            "Epoch 160/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2446 - accuracy: 0.8833 - val_loss: 0.3665 - val_accuracy: 0.8527\n",
            "Epoch 161/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2517 - accuracy: 0.8772 - val_loss: 0.3543 - val_accuracy: 0.8519\n",
            "Epoch 162/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2504 - accuracy: 0.8818 - val_loss: 0.3757 - val_accuracy: 0.8510\n",
            "Epoch 163/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2432 - accuracy: 0.8839 - val_loss: 0.4282 - val_accuracy: 0.8366\n",
            "Epoch 164/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2425 - accuracy: 0.8879 - val_loss: 0.3701 - val_accuracy: 0.8510\n",
            "Epoch 165/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2469 - accuracy: 0.8837 - val_loss: 0.3721 - val_accuracy: 0.8398\n",
            "Epoch 166/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2467 - accuracy: 0.8837 - val_loss: 0.3828 - val_accuracy: 0.8261\n",
            "Epoch 167/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2431 - accuracy: 0.8875 - val_loss: 0.3629 - val_accuracy: 0.8519\n",
            "Epoch 168/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2441 - accuracy: 0.8855 - val_loss: 0.3841 - val_accuracy: 0.8462\n",
            "Epoch 169/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2391 - accuracy: 0.8841 - val_loss: 0.3701 - val_accuracy: 0.8446\n",
            "Epoch 170/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2339 - accuracy: 0.8903 - val_loss: 0.3669 - val_accuracy: 0.8510\n",
            "Epoch 171/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2396 - accuracy: 0.8869 - val_loss: 0.4363 - val_accuracy: 0.8293\n",
            "Epoch 172/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2413 - accuracy: 0.8879 - val_loss: 0.3981 - val_accuracy: 0.8180\n",
            "Epoch 173/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2403 - accuracy: 0.8859 - val_loss: 0.4008 - val_accuracy: 0.8325\n",
            "Epoch 174/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2450 - accuracy: 0.8831 - val_loss: 0.3935 - val_accuracy: 0.8502\n",
            "Epoch 175/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2455 - accuracy: 0.8849 - val_loss: 0.3770 - val_accuracy: 0.8519\n",
            "Epoch 176/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2370 - accuracy: 0.8903 - val_loss: 0.3890 - val_accuracy: 0.8438\n",
            "Epoch 177/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2311 - accuracy: 0.8871 - val_loss: 0.3812 - val_accuracy: 0.8551\n",
            "Epoch 178/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2345 - accuracy: 0.8875 - val_loss: 0.3879 - val_accuracy: 0.8414\n",
            "Epoch 179/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2401 - accuracy: 0.8875 - val_loss: 0.3902 - val_accuracy: 0.8470\n",
            "Epoch 180/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2346 - accuracy: 0.8883 - val_loss: 0.3744 - val_accuracy: 0.8454\n",
            "Epoch 181/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2386 - accuracy: 0.8889 - val_loss: 0.3976 - val_accuracy: 0.8390\n",
            "Epoch 182/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2345 - accuracy: 0.8851 - val_loss: 0.3646 - val_accuracy: 0.8470\n",
            "Epoch 183/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2314 - accuracy: 0.8899 - val_loss: 0.3603 - val_accuracy: 0.8575\n",
            "Epoch 184/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2345 - accuracy: 0.8873 - val_loss: 0.3818 - val_accuracy: 0.8454\n",
            "Epoch 185/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2298 - accuracy: 0.8939 - val_loss: 0.3869 - val_accuracy: 0.8430\n",
            "Epoch 186/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2364 - accuracy: 0.8843 - val_loss: 0.3755 - val_accuracy: 0.8631\n",
            "Epoch 187/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2146 - accuracy: 0.8965 - val_loss: 0.4084 - val_accuracy: 0.8374\n",
            "Epoch 188/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2420 - accuracy: 0.8847 - val_loss: 0.3911 - val_accuracy: 0.8414\n",
            "Epoch 189/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2237 - accuracy: 0.8949 - val_loss: 0.3972 - val_accuracy: 0.8398\n",
            "Epoch 190/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2321 - accuracy: 0.8921 - val_loss: 0.3717 - val_accuracy: 0.8510\n",
            "Epoch 191/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2274 - accuracy: 0.8969 - val_loss: 0.4089 - val_accuracy: 0.8414\n",
            "Epoch 192/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2373 - accuracy: 0.8887 - val_loss: 0.3798 - val_accuracy: 0.8510\n",
            "Epoch 193/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2252 - accuracy: 0.8943 - val_loss: 0.3562 - val_accuracy: 0.8599\n",
            "Epoch 194/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2192 - accuracy: 0.8969 - val_loss: 0.3799 - val_accuracy: 0.8583\n",
            "Epoch 195/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2203 - accuracy: 0.8949 - val_loss: 0.4308 - val_accuracy: 0.8382\n",
            "Epoch 196/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2197 - accuracy: 0.8961 - val_loss: 0.3989 - val_accuracy: 0.8575\n",
            "Epoch 197/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2244 - accuracy: 0.8937 - val_loss: 0.3844 - val_accuracy: 0.8527\n",
            "Epoch 198/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2307 - accuracy: 0.8925 - val_loss: 0.3604 - val_accuracy: 0.8639\n",
            "Epoch 199/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2169 - accuracy: 0.8986 - val_loss: 0.3925 - val_accuracy: 0.8398\n",
            "Epoch 200/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2222 - accuracy: 0.8937 - val_loss: 0.3712 - val_accuracy: 0.8567\n",
            "Epoch 201/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2177 - accuracy: 0.8981 - val_loss: 0.3868 - val_accuracy: 0.8543\n",
            "Epoch 202/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2113 - accuracy: 0.9038 - val_loss: 0.3617 - val_accuracy: 0.8543\n",
            "Epoch 203/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2161 - accuracy: 0.8949 - val_loss: 0.4191 - val_accuracy: 0.8366\n",
            "Epoch 204/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2242 - accuracy: 0.8967 - val_loss: 0.3525 - val_accuracy: 0.8655\n",
            "Epoch 205/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2171 - accuracy: 0.8994 - val_loss: 0.3675 - val_accuracy: 0.8680\n",
            "Epoch 206/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2223 - accuracy: 0.8939 - val_loss: 0.3552 - val_accuracy: 0.8631\n",
            "Epoch 207/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2075 - accuracy: 0.9060 - val_loss: 0.4322 - val_accuracy: 0.8430\n",
            "Epoch 208/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2150 - accuracy: 0.8983 - val_loss: 0.4294 - val_accuracy: 0.8398\n",
            "Epoch 209/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2164 - accuracy: 0.9012 - val_loss: 0.3859 - val_accuracy: 0.8623\n",
            "Epoch 210/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2106 - accuracy: 0.8967 - val_loss: 0.3997 - val_accuracy: 0.8454\n",
            "Epoch 211/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.2196 - accuracy: 0.8937 - val_loss: 0.3682 - val_accuracy: 0.8680\n",
            "Epoch 212/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2186 - accuracy: 0.8951 - val_loss: 0.3942 - val_accuracy: 0.8390\n",
            "Epoch 213/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2135 - accuracy: 0.8981 - val_loss: 0.4126 - val_accuracy: 0.8454\n",
            "Epoch 214/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2141 - accuracy: 0.9024 - val_loss: 0.4032 - val_accuracy: 0.8591\n",
            "Epoch 215/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.2151 - accuracy: 0.8961 - val_loss: 0.4204 - val_accuracy: 0.8454\n",
            "Epoch 216/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2052 - accuracy: 0.9038 - val_loss: 0.4476 - val_accuracy: 0.8559\n",
            "Epoch 217/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2117 - accuracy: 0.9022 - val_loss: 0.4034 - val_accuracy: 0.8575\n",
            "Epoch 218/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2060 - accuracy: 0.9064 - val_loss: 0.3881 - val_accuracy: 0.8559\n",
            "Epoch 219/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2037 - accuracy: 0.9050 - val_loss: 0.4452 - val_accuracy: 0.8398\n",
            "Epoch 220/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2131 - accuracy: 0.8983 - val_loss: 0.3953 - val_accuracy: 0.8543\n",
            "Epoch 221/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2072 - accuracy: 0.9034 - val_loss: 0.3913 - val_accuracy: 0.8647\n",
            "Epoch 222/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2054 - accuracy: 0.9030 - val_loss: 0.5040 - val_accuracy: 0.8333\n",
            "Epoch 223/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2072 - accuracy: 0.9016 - val_loss: 0.4399 - val_accuracy: 0.8607\n",
            "Epoch 224/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2129 - accuracy: 0.9010 - val_loss: 0.4160 - val_accuracy: 0.8478\n",
            "Epoch 225/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2075 - accuracy: 0.9032 - val_loss: 0.4167 - val_accuracy: 0.8510\n",
            "Epoch 226/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2080 - accuracy: 0.9060 - val_loss: 0.4362 - val_accuracy: 0.8430\n",
            "Epoch 227/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2159 - accuracy: 0.8975 - val_loss: 0.3828 - val_accuracy: 0.8535\n",
            "Epoch 228/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2085 - accuracy: 0.9050 - val_loss: 0.3891 - val_accuracy: 0.8559\n",
            "Epoch 229/750\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.1993 - accuracy: 0.9088 - val_loss: 0.3970 - val_accuracy: 0.8575\n",
            "Epoch 230/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1981 - accuracy: 0.9042 - val_loss: 0.4140 - val_accuracy: 0.8559\n",
            "Epoch 231/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2146 - accuracy: 0.9030 - val_loss: 0.4185 - val_accuracy: 0.8438\n",
            "Epoch 232/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1992 - accuracy: 0.9060 - val_loss: 0.4023 - val_accuracy: 0.8414\n",
            "Epoch 233/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2093 - accuracy: 0.9052 - val_loss: 0.4054 - val_accuracy: 0.8591\n",
            "Epoch 234/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1896 - accuracy: 0.9128 - val_loss: 0.4186 - val_accuracy: 0.8655\n",
            "Epoch 235/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1946 - accuracy: 0.9102 - val_loss: 0.4218 - val_accuracy: 0.8486\n",
            "Epoch 236/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.1984 - accuracy: 0.9104 - val_loss: 0.4222 - val_accuracy: 0.8446\n",
            "Epoch 237/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1915 - accuracy: 0.9124 - val_loss: 0.4383 - val_accuracy: 0.8535\n",
            "Epoch 238/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2028 - accuracy: 0.9038 - val_loss: 0.3856 - val_accuracy: 0.8671\n",
            "Epoch 239/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1968 - accuracy: 0.9068 - val_loss: 0.4347 - val_accuracy: 0.8535\n",
            "Epoch 240/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1996 - accuracy: 0.9046 - val_loss: 0.4280 - val_accuracy: 0.8398\n",
            "Epoch 241/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1905 - accuracy: 0.9153 - val_loss: 0.4317 - val_accuracy: 0.8583\n",
            "Epoch 242/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1931 - accuracy: 0.9136 - val_loss: 0.4848 - val_accuracy: 0.8599\n",
            "Epoch 243/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1895 - accuracy: 0.9100 - val_loss: 0.4311 - val_accuracy: 0.8591\n",
            "Epoch 244/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2139 - accuracy: 0.9048 - val_loss: 0.4381 - val_accuracy: 0.8446\n",
            "Epoch 245/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1943 - accuracy: 0.9092 - val_loss: 0.4054 - val_accuracy: 0.8615\n",
            "Epoch 246/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1903 - accuracy: 0.9153 - val_loss: 0.4373 - val_accuracy: 0.8543\n",
            "Epoch 247/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1957 - accuracy: 0.9108 - val_loss: 0.4277 - val_accuracy: 0.8494\n",
            "Epoch 248/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1894 - accuracy: 0.9145 - val_loss: 0.4314 - val_accuracy: 0.8607\n",
            "Epoch 249/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1919 - accuracy: 0.9149 - val_loss: 0.4408 - val_accuracy: 0.8502\n",
            "Epoch 250/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2026 - accuracy: 0.9084 - val_loss: 0.4234 - val_accuracy: 0.8543\n",
            "Epoch 251/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.1869 - accuracy: 0.9177 - val_loss: 0.4210 - val_accuracy: 0.8543\n",
            "Epoch 252/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1863 - accuracy: 0.9149 - val_loss: 0.4382 - val_accuracy: 0.8510\n",
            "Epoch 253/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1899 - accuracy: 0.9134 - val_loss: 0.4329 - val_accuracy: 0.8591\n",
            "Epoch 254/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1904 - accuracy: 0.9140 - val_loss: 0.4327 - val_accuracy: 0.8414\n",
            "Epoch 255/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1839 - accuracy: 0.9163 - val_loss: 0.4481 - val_accuracy: 0.8535\n",
            "Epoch 256/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1948 - accuracy: 0.9094 - val_loss: 0.4304 - val_accuracy: 0.8494\n",
            "Epoch 257/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1927 - accuracy: 0.9102 - val_loss: 0.4286 - val_accuracy: 0.8478\n",
            "Epoch 258/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1940 - accuracy: 0.9096 - val_loss: 0.4030 - val_accuracy: 0.8663\n",
            "Epoch 259/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.1807 - accuracy: 0.9201 - val_loss: 0.3949 - val_accuracy: 0.8696\n",
            "Epoch 260/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1934 - accuracy: 0.9110 - val_loss: 0.4470 - val_accuracy: 0.8510\n",
            "Epoch 261/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2037 - accuracy: 0.9068 - val_loss: 0.4204 - val_accuracy: 0.8680\n",
            "Epoch 262/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1771 - accuracy: 0.9197 - val_loss: 0.4602 - val_accuracy: 0.8535\n",
            "Epoch 263/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1891 - accuracy: 0.9145 - val_loss: 0.4501 - val_accuracy: 0.8543\n",
            "Epoch 264/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1943 - accuracy: 0.9118 - val_loss: 0.4562 - val_accuracy: 0.8583\n",
            "Epoch 265/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1890 - accuracy: 0.9132 - val_loss: 0.4857 - val_accuracy: 0.8639\n",
            "Epoch 266/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1920 - accuracy: 0.9098 - val_loss: 0.4245 - val_accuracy: 0.8543\n",
            "Epoch 267/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.1834 - accuracy: 0.9163 - val_loss: 0.4440 - val_accuracy: 0.8639\n",
            "Epoch 268/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1888 - accuracy: 0.9110 - val_loss: 0.4826 - val_accuracy: 0.8438\n",
            "Epoch 269/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1824 - accuracy: 0.9181 - val_loss: 0.4281 - val_accuracy: 0.8591\n",
            "Epoch 270/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1786 - accuracy: 0.9185 - val_loss: 0.4717 - val_accuracy: 0.8519\n",
            "Epoch 271/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1843 - accuracy: 0.9169 - val_loss: 0.4778 - val_accuracy: 0.8462\n",
            "Epoch 272/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2050 - accuracy: 0.9094 - val_loss: 0.4265 - val_accuracy: 0.8615\n",
            "Epoch 273/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1883 - accuracy: 0.9120 - val_loss: 0.4346 - val_accuracy: 0.8696\n",
            "Epoch 274/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1930 - accuracy: 0.9110 - val_loss: 0.4431 - val_accuracy: 0.8567\n",
            "Epoch 275/750\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.1877 - accuracy: 0.9138 - val_loss: 0.4484 - val_accuracy: 0.8583\n",
            "Epoch 276/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1752 - accuracy: 0.9177 - val_loss: 0.5107 - val_accuracy: 0.8519\n",
            "Epoch 277/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1785 - accuracy: 0.9163 - val_loss: 0.4278 - val_accuracy: 0.8527\n",
            "Epoch 278/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1954 - accuracy: 0.9100 - val_loss: 0.4320 - val_accuracy: 0.8559\n",
            "Epoch 279/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1744 - accuracy: 0.9209 - val_loss: 0.4522 - val_accuracy: 0.8535\n",
            "Epoch 280/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1867 - accuracy: 0.9175 - val_loss: 0.4671 - val_accuracy: 0.8438\n",
            "Epoch 281/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.2059 - accuracy: 0.9060 - val_loss: 0.4137 - val_accuracy: 0.8655\n",
            "Epoch 282/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1916 - accuracy: 0.9136 - val_loss: 0.4226 - val_accuracy: 0.8655\n",
            "Epoch 283/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1729 - accuracy: 0.9213 - val_loss: 0.4466 - val_accuracy: 0.8647\n",
            "Epoch 284/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1762 - accuracy: 0.9215 - val_loss: 0.4429 - val_accuracy: 0.8551\n",
            "Epoch 285/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1791 - accuracy: 0.9167 - val_loss: 0.4812 - val_accuracy: 0.8502\n",
            "Epoch 286/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1850 - accuracy: 0.9167 - val_loss: 0.4657 - val_accuracy: 0.8486\n",
            "Epoch 287/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1842 - accuracy: 0.9173 - val_loss: 0.4337 - val_accuracy: 0.8583\n",
            "Epoch 288/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1796 - accuracy: 0.9153 - val_loss: 0.5957 - val_accuracy: 0.8180\n",
            "Epoch 289/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1783 - accuracy: 0.9207 - val_loss: 0.4911 - val_accuracy: 0.8559\n",
            "Epoch 290/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1859 - accuracy: 0.9167 - val_loss: 0.4188 - val_accuracy: 0.8446\n",
            "Epoch 291/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1753 - accuracy: 0.9191 - val_loss: 0.5578 - val_accuracy: 0.8470\n",
            "Epoch 292/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1818 - accuracy: 0.9185 - val_loss: 0.4489 - val_accuracy: 0.8663\n",
            "Epoch 293/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1839 - accuracy: 0.9179 - val_loss: 0.4451 - val_accuracy: 0.8567\n",
            "Epoch 294/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1738 - accuracy: 0.9255 - val_loss: 0.5076 - val_accuracy: 0.8583\n",
            "Epoch 295/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1799 - accuracy: 0.9189 - val_loss: 0.4473 - val_accuracy: 0.8655\n",
            "Epoch 296/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1748 - accuracy: 0.9227 - val_loss: 0.4743 - val_accuracy: 0.8502\n",
            "Epoch 297/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1706 - accuracy: 0.9221 - val_loss: 0.5522 - val_accuracy: 0.8478\n",
            "Epoch 298/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1787 - accuracy: 0.9201 - val_loss: 0.4281 - val_accuracy: 0.8655\n",
            "Epoch 299/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1677 - accuracy: 0.9243 - val_loss: 0.4223 - val_accuracy: 0.8647\n",
            "Epoch 300/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1923 - accuracy: 0.9138 - val_loss: 0.4405 - val_accuracy: 0.8607\n",
            "Epoch 301/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1765 - accuracy: 0.9177 - val_loss: 0.4459 - val_accuracy: 0.8623\n",
            "Epoch 302/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1807 - accuracy: 0.9179 - val_loss: 0.4373 - val_accuracy: 0.8631\n",
            "Epoch 303/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1711 - accuracy: 0.9243 - val_loss: 0.4501 - val_accuracy: 0.8688\n",
            "Epoch 304/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1689 - accuracy: 0.9237 - val_loss: 0.4749 - val_accuracy: 0.8607\n",
            "Epoch 305/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1979 - accuracy: 0.9100 - val_loss: 0.4313 - val_accuracy: 0.8575\n",
            "Epoch 306/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1670 - accuracy: 0.9243 - val_loss: 0.4347 - val_accuracy: 0.8712\n",
            "Epoch 307/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1787 - accuracy: 0.9205 - val_loss: 0.4455 - val_accuracy: 0.8535\n",
            "Epoch 308/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1590 - accuracy: 0.9265 - val_loss: 0.4498 - val_accuracy: 0.8599\n",
            "Epoch 309/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1718 - accuracy: 0.9209 - val_loss: 0.4437 - val_accuracy: 0.8599\n",
            "Epoch 310/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1751 - accuracy: 0.9239 - val_loss: 0.4572 - val_accuracy: 0.8655\n",
            "Epoch 311/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1650 - accuracy: 0.9241 - val_loss: 0.4870 - val_accuracy: 0.8615\n",
            "Epoch 312/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1768 - accuracy: 0.9213 - val_loss: 0.4254 - val_accuracy: 0.8631\n",
            "Epoch 313/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1694 - accuracy: 0.9241 - val_loss: 0.4135 - val_accuracy: 0.8712\n",
            "Epoch 314/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1774 - accuracy: 0.9223 - val_loss: 0.4642 - val_accuracy: 0.8607\n",
            "Epoch 315/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1777 - accuracy: 0.9209 - val_loss: 0.4810 - val_accuracy: 0.8567\n",
            "Epoch 316/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1780 - accuracy: 0.9213 - val_loss: 0.4633 - val_accuracy: 0.8599\n",
            "Epoch 317/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1817 - accuracy: 0.9163 - val_loss: 0.4531 - val_accuracy: 0.8591\n",
            "Epoch 318/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1713 - accuracy: 0.9231 - val_loss: 0.5058 - val_accuracy: 0.8559\n",
            "Epoch 319/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1740 - accuracy: 0.9237 - val_loss: 0.4536 - val_accuracy: 0.8599\n",
            "Epoch 320/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1644 - accuracy: 0.9219 - val_loss: 0.4400 - val_accuracy: 0.8688\n",
            "Epoch 321/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1856 - accuracy: 0.9233 - val_loss: 0.4524 - val_accuracy: 0.8567\n",
            "Epoch 322/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1623 - accuracy: 0.9283 - val_loss: 0.4563 - val_accuracy: 0.8623\n",
            "Epoch 323/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1661 - accuracy: 0.9231 - val_loss: 0.4840 - val_accuracy: 0.8583\n",
            "Epoch 324/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1789 - accuracy: 0.9207 - val_loss: 0.4554 - val_accuracy: 0.8607\n",
            "Epoch 325/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.2019 - accuracy: 0.9112 - val_loss: 0.4179 - val_accuracy: 0.8655\n",
            "Epoch 326/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1632 - accuracy: 0.9279 - val_loss: 0.4529 - val_accuracy: 0.8623\n",
            "Epoch 327/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1706 - accuracy: 0.9271 - val_loss: 0.4731 - val_accuracy: 0.8655\n",
            "Epoch 328/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1663 - accuracy: 0.9263 - val_loss: 0.4666 - val_accuracy: 0.8615\n",
            "Epoch 329/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1660 - accuracy: 0.9265 - val_loss: 0.4264 - val_accuracy: 0.8615\n",
            "Epoch 330/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1685 - accuracy: 0.9237 - val_loss: 0.4716 - val_accuracy: 0.8623\n",
            "Epoch 331/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1578 - accuracy: 0.9316 - val_loss: 0.5166 - val_accuracy: 0.8623\n",
            "Epoch 332/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1664 - accuracy: 0.9271 - val_loss: 0.5176 - val_accuracy: 0.8631\n",
            "Epoch 333/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.2116 - accuracy: 0.9096 - val_loss: 0.4377 - val_accuracy: 0.8607\n",
            "Epoch 334/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1607 - accuracy: 0.9277 - val_loss: 0.5176 - val_accuracy: 0.8591\n",
            "Epoch 335/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1676 - accuracy: 0.9251 - val_loss: 0.4834 - val_accuracy: 0.8647\n",
            "Epoch 336/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1584 - accuracy: 0.9287 - val_loss: 0.5087 - val_accuracy: 0.8639\n",
            "Epoch 337/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1726 - accuracy: 0.9217 - val_loss: 0.4750 - val_accuracy: 0.8575\n",
            "Epoch 338/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1581 - accuracy: 0.9310 - val_loss: 0.4355 - val_accuracy: 0.8607\n",
            "Epoch 339/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1557 - accuracy: 0.9275 - val_loss: 0.4834 - val_accuracy: 0.8655\n",
            "Epoch 340/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1565 - accuracy: 0.9300 - val_loss: 0.5004 - val_accuracy: 0.8639\n",
            "Epoch 341/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1631 - accuracy: 0.9261 - val_loss: 0.5108 - val_accuracy: 0.8615\n",
            "Epoch 342/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1889 - accuracy: 0.9209 - val_loss: 0.4517 - val_accuracy: 0.8398\n",
            "Epoch 343/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1743 - accuracy: 0.9255 - val_loss: 0.4677 - val_accuracy: 0.8543\n",
            "Epoch 344/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1744 - accuracy: 0.9251 - val_loss: 0.4701 - val_accuracy: 0.8559\n",
            "Epoch 345/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1532 - accuracy: 0.9273 - val_loss: 0.4364 - val_accuracy: 0.8704\n",
            "Epoch 346/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1580 - accuracy: 0.9261 - val_loss: 0.4729 - val_accuracy: 0.8559\n",
            "Epoch 347/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1652 - accuracy: 0.9287 - val_loss: 0.5069 - val_accuracy: 0.8494\n",
            "Epoch 348/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1675 - accuracy: 0.9267 - val_loss: 0.4902 - val_accuracy: 0.8623\n",
            "Epoch 349/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1794 - accuracy: 0.9187 - val_loss: 0.4452 - val_accuracy: 0.8462\n",
            "Epoch 350/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1645 - accuracy: 0.9259 - val_loss: 0.4332 - val_accuracy: 0.8599\n",
            "Epoch 351/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1649 - accuracy: 0.9213 - val_loss: 0.5188 - val_accuracy: 0.8583\n",
            "Epoch 352/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1675 - accuracy: 0.9269 - val_loss: 0.4919 - val_accuracy: 0.8527\n",
            "Epoch 353/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1505 - accuracy: 0.9308 - val_loss: 0.4367 - val_accuracy: 0.8680\n",
            "Epoch 354/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1658 - accuracy: 0.9283 - val_loss: 0.4131 - val_accuracy: 0.8575\n",
            "Epoch 355/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1535 - accuracy: 0.9332 - val_loss: 0.5129 - val_accuracy: 0.8688\n",
            "Epoch 356/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1721 - accuracy: 0.9245 - val_loss: 0.4881 - val_accuracy: 0.8510\n",
            "Epoch 357/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1570 - accuracy: 0.9289 - val_loss: 0.5089 - val_accuracy: 0.8591\n",
            "Epoch 358/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1823 - accuracy: 0.9249 - val_loss: 0.4652 - val_accuracy: 0.8567\n",
            "Epoch 359/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1581 - accuracy: 0.9320 - val_loss: 0.4547 - val_accuracy: 0.8712\n",
            "Epoch 360/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1598 - accuracy: 0.9265 - val_loss: 0.4654 - val_accuracy: 0.8712\n",
            "Epoch 361/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1691 - accuracy: 0.9267 - val_loss: 0.5069 - val_accuracy: 0.8647\n",
            "Epoch 362/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1509 - accuracy: 0.9316 - val_loss: 0.5125 - val_accuracy: 0.8535\n",
            "Epoch 363/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1744 - accuracy: 0.9221 - val_loss: 0.4221 - val_accuracy: 0.8583\n",
            "Epoch 364/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1509 - accuracy: 0.9320 - val_loss: 0.4957 - val_accuracy: 0.8591\n",
            "Epoch 365/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1716 - accuracy: 0.9257 - val_loss: 0.4836 - val_accuracy: 0.8623\n",
            "Epoch 366/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1675 - accuracy: 0.9253 - val_loss: 0.5091 - val_accuracy: 0.8551\n",
            "Epoch 367/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1513 - accuracy: 0.9338 - val_loss: 0.4906 - val_accuracy: 0.8583\n",
            "Epoch 368/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1623 - accuracy: 0.9279 - val_loss: 0.5008 - val_accuracy: 0.8736\n",
            "Epoch 369/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1562 - accuracy: 0.9304 - val_loss: 0.4797 - val_accuracy: 0.8728\n",
            "Epoch 370/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1579 - accuracy: 0.9279 - val_loss: 0.4655 - val_accuracy: 0.8696\n",
            "Epoch 371/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1444 - accuracy: 0.9378 - val_loss: 0.4845 - val_accuracy: 0.8655\n",
            "Epoch 372/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1634 - accuracy: 0.9257 - val_loss: 0.5523 - val_accuracy: 0.8607\n",
            "Epoch 373/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1547 - accuracy: 0.9326 - val_loss: 0.5367 - val_accuracy: 0.8623\n",
            "Epoch 374/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1620 - accuracy: 0.9273 - val_loss: 0.4245 - val_accuracy: 0.8696\n",
            "Epoch 375/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1456 - accuracy: 0.9330 - val_loss: 0.5138 - val_accuracy: 0.8680\n",
            "Epoch 376/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1503 - accuracy: 0.9314 - val_loss: 0.5007 - val_accuracy: 0.8639\n",
            "Epoch 377/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1523 - accuracy: 0.9328 - val_loss: 0.4804 - val_accuracy: 0.8671\n",
            "Epoch 378/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1545 - accuracy: 0.9283 - val_loss: 0.4936 - val_accuracy: 0.8663\n",
            "Epoch 379/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1657 - accuracy: 0.9277 - val_loss: 0.4480 - val_accuracy: 0.8728\n",
            "Epoch 380/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1541 - accuracy: 0.9308 - val_loss: 0.4212 - val_accuracy: 0.8808\n",
            "Epoch 381/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1431 - accuracy: 0.9360 - val_loss: 0.5051 - val_accuracy: 0.8671\n",
            "Epoch 382/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1748 - accuracy: 0.9233 - val_loss: 0.4902 - val_accuracy: 0.8680\n",
            "Epoch 383/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1555 - accuracy: 0.9306 - val_loss: 0.5019 - val_accuracy: 0.8599\n",
            "Epoch 384/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1520 - accuracy: 0.9324 - val_loss: 0.5012 - val_accuracy: 0.8720\n",
            "Epoch 385/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1512 - accuracy: 0.9316 - val_loss: 0.5004 - val_accuracy: 0.8760\n",
            "Epoch 386/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1664 - accuracy: 0.9283 - val_loss: 0.5922 - val_accuracy: 0.8301\n",
            "Epoch 387/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1646 - accuracy: 0.9304 - val_loss: 0.4756 - val_accuracy: 0.8575\n",
            "Epoch 388/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1351 - accuracy: 0.9386 - val_loss: 0.5412 - val_accuracy: 0.8663\n",
            "Epoch 389/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1571 - accuracy: 0.9340 - val_loss: 0.4563 - val_accuracy: 0.8543\n",
            "Epoch 390/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1590 - accuracy: 0.9322 - val_loss: 0.4631 - val_accuracy: 0.8519\n",
            "Epoch 391/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1732 - accuracy: 0.9247 - val_loss: 0.4786 - val_accuracy: 0.8551\n",
            "Epoch 392/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1449 - accuracy: 0.9344 - val_loss: 0.4934 - val_accuracy: 0.8728\n",
            "Epoch 393/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1554 - accuracy: 0.9308 - val_loss: 0.5200 - val_accuracy: 0.8607\n",
            "Epoch 394/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1480 - accuracy: 0.9322 - val_loss: 0.4530 - val_accuracy: 0.8792\n",
            "Epoch 395/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1417 - accuracy: 0.9370 - val_loss: 0.5205 - val_accuracy: 0.8696\n",
            "Epoch 396/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1508 - accuracy: 0.9310 - val_loss: 0.5937 - val_accuracy: 0.8470\n",
            "Epoch 397/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1504 - accuracy: 0.9334 - val_loss: 0.5411 - val_accuracy: 0.8567\n",
            "Epoch 398/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1602 - accuracy: 0.9308 - val_loss: 0.4699 - val_accuracy: 0.8760\n",
            "Epoch 399/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1723 - accuracy: 0.9271 - val_loss: 0.4807 - val_accuracy: 0.8647\n",
            "Epoch 400/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1447 - accuracy: 0.9332 - val_loss: 0.5350 - val_accuracy: 0.8559\n",
            "Epoch 401/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1334 - accuracy: 0.9416 - val_loss: 0.5069 - val_accuracy: 0.8784\n",
            "Epoch 402/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1622 - accuracy: 0.9293 - val_loss: 0.5066 - val_accuracy: 0.8575\n",
            "Epoch 403/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1526 - accuracy: 0.9300 - val_loss: 0.4733 - val_accuracy: 0.8776\n",
            "Epoch 404/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1469 - accuracy: 0.9342 - val_loss: 0.4674 - val_accuracy: 0.8800\n",
            "Epoch 405/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1544 - accuracy: 0.9326 - val_loss: 0.4577 - val_accuracy: 0.8680\n",
            "Epoch 406/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1486 - accuracy: 0.9344 - val_loss: 0.5280 - val_accuracy: 0.8744\n",
            "Epoch 407/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1490 - accuracy: 0.9368 - val_loss: 0.4766 - val_accuracy: 0.8776\n",
            "Epoch 408/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1488 - accuracy: 0.9332 - val_loss: 0.4741 - val_accuracy: 0.8680\n",
            "Epoch 409/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1406 - accuracy: 0.9370 - val_loss: 0.5226 - val_accuracy: 0.8591\n",
            "Epoch 410/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1450 - accuracy: 0.9340 - val_loss: 0.5030 - val_accuracy: 0.8663\n",
            "Epoch 411/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1678 - accuracy: 0.9293 - val_loss: 0.5360 - val_accuracy: 0.8607\n",
            "Epoch 412/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1476 - accuracy: 0.9362 - val_loss: 0.4900 - val_accuracy: 0.8671\n",
            "Epoch 413/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1594 - accuracy: 0.9318 - val_loss: 0.5084 - val_accuracy: 0.8760\n",
            "Epoch 414/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1415 - accuracy: 0.9362 - val_loss: 0.4870 - val_accuracy: 0.8752\n",
            "Epoch 415/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1331 - accuracy: 0.9392 - val_loss: 0.5462 - val_accuracy: 0.8615\n",
            "Epoch 416/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1430 - accuracy: 0.9372 - val_loss: 0.4740 - val_accuracy: 0.8784\n",
            "Epoch 417/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1524 - accuracy: 0.9342 - val_loss: 0.5931 - val_accuracy: 0.8599\n",
            "Epoch 418/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1407 - accuracy: 0.9376 - val_loss: 0.5485 - val_accuracy: 0.8720\n",
            "Epoch 419/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1409 - accuracy: 0.9352 - val_loss: 0.5182 - val_accuracy: 0.8768\n",
            "Epoch 420/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1574 - accuracy: 0.9310 - val_loss: 0.5032 - val_accuracy: 0.8696\n",
            "Epoch 421/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1443 - accuracy: 0.9374 - val_loss: 0.6386 - val_accuracy: 0.8559\n",
            "Epoch 422/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1557 - accuracy: 0.9366 - val_loss: 0.5043 - val_accuracy: 0.8744\n",
            "Epoch 423/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1372 - accuracy: 0.9406 - val_loss: 0.4903 - val_accuracy: 0.8680\n",
            "Epoch 424/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1390 - accuracy: 0.9412 - val_loss: 0.5562 - val_accuracy: 0.8752\n",
            "Epoch 425/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1455 - accuracy: 0.9344 - val_loss: 0.5482 - val_accuracy: 0.8631\n",
            "Epoch 426/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1585 - accuracy: 0.9328 - val_loss: 0.4765 - val_accuracy: 0.8647\n",
            "Epoch 427/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1387 - accuracy: 0.9374 - val_loss: 0.4789 - val_accuracy: 0.8816\n",
            "Epoch 428/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1544 - accuracy: 0.9338 - val_loss: 0.5440 - val_accuracy: 0.8655\n",
            "Epoch 429/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1569 - accuracy: 0.9322 - val_loss: 0.4802 - val_accuracy: 0.8808\n",
            "Epoch 430/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1255 - accuracy: 0.9446 - val_loss: 0.5113 - val_accuracy: 0.8696\n",
            "Epoch 431/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1371 - accuracy: 0.9358 - val_loss: 0.5882 - val_accuracy: 0.8712\n",
            "Epoch 432/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1456 - accuracy: 0.9358 - val_loss: 0.5134 - val_accuracy: 0.8736\n",
            "Epoch 433/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1508 - accuracy: 0.9354 - val_loss: 0.5205 - val_accuracy: 0.8647\n",
            "Epoch 434/750\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.1320 - accuracy: 0.9422 - val_loss: 0.5500 - val_accuracy: 0.8615\n",
            "Epoch 435/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1528 - accuracy: 0.9354 - val_loss: 0.5225 - val_accuracy: 0.8712\n",
            "Epoch 436/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1356 - accuracy: 0.9402 - val_loss: 0.5838 - val_accuracy: 0.8502\n",
            "Epoch 437/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1678 - accuracy: 0.9316 - val_loss: 0.4575 - val_accuracy: 0.8744\n",
            "Epoch 438/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1545 - accuracy: 0.9328 - val_loss: 0.4436 - val_accuracy: 0.8800\n",
            "Epoch 439/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1383 - accuracy: 0.9380 - val_loss: 0.4497 - val_accuracy: 0.8696\n",
            "Epoch 440/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1297 - accuracy: 0.9416 - val_loss: 0.4923 - val_accuracy: 0.8728\n",
            "Epoch 441/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1452 - accuracy: 0.9370 - val_loss: 0.4651 - val_accuracy: 0.8704\n",
            "Epoch 442/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1355 - accuracy: 0.9360 - val_loss: 0.4920 - val_accuracy: 0.8744\n",
            "Epoch 443/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1508 - accuracy: 0.9348 - val_loss: 0.4477 - val_accuracy: 0.8696\n",
            "Epoch 444/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1417 - accuracy: 0.9384 - val_loss: 0.5068 - val_accuracy: 0.8647\n",
            "Epoch 445/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1406 - accuracy: 0.9380 - val_loss: 0.4656 - val_accuracy: 0.8720\n",
            "Epoch 446/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1476 - accuracy: 0.9366 - val_loss: 0.5133 - val_accuracy: 0.8752\n",
            "Epoch 447/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1486 - accuracy: 0.9356 - val_loss: 0.4868 - val_accuracy: 0.8736\n",
            "Epoch 448/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1450 - accuracy: 0.9352 - val_loss: 0.4569 - val_accuracy: 0.8752\n",
            "Epoch 449/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.1366 - accuracy: 0.9388 - val_loss: 0.4809 - val_accuracy: 0.8752\n",
            "Epoch 450/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1400 - accuracy: 0.9398 - val_loss: 0.5393 - val_accuracy: 0.8704\n",
            "Epoch 451/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1464 - accuracy: 0.9366 - val_loss: 0.6060 - val_accuracy: 0.8607\n",
            "Epoch 452/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1505 - accuracy: 0.9370 - val_loss: 0.4764 - val_accuracy: 0.8712\n",
            "Epoch 453/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1315 - accuracy: 0.9422 - val_loss: 0.4988 - val_accuracy: 0.8760\n",
            "Epoch 454/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1349 - accuracy: 0.9404 - val_loss: 0.4998 - val_accuracy: 0.8615\n",
            "Epoch 455/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1487 - accuracy: 0.9346 - val_loss: 0.5142 - val_accuracy: 0.8623\n",
            "Epoch 456/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1250 - accuracy: 0.9414 - val_loss: 0.5048 - val_accuracy: 0.8760\n",
            "Epoch 457/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1232 - accuracy: 0.9440 - val_loss: 0.5358 - val_accuracy: 0.8671\n",
            "Epoch 458/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1690 - accuracy: 0.9312 - val_loss: 0.5628 - val_accuracy: 0.8663\n",
            "Epoch 459/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1473 - accuracy: 0.9398 - val_loss: 0.5260 - val_accuracy: 0.8623\n",
            "Epoch 460/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1324 - accuracy: 0.9434 - val_loss: 0.4870 - val_accuracy: 0.8671\n",
            "Epoch 461/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1316 - accuracy: 0.9424 - val_loss: 0.4946 - val_accuracy: 0.8760\n",
            "Epoch 462/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1490 - accuracy: 0.9346 - val_loss: 0.5492 - val_accuracy: 0.8583\n",
            "Epoch 463/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1454 - accuracy: 0.9382 - val_loss: 0.4903 - val_accuracy: 0.8784\n",
            "Epoch 464/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1492 - accuracy: 0.9332 - val_loss: 0.5063 - val_accuracy: 0.8688\n",
            "Epoch 465/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1291 - accuracy: 0.9452 - val_loss: 0.4871 - val_accuracy: 0.8776\n",
            "Epoch 466/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1262 - accuracy: 0.9434 - val_loss: 0.5098 - val_accuracy: 0.8704\n",
            "Epoch 467/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1379 - accuracy: 0.9388 - val_loss: 0.5311 - val_accuracy: 0.8688\n",
            "Epoch 468/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1453 - accuracy: 0.9392 - val_loss: 0.5220 - val_accuracy: 0.8446\n",
            "Epoch 469/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1512 - accuracy: 0.9318 - val_loss: 0.4693 - val_accuracy: 0.8736\n",
            "Epoch 470/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1418 - accuracy: 0.9358 - val_loss: 0.5873 - val_accuracy: 0.8663\n",
            "Epoch 471/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1403 - accuracy: 0.9374 - val_loss: 0.4732 - val_accuracy: 0.8744\n",
            "Epoch 472/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1373 - accuracy: 0.9380 - val_loss: 0.4780 - val_accuracy: 0.8696\n",
            "Epoch 473/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1416 - accuracy: 0.9410 - val_loss: 0.5177 - val_accuracy: 0.8824\n",
            "Epoch 474/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1205 - accuracy: 0.9491 - val_loss: 0.5400 - val_accuracy: 0.8639\n",
            "Epoch 475/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1370 - accuracy: 0.9394 - val_loss: 0.4798 - val_accuracy: 0.8736\n",
            "Epoch 476/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1456 - accuracy: 0.9376 - val_loss: 0.5579 - val_accuracy: 0.8704\n",
            "Epoch 477/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1312 - accuracy: 0.9438 - val_loss: 0.5436 - val_accuracy: 0.8728\n",
            "Epoch 478/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1436 - accuracy: 0.9346 - val_loss: 0.4964 - val_accuracy: 0.8663\n",
            "Epoch 479/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1222 - accuracy: 0.9444 - val_loss: 0.5517 - val_accuracy: 0.8784\n",
            "Epoch 480/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1272 - accuracy: 0.9420 - val_loss: 0.5185 - val_accuracy: 0.8776\n",
            "Epoch 481/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1507 - accuracy: 0.9348 - val_loss: 0.5055 - val_accuracy: 0.8728\n",
            "Epoch 482/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1349 - accuracy: 0.9380 - val_loss: 0.5545 - val_accuracy: 0.8680\n",
            "Epoch 483/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1249 - accuracy: 0.9412 - val_loss: 0.5841 - val_accuracy: 0.8639\n",
            "Epoch 484/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1373 - accuracy: 0.9366 - val_loss: 0.5767 - val_accuracy: 0.8583\n",
            "Epoch 485/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1526 - accuracy: 0.9328 - val_loss: 0.5020 - val_accuracy: 0.8680\n",
            "Epoch 486/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1376 - accuracy: 0.9428 - val_loss: 0.5505 - val_accuracy: 0.8639\n",
            "Epoch 487/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1265 - accuracy: 0.9436 - val_loss: 0.5788 - val_accuracy: 0.8631\n",
            "Epoch 488/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1335 - accuracy: 0.9386 - val_loss: 0.6067 - val_accuracy: 0.8583\n",
            "Epoch 489/750\n",
            "414/414 [==============================] - 1s 3ms/step - loss: 0.1373 - accuracy: 0.9414 - val_loss: 0.5281 - val_accuracy: 0.8680\n",
            "Epoch 490/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1200 - accuracy: 0.9471 - val_loss: 0.5376 - val_accuracy: 0.8607\n",
            "Epoch 491/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1487 - accuracy: 0.9360 - val_loss: 0.5068 - val_accuracy: 0.8639\n",
            "Epoch 492/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1228 - accuracy: 0.9469 - val_loss: 0.5448 - val_accuracy: 0.8680\n",
            "Epoch 493/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1461 - accuracy: 0.9348 - val_loss: 0.5213 - val_accuracy: 0.8688\n",
            "Epoch 494/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1222 - accuracy: 0.9469 - val_loss: 0.5340 - val_accuracy: 0.8752\n",
            "Epoch 495/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1277 - accuracy: 0.9426 - val_loss: 0.6090 - val_accuracy: 0.8559\n",
            "Epoch 496/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1706 - accuracy: 0.9269 - val_loss: 0.4677 - val_accuracy: 0.8792\n",
            "Epoch 497/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1266 - accuracy: 0.9450 - val_loss: 0.6196 - val_accuracy: 0.8655\n",
            "Epoch 498/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1227 - accuracy: 0.9455 - val_loss: 0.5737 - val_accuracy: 0.8808\n",
            "Epoch 499/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1295 - accuracy: 0.9457 - val_loss: 0.6104 - val_accuracy: 0.8655\n",
            "Epoch 500/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1373 - accuracy: 0.9410 - val_loss: 0.4833 - val_accuracy: 0.8688\n",
            "Epoch 501/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1198 - accuracy: 0.9495 - val_loss: 0.6254 - val_accuracy: 0.8575\n",
            "Epoch 502/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1370 - accuracy: 0.9388 - val_loss: 0.6168 - val_accuracy: 0.8591\n",
            "Epoch 503/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1383 - accuracy: 0.9420 - val_loss: 0.6052 - val_accuracy: 0.8663\n",
            "Epoch 504/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1505 - accuracy: 0.9370 - val_loss: 0.5765 - val_accuracy: 0.8696\n",
            "Epoch 505/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1264 - accuracy: 0.9459 - val_loss: 0.6688 - val_accuracy: 0.8688\n",
            "Epoch 506/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1189 - accuracy: 0.9457 - val_loss: 0.5634 - val_accuracy: 0.8776\n",
            "Epoch 507/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1462 - accuracy: 0.9350 - val_loss: 0.5465 - val_accuracy: 0.8720\n",
            "Epoch 508/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1301 - accuracy: 0.9459 - val_loss: 0.6814 - val_accuracy: 0.8591\n",
            "Epoch 509/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.1270 - accuracy: 0.9438 - val_loss: 0.5690 - val_accuracy: 0.8728\n",
            "Epoch 510/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1380 - accuracy: 0.9418 - val_loss: 0.4795 - val_accuracy: 0.8688\n",
            "Epoch 511/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1263 - accuracy: 0.9450 - val_loss: 0.5509 - val_accuracy: 0.8623\n",
            "Epoch 512/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1296 - accuracy: 0.9412 - val_loss: 0.5160 - val_accuracy: 0.8744\n",
            "Epoch 513/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1209 - accuracy: 0.9459 - val_loss: 0.5672 - val_accuracy: 0.8639\n",
            "Epoch 514/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1322 - accuracy: 0.9402 - val_loss: 0.6205 - val_accuracy: 0.8623\n",
            "Epoch 515/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1444 - accuracy: 0.9360 - val_loss: 0.5020 - val_accuracy: 0.8696\n",
            "Epoch 516/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1297 - accuracy: 0.9432 - val_loss: 0.5515 - val_accuracy: 0.8696\n",
            "Epoch 517/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1206 - accuracy: 0.9465 - val_loss: 0.5822 - val_accuracy: 0.8696\n",
            "Epoch 518/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1410 - accuracy: 0.9404 - val_loss: 0.6295 - val_accuracy: 0.8591\n",
            "Epoch 519/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1335 - accuracy: 0.9414 - val_loss: 0.5949 - val_accuracy: 0.8704\n",
            "Epoch 520/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1181 - accuracy: 0.9448 - val_loss: 0.5688 - val_accuracy: 0.8720\n",
            "Epoch 521/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1220 - accuracy: 0.9457 - val_loss: 0.5680 - val_accuracy: 0.8615\n",
            "Epoch 522/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1376 - accuracy: 0.9404 - val_loss: 0.5837 - val_accuracy: 0.8567\n",
            "Epoch 523/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1420 - accuracy: 0.9404 - val_loss: 0.5158 - val_accuracy: 0.8631\n",
            "Epoch 524/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1252 - accuracy: 0.9452 - val_loss: 0.5022 - val_accuracy: 0.8728\n",
            "Epoch 525/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1448 - accuracy: 0.9382 - val_loss: 0.5210 - val_accuracy: 0.8736\n",
            "Epoch 526/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1244 - accuracy: 0.9461 - val_loss: 0.5837 - val_accuracy: 0.8728\n",
            "Epoch 527/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1263 - accuracy: 0.9475 - val_loss: 0.5668 - val_accuracy: 0.8728\n",
            "Epoch 528/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1177 - accuracy: 0.9483 - val_loss: 0.5046 - val_accuracy: 0.8720\n",
            "Epoch 529/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1391 - accuracy: 0.9410 - val_loss: 0.5424 - val_accuracy: 0.8647\n",
            "Epoch 530/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1196 - accuracy: 0.9495 - val_loss: 0.5127 - val_accuracy: 0.8841\n",
            "Epoch 531/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1397 - accuracy: 0.9434 - val_loss: 0.4938 - val_accuracy: 0.8792\n",
            "Epoch 532/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1127 - accuracy: 0.9491 - val_loss: 0.4900 - val_accuracy: 0.8752\n",
            "Epoch 533/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1324 - accuracy: 0.9444 - val_loss: 0.5969 - val_accuracy: 0.8623\n",
            "Epoch 534/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1277 - accuracy: 0.9434 - val_loss: 0.5261 - val_accuracy: 0.8720\n",
            "Epoch 535/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1178 - accuracy: 0.9475 - val_loss: 0.6056 - val_accuracy: 0.8655\n",
            "Epoch 536/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1362 - accuracy: 0.9414 - val_loss: 0.5741 - val_accuracy: 0.8647\n",
            "Epoch 537/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1320 - accuracy: 0.9386 - val_loss: 0.6166 - val_accuracy: 0.8583\n",
            "Epoch 538/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1326 - accuracy: 0.9416 - val_loss: 0.5853 - val_accuracy: 0.8688\n",
            "Epoch 539/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1339 - accuracy: 0.9414 - val_loss: 0.5004 - val_accuracy: 0.8663\n",
            "Epoch 540/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1298 - accuracy: 0.9450 - val_loss: 0.5209 - val_accuracy: 0.8776\n",
            "Epoch 541/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1158 - accuracy: 0.9497 - val_loss: 0.5577 - val_accuracy: 0.8655\n",
            "Epoch 542/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1402 - accuracy: 0.9378 - val_loss: 0.6736 - val_accuracy: 0.8543\n",
            "Epoch 543/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1356 - accuracy: 0.9410 - val_loss: 0.5884 - val_accuracy: 0.8583\n",
            "Epoch 544/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1214 - accuracy: 0.9495 - val_loss: 0.5592 - val_accuracy: 0.8639\n",
            "Epoch 545/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1058 - accuracy: 0.9529 - val_loss: 0.6022 - val_accuracy: 0.8583\n",
            "Epoch 546/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1297 - accuracy: 0.9406 - val_loss: 0.6129 - val_accuracy: 0.8760\n",
            "Epoch 547/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1471 - accuracy: 0.9406 - val_loss: 0.5195 - val_accuracy: 0.8776\n",
            "Epoch 548/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1256 - accuracy: 0.9459 - val_loss: 0.5459 - val_accuracy: 0.8736\n",
            "Epoch 549/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1257 - accuracy: 0.9471 - val_loss: 0.5956 - val_accuracy: 0.8696\n",
            "Epoch 550/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1325 - accuracy: 0.9444 - val_loss: 0.4975 - val_accuracy: 0.8768\n",
            "Epoch 551/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1118 - accuracy: 0.9507 - val_loss: 0.5363 - val_accuracy: 0.8688\n",
            "Epoch 552/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1229 - accuracy: 0.9459 - val_loss: 0.6053 - val_accuracy: 0.8478\n",
            "Epoch 553/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1252 - accuracy: 0.9483 - val_loss: 0.5625 - val_accuracy: 0.8736\n",
            "Epoch 554/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1353 - accuracy: 0.9432 - val_loss: 0.5729 - val_accuracy: 0.8615\n",
            "Epoch 555/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1298 - accuracy: 0.9448 - val_loss: 0.5450 - val_accuracy: 0.8615\n",
            "Epoch 556/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1159 - accuracy: 0.9487 - val_loss: 0.5777 - val_accuracy: 0.8792\n",
            "Epoch 557/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1184 - accuracy: 0.9499 - val_loss: 0.5771 - val_accuracy: 0.8744\n",
            "Epoch 558/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1226 - accuracy: 0.9452 - val_loss: 0.5354 - val_accuracy: 0.8752\n",
            "Epoch 559/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1302 - accuracy: 0.9418 - val_loss: 0.5907 - val_accuracy: 0.8696\n",
            "Epoch 560/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1213 - accuracy: 0.9471 - val_loss: 0.5748 - val_accuracy: 0.8680\n",
            "Epoch 561/750\n",
            "414/414 [==============================] - 1s 4ms/step - loss: 0.1287 - accuracy: 0.9473 - val_loss: 0.5343 - val_accuracy: 0.8680\n",
            "Epoch 562/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1372 - accuracy: 0.9420 - val_loss: 0.5464 - val_accuracy: 0.8792\n",
            "Epoch 563/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1265 - accuracy: 0.9436 - val_loss: 0.6001 - val_accuracy: 0.8760\n",
            "Epoch 564/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1128 - accuracy: 0.9525 - val_loss: 0.5907 - val_accuracy: 0.8792\n",
            "Epoch 565/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1337 - accuracy: 0.9428 - val_loss: 0.6242 - val_accuracy: 0.8519\n",
            "Epoch 566/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1191 - accuracy: 0.9479 - val_loss: 0.5946 - val_accuracy: 0.8655\n",
            "Epoch 567/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.1190 - accuracy: 0.9487 - val_loss: 0.6021 - val_accuracy: 0.8615\n",
            "Epoch 568/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1136 - accuracy: 0.9487 - val_loss: 0.5551 - val_accuracy: 0.8696\n",
            "Epoch 569/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1484 - accuracy: 0.9396 - val_loss: 0.6013 - val_accuracy: 0.8720\n",
            "Epoch 570/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1261 - accuracy: 0.9452 - val_loss: 0.5476 - val_accuracy: 0.8696\n",
            "Epoch 571/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1250 - accuracy: 0.9463 - val_loss: 0.5839 - val_accuracy: 0.8655\n",
            "Epoch 572/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1190 - accuracy: 0.9471 - val_loss: 0.5671 - val_accuracy: 0.8881\n",
            "Epoch 573/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1087 - accuracy: 0.9531 - val_loss: 0.6489 - val_accuracy: 0.8607\n",
            "Epoch 574/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1155 - accuracy: 0.9495 - val_loss: 0.5746 - val_accuracy: 0.8704\n",
            "Epoch 575/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1187 - accuracy: 0.9442 - val_loss: 0.6189 - val_accuracy: 0.8599\n",
            "Epoch 576/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1318 - accuracy: 0.9457 - val_loss: 0.6071 - val_accuracy: 0.8551\n",
            "Epoch 577/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1625 - accuracy: 0.9314 - val_loss: 0.5465 - val_accuracy: 0.8704\n",
            "Epoch 578/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1069 - accuracy: 0.9507 - val_loss: 0.6315 - val_accuracy: 0.8647\n",
            "Epoch 579/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1131 - accuracy: 0.9507 - val_loss: 0.5731 - val_accuracy: 0.8688\n",
            "Epoch 580/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1431 - accuracy: 0.9384 - val_loss: 0.5413 - val_accuracy: 0.8647\n",
            "Epoch 581/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1242 - accuracy: 0.9473 - val_loss: 0.6167 - val_accuracy: 0.8519\n",
            "Epoch 582/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1184 - accuracy: 0.9485 - val_loss: 0.5265 - val_accuracy: 0.8736\n",
            "Epoch 583/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.1113 - accuracy: 0.9531 - val_loss: 0.5894 - val_accuracy: 0.8639\n",
            "Epoch 584/750\n",
            "414/414 [==============================] - 3s 8ms/step - loss: 0.1190 - accuracy: 0.9473 - val_loss: 0.6342 - val_accuracy: 0.8623\n",
            "Epoch 585/750\n",
            "414/414 [==============================] - 4s 9ms/step - loss: 0.1457 - accuracy: 0.9374 - val_loss: 0.5941 - val_accuracy: 0.8680\n",
            "Epoch 586/750\n",
            "414/414 [==============================] - 6s 13ms/step - loss: 0.1168 - accuracy: 0.9477 - val_loss: 0.6052 - val_accuracy: 0.8647\n",
            "Epoch 587/750\n",
            "414/414 [==============================] - 6s 14ms/step - loss: 0.1276 - accuracy: 0.9455 - val_loss: 0.6266 - val_accuracy: 0.8688\n",
            "Epoch 588/750\n",
            "414/414 [==============================] - 4s 11ms/step - loss: 0.1026 - accuracy: 0.9583 - val_loss: 0.6145 - val_accuracy: 0.8615\n",
            "Epoch 589/750\n",
            "414/414 [==============================] - 4s 10ms/step - loss: 0.1164 - accuracy: 0.9483 - val_loss: 0.5925 - val_accuracy: 0.8680\n",
            "Epoch 590/750\n",
            "414/414 [==============================] - 9s 21ms/step - loss: 0.1183 - accuracy: 0.9507 - val_loss: 0.5813 - val_accuracy: 0.8647\n",
            "Epoch 591/750\n",
            "414/414 [==============================] - 6s 14ms/step - loss: 0.1587 - accuracy: 0.9384 - val_loss: 0.5038 - val_accuracy: 0.8655\n",
            "Epoch 592/750\n",
            "414/414 [==============================] - 4s 10ms/step - loss: 0.1274 - accuracy: 0.9459 - val_loss: 0.5329 - val_accuracy: 0.8720\n",
            "Epoch 593/750\n",
            "414/414 [==============================] - 6s 14ms/step - loss: 0.1035 - accuracy: 0.9569 - val_loss: 0.5703 - val_accuracy: 0.8792\n",
            "Epoch 594/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1148 - accuracy: 0.9511 - val_loss: 0.4920 - val_accuracy: 0.8680\n",
            "Epoch 595/750\n",
            "414/414 [==============================] - 4s 10ms/step - loss: 0.1177 - accuracy: 0.9505 - val_loss: 0.4930 - val_accuracy: 0.8696\n",
            "Epoch 596/750\n",
            "414/414 [==============================] - 4s 9ms/step - loss: 0.1071 - accuracy: 0.9527 - val_loss: 0.6736 - val_accuracy: 0.8736\n",
            "Epoch 597/750\n",
            "414/414 [==============================] - 6s 14ms/step - loss: 0.1255 - accuracy: 0.9465 - val_loss: 0.5919 - val_accuracy: 0.8688\n",
            "Epoch 598/750\n",
            "414/414 [==============================] - 5s 13ms/step - loss: 0.1197 - accuracy: 0.9477 - val_loss: 0.6588 - val_accuracy: 0.8631\n",
            "Epoch 599/750\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.1286 - accuracy: 0.9420 - val_loss: 0.5243 - val_accuracy: 0.8704\n",
            "Epoch 600/750\n",
            "414/414 [==============================] - 3s 8ms/step - loss: 0.1131 - accuracy: 0.9517 - val_loss: 0.5775 - val_accuracy: 0.8696\n",
            "Epoch 601/750\n",
            "414/414 [==============================] - 6s 15ms/step - loss: 0.1166 - accuracy: 0.9515 - val_loss: 0.6108 - val_accuracy: 0.8728\n",
            "Epoch 602/750\n",
            "414/414 [==============================] - 4s 10ms/step - loss: 0.1095 - accuracy: 0.9517 - val_loss: 0.5450 - val_accuracy: 0.8752\n",
            "Epoch 603/750\n",
            "414/414 [==============================] - 4s 9ms/step - loss: 0.1107 - accuracy: 0.9499 - val_loss: 0.5831 - val_accuracy: 0.8680\n",
            "Epoch 604/750\n",
            "414/414 [==============================] - 6s 14ms/step - loss: 0.1306 - accuracy: 0.9461 - val_loss: 0.5283 - val_accuracy: 0.8663\n",
            "Epoch 605/750\n",
            "414/414 [==============================] - 4s 10ms/step - loss: 0.1371 - accuracy: 0.9420 - val_loss: 0.5653 - val_accuracy: 0.8680\n",
            "Epoch 606/750\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.1058 - accuracy: 0.9551 - val_loss: 0.5178 - val_accuracy: 0.8792\n",
            "Epoch 607/750\n",
            "414/414 [==============================] - 3s 8ms/step - loss: 0.1227 - accuracy: 0.9465 - val_loss: 0.5980 - val_accuracy: 0.8680\n",
            "Epoch 608/750\n",
            "414/414 [==============================] - 4s 11ms/step - loss: 0.1205 - accuracy: 0.9487 - val_loss: 0.5438 - val_accuracy: 0.8623\n",
            "Epoch 609/750\n",
            "414/414 [==============================] - 4s 10ms/step - loss: 0.1106 - accuracy: 0.9527 - val_loss: 0.5707 - val_accuracy: 0.8639\n",
            "Epoch 610/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1228 - accuracy: 0.9507 - val_loss: 0.5451 - val_accuracy: 0.8720\n",
            "Epoch 611/750\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.1112 - accuracy: 0.9507 - val_loss: 0.5707 - val_accuracy: 0.8680\n",
            "Epoch 612/750\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.1248 - accuracy: 0.9465 - val_loss: 0.5526 - val_accuracy: 0.8752\n",
            "Epoch 613/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1097 - accuracy: 0.9531 - val_loss: 0.5844 - val_accuracy: 0.8736\n",
            "Epoch 614/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1137 - accuracy: 0.9507 - val_loss: 0.6941 - val_accuracy: 0.8623\n",
            "Epoch 615/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1111 - accuracy: 0.9529 - val_loss: 0.5893 - val_accuracy: 0.8639\n",
            "Epoch 616/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1276 - accuracy: 0.9489 - val_loss: 0.5338 - val_accuracy: 0.8752\n",
            "Epoch 617/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1101 - accuracy: 0.9545 - val_loss: 0.5579 - val_accuracy: 0.8816\n",
            "Epoch 618/750\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.1300 - accuracy: 0.9477 - val_loss: 0.6205 - val_accuracy: 0.8567\n",
            "Epoch 619/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1208 - accuracy: 0.9477 - val_loss: 0.5747 - val_accuracy: 0.8543\n",
            "Epoch 620/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1125 - accuracy: 0.9521 - val_loss: 0.6071 - val_accuracy: 0.8559\n",
            "Epoch 621/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1147 - accuracy: 0.9521 - val_loss: 0.6198 - val_accuracy: 0.8680\n",
            "Epoch 622/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1154 - accuracy: 0.9509 - val_loss: 0.5868 - val_accuracy: 0.8696\n",
            "Epoch 623/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1272 - accuracy: 0.9483 - val_loss: 0.5740 - val_accuracy: 0.8647\n",
            "Epoch 624/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1045 - accuracy: 0.9557 - val_loss: 0.5655 - val_accuracy: 0.8736\n",
            "Epoch 625/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1262 - accuracy: 0.9483 - val_loss: 0.6200 - val_accuracy: 0.8688\n",
            "Epoch 626/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1032 - accuracy: 0.9543 - val_loss: 0.5579 - val_accuracy: 0.8663\n",
            "Epoch 627/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1263 - accuracy: 0.9471 - val_loss: 0.5883 - val_accuracy: 0.8760\n",
            "Epoch 628/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0989 - accuracy: 0.9561 - val_loss: 0.5762 - val_accuracy: 0.8792\n",
            "Epoch 629/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1132 - accuracy: 0.9505 - val_loss: 0.6201 - val_accuracy: 0.8655\n",
            "Epoch 630/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1170 - accuracy: 0.9487 - val_loss: 0.5750 - val_accuracy: 0.8704\n",
            "Epoch 631/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1206 - accuracy: 0.9469 - val_loss: 0.6004 - val_accuracy: 0.8688\n",
            "Epoch 632/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1186 - accuracy: 0.9517 - val_loss: 0.5432 - val_accuracy: 0.8720\n",
            "Epoch 633/750\n",
            "414/414 [==============================] - 3s 8ms/step - loss: 0.1140 - accuracy: 0.9537 - val_loss: 0.5940 - val_accuracy: 0.8591\n",
            "Epoch 634/750\n",
            "414/414 [==============================] - 4s 9ms/step - loss: 0.1186 - accuracy: 0.9523 - val_loss: 0.6152 - val_accuracy: 0.8688\n",
            "Epoch 635/750\n",
            "414/414 [==============================] - 6s 14ms/step - loss: 0.1096 - accuracy: 0.9525 - val_loss: 0.6209 - val_accuracy: 0.8776\n",
            "Epoch 636/750\n",
            "414/414 [==============================] - 3s 8ms/step - loss: 0.1084 - accuracy: 0.9529 - val_loss: 0.6403 - val_accuracy: 0.8599\n",
            "Epoch 637/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.1048 - accuracy: 0.9563 - val_loss: 0.6067 - val_accuracy: 0.8704\n",
            "Epoch 638/750\n",
            "414/414 [==============================] - 3s 8ms/step - loss: 0.1083 - accuracy: 0.9529 - val_loss: 0.6490 - val_accuracy: 0.8744\n",
            "Epoch 639/750\n",
            "414/414 [==============================] - 6s 13ms/step - loss: 0.1230 - accuracy: 0.9461 - val_loss: 0.6042 - val_accuracy: 0.8720\n",
            "Epoch 640/750\n",
            "414/414 [==============================] - 4s 10ms/step - loss: 0.1329 - accuracy: 0.9461 - val_loss: 0.5610 - val_accuracy: 0.8728\n",
            "Epoch 641/750\n",
            "414/414 [==============================] - 3s 8ms/step - loss: 0.1108 - accuracy: 0.9511 - val_loss: 0.5534 - val_accuracy: 0.8752\n",
            "Epoch 642/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.0996 - accuracy: 0.9573 - val_loss: 0.6184 - val_accuracy: 0.8704\n",
            "Epoch 643/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1057 - accuracy: 0.9529 - val_loss: 0.6354 - val_accuracy: 0.8704\n",
            "Epoch 644/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1162 - accuracy: 0.9503 - val_loss: 0.6623 - val_accuracy: 0.8639\n",
            "Epoch 645/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.1267 - accuracy: 0.9467 - val_loss: 0.5427 - val_accuracy: 0.8768\n",
            "Epoch 646/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1050 - accuracy: 0.9541 - val_loss: 0.5777 - val_accuracy: 0.8720\n",
            "Epoch 647/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1231 - accuracy: 0.9493 - val_loss: 0.6041 - val_accuracy: 0.8567\n",
            "Epoch 648/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1232 - accuracy: 0.9452 - val_loss: 0.6219 - val_accuracy: 0.8559\n",
            "Epoch 649/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1166 - accuracy: 0.9513 - val_loss: 0.6331 - val_accuracy: 0.8663\n",
            "Epoch 650/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1056 - accuracy: 0.9545 - val_loss: 0.6048 - val_accuracy: 0.8720\n",
            "Epoch 651/750\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.1031 - accuracy: 0.9525 - val_loss: 0.6377 - val_accuracy: 0.8712\n",
            "Epoch 652/750\n",
            "414/414 [==============================] - 5s 11ms/step - loss: 0.1156 - accuracy: 0.9503 - val_loss: 0.6271 - val_accuracy: 0.8680\n",
            "Epoch 653/750\n",
            "414/414 [==============================] - 3s 8ms/step - loss: 0.1212 - accuracy: 0.9479 - val_loss: 0.6056 - val_accuracy: 0.8768\n",
            "Epoch 654/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0988 - accuracy: 0.9557 - val_loss: 0.5551 - val_accuracy: 0.8768\n",
            "Epoch 655/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1036 - accuracy: 0.9543 - val_loss: 0.6338 - val_accuracy: 0.8728\n",
            "Epoch 656/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1307 - accuracy: 0.9479 - val_loss: 0.4988 - val_accuracy: 0.8720\n",
            "Epoch 657/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0993 - accuracy: 0.9567 - val_loss: 0.5911 - val_accuracy: 0.8736\n",
            "Epoch 658/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1049 - accuracy: 0.9545 - val_loss: 0.6119 - val_accuracy: 0.8808\n",
            "Epoch 659/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.1079 - accuracy: 0.9535 - val_loss: 0.6457 - val_accuracy: 0.8704\n",
            "Epoch 660/750\n",
            "414/414 [==============================] - 4s 9ms/step - loss: 0.1384 - accuracy: 0.9408 - val_loss: 0.5985 - val_accuracy: 0.8647\n",
            "Epoch 661/750\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.1199 - accuracy: 0.9491 - val_loss: 0.6262 - val_accuracy: 0.8655\n",
            "Epoch 662/750\n",
            "414/414 [==============================] - 5s 13ms/step - loss: 0.0967 - accuracy: 0.9603 - val_loss: 0.6143 - val_accuracy: 0.8752\n",
            "Epoch 663/750\n",
            "414/414 [==============================] - 5s 13ms/step - loss: 0.1000 - accuracy: 0.9583 - val_loss: 0.6684 - val_accuracy: 0.8680\n",
            "Epoch 664/750\n",
            "414/414 [==============================] - 5s 13ms/step - loss: 0.1075 - accuracy: 0.9567 - val_loss: 0.6397 - val_accuracy: 0.8583\n",
            "Epoch 665/750\n",
            "414/414 [==============================] - 4s 11ms/step - loss: 0.1222 - accuracy: 0.9473 - val_loss: 0.5795 - val_accuracy: 0.8631\n",
            "Epoch 666/750\n",
            "414/414 [==============================] - 3s 8ms/step - loss: 0.1119 - accuracy: 0.9509 - val_loss: 0.6048 - val_accuracy: 0.8760\n",
            "Epoch 667/750\n",
            "414/414 [==============================] - 5s 12ms/step - loss: 0.0984 - accuracy: 0.9577 - val_loss: 0.7879 - val_accuracy: 0.8688\n",
            "Epoch 668/750\n",
            "414/414 [==============================] - 5s 12ms/step - loss: 0.1140 - accuracy: 0.9521 - val_loss: 0.7022 - val_accuracy: 0.8736\n",
            "Epoch 669/750\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.0958 - accuracy: 0.9589 - val_loss: 0.7004 - val_accuracy: 0.8752\n",
            "Epoch 670/750\n",
            "414/414 [==============================] - 4s 10ms/step - loss: 0.0961 - accuracy: 0.9587 - val_loss: 0.8030 - val_accuracy: 0.8712\n",
            "Epoch 671/750\n",
            "414/414 [==============================] - 8s 20ms/step - loss: 0.1249 - accuracy: 0.9505 - val_loss: 0.6898 - val_accuracy: 0.8712\n",
            "Epoch 672/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1223 - accuracy: 0.9491 - val_loss: 0.6601 - val_accuracy: 0.8688\n",
            "Epoch 673/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1194 - accuracy: 0.9513 - val_loss: 0.6332 - val_accuracy: 0.8607\n",
            "Epoch 674/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1094 - accuracy: 0.9555 - val_loss: 0.5676 - val_accuracy: 0.8655\n",
            "Epoch 675/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0991 - accuracy: 0.9595 - val_loss: 0.7123 - val_accuracy: 0.8663\n",
            "Epoch 676/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1104 - accuracy: 0.9531 - val_loss: 0.5727 - val_accuracy: 0.8744\n",
            "Epoch 677/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.1140 - accuracy: 0.9525 - val_loss: 0.5612 - val_accuracy: 0.8800\n",
            "Epoch 678/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1061 - accuracy: 0.9597 - val_loss: 0.6104 - val_accuracy: 0.8816\n",
            "Epoch 679/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1085 - accuracy: 0.9547 - val_loss: 0.6007 - val_accuracy: 0.8615\n",
            "Epoch 680/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1005 - accuracy: 0.9571 - val_loss: 0.5718 - val_accuracy: 0.8704\n",
            "Epoch 681/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1080 - accuracy: 0.9533 - val_loss: 0.6667 - val_accuracy: 0.8671\n",
            "Epoch 682/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1174 - accuracy: 0.9511 - val_loss: 0.6216 - val_accuracy: 0.8784\n",
            "Epoch 683/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1057 - accuracy: 0.9557 - val_loss: 0.6903 - val_accuracy: 0.8720\n",
            "Epoch 684/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1015 - accuracy: 0.9547 - val_loss: 0.6964 - val_accuracy: 0.8688\n",
            "Epoch 685/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.0970 - accuracy: 0.9589 - val_loss: 0.6697 - val_accuracy: 0.8808\n",
            "Epoch 686/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1104 - accuracy: 0.9533 - val_loss: 0.6576 - val_accuracy: 0.8712\n",
            "Epoch 687/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1189 - accuracy: 0.9491 - val_loss: 0.7082 - val_accuracy: 0.8744\n",
            "Epoch 688/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1207 - accuracy: 0.9523 - val_loss: 0.7391 - val_accuracy: 0.8776\n",
            "Epoch 689/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0961 - accuracy: 0.9599 - val_loss: 0.7122 - val_accuracy: 0.8728\n",
            "Epoch 690/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1161 - accuracy: 0.9507 - val_loss: 0.6743 - val_accuracy: 0.8720\n",
            "Epoch 691/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0927 - accuracy: 0.9607 - val_loss: 0.6122 - val_accuracy: 0.8841\n",
            "Epoch 692/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.0936 - accuracy: 0.9614 - val_loss: 0.6915 - val_accuracy: 0.8752\n",
            "Epoch 693/750\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.1171 - accuracy: 0.9503 - val_loss: 0.6406 - val_accuracy: 0.8696\n",
            "Epoch 694/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0934 - accuracy: 0.9599 - val_loss: 0.7036 - val_accuracy: 0.8696\n",
            "Epoch 695/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1318 - accuracy: 0.9436 - val_loss: 0.7003 - val_accuracy: 0.8599\n",
            "Epoch 696/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1258 - accuracy: 0.9477 - val_loss: 0.5419 - val_accuracy: 0.8784\n",
            "Epoch 697/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0864 - accuracy: 0.9654 - val_loss: 0.6524 - val_accuracy: 0.8704\n",
            "Epoch 698/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1192 - accuracy: 0.9521 - val_loss: 0.6447 - val_accuracy: 0.8615\n",
            "Epoch 699/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1118 - accuracy: 0.9539 - val_loss: 0.6351 - val_accuracy: 0.8671\n",
            "Epoch 700/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.0992 - accuracy: 0.9587 - val_loss: 0.7004 - val_accuracy: 0.8639\n",
            "Epoch 701/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.1040 - accuracy: 0.9577 - val_loss: 0.6517 - val_accuracy: 0.8631\n",
            "Epoch 702/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0944 - accuracy: 0.9591 - val_loss: 0.6202 - val_accuracy: 0.8784\n",
            "Epoch 703/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1356 - accuracy: 0.9448 - val_loss: 0.5941 - val_accuracy: 0.8671\n",
            "Epoch 704/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0982 - accuracy: 0.9589 - val_loss: 0.6783 - val_accuracy: 0.8720\n",
            "Epoch 705/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1111 - accuracy: 0.9557 - val_loss: 0.6441 - val_accuracy: 0.8728\n",
            "Epoch 706/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0968 - accuracy: 0.9618 - val_loss: 0.6800 - val_accuracy: 0.8768\n",
            "Epoch 707/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1175 - accuracy: 0.9529 - val_loss: 0.6590 - val_accuracy: 0.8712\n",
            "Epoch 708/750\n",
            "414/414 [==============================] - 3s 7ms/step - loss: 0.0895 - accuracy: 0.9612 - val_loss: 0.6524 - val_accuracy: 0.8816\n",
            "Epoch 709/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1263 - accuracy: 0.9509 - val_loss: 0.6542 - val_accuracy: 0.8728\n",
            "Epoch 710/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0966 - accuracy: 0.9628 - val_loss: 0.6719 - val_accuracy: 0.8768\n",
            "Epoch 711/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0943 - accuracy: 0.9589 - val_loss: 0.7006 - val_accuracy: 0.8752\n",
            "Epoch 712/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1046 - accuracy: 0.9559 - val_loss: 0.6855 - val_accuracy: 0.8720\n",
            "Epoch 713/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1211 - accuracy: 0.9519 - val_loss: 0.6101 - val_accuracy: 0.8631\n",
            "Epoch 714/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0994 - accuracy: 0.9607 - val_loss: 0.6926 - val_accuracy: 0.8792\n",
            "Epoch 715/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.0946 - accuracy: 0.9614 - val_loss: 0.6143 - val_accuracy: 0.8728\n",
            "Epoch 716/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.0985 - accuracy: 0.9585 - val_loss: 0.6578 - val_accuracy: 0.8655\n",
            "Epoch 717/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1610 - accuracy: 0.9374 - val_loss: 0.6282 - val_accuracy: 0.8792\n",
            "Epoch 718/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1149 - accuracy: 0.9515 - val_loss: 0.6682 - val_accuracy: 0.8808\n",
            "Epoch 719/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0856 - accuracy: 0.9656 - val_loss: 0.6027 - val_accuracy: 0.8808\n",
            "Epoch 720/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0849 - accuracy: 0.9632 - val_loss: 0.6591 - val_accuracy: 0.8824\n",
            "Epoch 721/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1015 - accuracy: 0.9565 - val_loss: 0.6173 - val_accuracy: 0.8776\n",
            "Epoch 722/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0963 - accuracy: 0.9589 - val_loss: 0.6618 - val_accuracy: 0.8744\n",
            "Epoch 723/750\n",
            "414/414 [==============================] - 4s 11ms/step - loss: 0.0917 - accuracy: 0.9630 - val_loss: 0.5973 - val_accuracy: 0.8857\n",
            "Epoch 724/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1113 - accuracy: 0.9537 - val_loss: 0.6087 - val_accuracy: 0.8752\n",
            "Epoch 725/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1190 - accuracy: 0.9495 - val_loss: 0.6387 - val_accuracy: 0.8647\n",
            "Epoch 726/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0985 - accuracy: 0.9593 - val_loss: 0.6496 - val_accuracy: 0.8776\n",
            "Epoch 727/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0994 - accuracy: 0.9575 - val_loss: 0.7401 - val_accuracy: 0.8704\n",
            "Epoch 728/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1085 - accuracy: 0.9553 - val_loss: 0.6378 - val_accuracy: 0.8720\n",
            "Epoch 729/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0965 - accuracy: 0.9581 - val_loss: 0.5992 - val_accuracy: 0.8800\n",
            "Epoch 730/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1209 - accuracy: 0.9531 - val_loss: 0.7268 - val_accuracy: 0.8599\n",
            "Epoch 731/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1087 - accuracy: 0.9565 - val_loss: 0.5938 - val_accuracy: 0.8857\n",
            "Epoch 732/750\n",
            "414/414 [==============================] - 3s 6ms/step - loss: 0.0929 - accuracy: 0.9599 - val_loss: 0.6720 - val_accuracy: 0.8728\n",
            "Epoch 733/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1001 - accuracy: 0.9581 - val_loss: 0.6729 - val_accuracy: 0.8752\n",
            "Epoch 734/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0995 - accuracy: 0.9589 - val_loss: 0.6134 - val_accuracy: 0.8824\n",
            "Epoch 735/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0974 - accuracy: 0.9595 - val_loss: 0.6087 - val_accuracy: 0.8768\n",
            "Epoch 736/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1059 - accuracy: 0.9551 - val_loss: 0.6582 - val_accuracy: 0.8824\n",
            "Epoch 737/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1093 - accuracy: 0.9571 - val_loss: 0.7366 - val_accuracy: 0.8671\n",
            "Epoch 738/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1028 - accuracy: 0.9583 - val_loss: 0.6733 - val_accuracy: 0.8792\n",
            "Epoch 739/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.0882 - accuracy: 0.9630 - val_loss: 0.7141 - val_accuracy: 0.8784\n",
            "Epoch 740/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.1116 - accuracy: 0.9559 - val_loss: 0.6677 - val_accuracy: 0.8808\n",
            "Epoch 741/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.1085 - accuracy: 0.9549 - val_loss: 0.7063 - val_accuracy: 0.8655\n",
            "Epoch 742/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0935 - accuracy: 0.9605 - val_loss: 0.7135 - val_accuracy: 0.8663\n",
            "Epoch 743/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0980 - accuracy: 0.9585 - val_loss: 0.7261 - val_accuracy: 0.8736\n",
            "Epoch 744/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0933 - accuracy: 0.9601 - val_loss: 0.7207 - val_accuracy: 0.8680\n",
            "Epoch 745/750\n",
            "414/414 [==============================] - 2s 5ms/step - loss: 0.0987 - accuracy: 0.9577 - val_loss: 0.6285 - val_accuracy: 0.8760\n",
            "Epoch 746/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.0974 - accuracy: 0.9614 - val_loss: 0.7069 - val_accuracy: 0.8704\n",
            "Epoch 747/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.0945 - accuracy: 0.9634 - val_loss: 0.8245 - val_accuracy: 0.8655\n",
            "Epoch 748/750\n",
            "414/414 [==============================] - 2s 6ms/step - loss: 0.0918 - accuracy: 0.9587 - val_loss: 0.7309 - val_accuracy: 0.8849\n",
            "Epoch 749/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.1036 - accuracy: 0.9557 - val_loss: 0.6941 - val_accuracy: 0.8680\n",
            "Epoch 750/750\n",
            "414/414 [==============================] - 2s 4ms/step - loss: 0.0967 - accuracy: 0.9593 - val_loss: 0.7881 - val_accuracy: 0.8776\n",
            "39/39 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.82      0.87       617\n",
            "           1       0.84      0.93      0.88       625\n",
            "\n",
            "    accuracy                           0.88      1242\n",
            "   macro avg       0.88      0.88      0.88      1242\n",
            "weighted avg       0.88      0.88      0.88      1242\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8776167471819646"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def predict_label(AT, DPX, ASA, Average_Bfactor, CX, RMSF, kdHydrophobicity):\n",
        "    # Create a DataFrame with user input\n",
        "    user_input = pd.DataFrame({\n",
        "        'AT': [AT],\n",
        "        'DPX': [DPX],\n",
        "        'ASA': [ASA],\n",
        "        'Average Bfactor': [Average_Bfactor],\n",
        "        'CX': [CX],\n",
        "        'RMSF': [RMSF],\n",
        "        'kdHydrophobicity': [kdHydrophobicity]\n",
        "    })\n",
        "\n",
        "    user_input_array = user_input.values\n",
        "    user_input_normalized = scaler.transform(user_input_array)\n",
        "    user_input_pca = pca.transform(user_input_normalized)\n",
        "\n",
        "    # Use the trained model for prediction\n",
        "    prediction1 = ann.predict(user_input_pca)\n",
        "    prediction_dnn = [1 if p > 0.5 else 0 for p in prediction1]\n",
        "\n",
        "    # Output the prediction\n",
        "    if prediction_dnn[0] == 1:\n",
        "        print(\"The model predicts a positive label (1).\")\n",
        "    else:\n",
        "        print(\"The model predicts a negative label (0).\")\n",
        "\n",
        "# get new values by user\n",
        "AT = float(input(\"Enter AT value: \"))\n",
        "DPX = float(input(\"Enter DPX value: \"))\n",
        "ASA = float(input(\"Enter ASA value: \"))\n",
        "Average_Bfactor = float(input(\"Enter Average Bfactor value: \"))\n",
        "CX = float(input(\"Enter CX value: \"))\n",
        "RMSF = float(input(\"Enter RMSF value: \"))\n",
        "kdHydrophobicity = float(input(\"Enter kdHydrophobicity value: \"))\n",
        "\n",
        "# Predict label based on user input\n",
        "predict_label(AT, DPX, ASA, Average_Bfactor, CX, RMSF, kdHydrophobicity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqSDW2LRNN6L",
        "outputId": "985e4fd7-df09-4fd4-817c-abac86884f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter AT value: 7\n",
            "Enter DPX value: 9\n",
            "Enter ASA value: 29.4\n",
            "Enter Average Bfactor value: 0.438\n",
            "Enter CX value: 2.51\n",
            "Enter RMSF value: 0.618\n",
            "Enter kdHydrophobicity value: -4.2\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "The model predicts a negative label (0).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3-2 CNN**"
      ],
      "metadata": {
        "id": "OrB24-zz9_-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_smote.shape)\n",
        "print(X_test_norm.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy65AjhzU0s9",
        "outputId": "0288cdec-67d8-4232-f926-202a5c9f30f3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4966, 7)\n",
            "(649, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "\n",
        "\n",
        "\n",
        "#DATA PREPROCESSING - Reshaping X:\n",
        "#X_test_norm, X_train_smote, y_train_smote\n",
        "\n",
        "X_cnn_train, X_cnn_test, y_cnn_train, y_cnn_test = train_test_split(x,y,test_size=0.2, random_state=16, stratify=y)\n",
        "\n",
        "#apply smote\n",
        "smote_cnn = SMOTE(sampling_strategy='minority', random_state=16)\n",
        "X_cnn_train_smote, y_cnn_train_smote = smote_cnn.fit_resample(X_cnn_train, y_cnn_train)\n",
        "\n",
        "#normalization\n",
        "X_cnn_train_smote_norm = sc.fit_transform(X_cnn_train_smote)\n",
        "X_cnn_test_norm = sc.transform(X_cnn_test)\n",
        "\n",
        "\n",
        "X_cnn_train_reshape = X_cnn_train_smote_norm.reshape(X_cnn_train_smote_norm.shape[0], 7, 1)\n",
        "X_cnn_test_reshape = X_cnn_test_norm.reshape(X_cnn_test_norm.shape[0], 7, 1)\n",
        "\n",
        "\n",
        "SEQ_LENGTH = 7\n",
        "NUM_FEATURES = 1\n",
        "\n",
        "CNN_SMOTE = Sequential([\n",
        "    Conv1D(64, kernel_size=2, activation='relu', input_shape=(SEQ_LENGTH, NUM_FEATURES)),\n",
        "    MaxPooling1D(pool_size=1),\n",
        "    Conv1D(128, kernel_size=2, activation='relu'),\n",
        "    MaxPooling1D(pool_size=1),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "CNN_SMOTE.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "CNN_SMOTE.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "CNN_SMOTE.fit(X_cnn_train_reshape,y_cnn_train_smote, batch_size=6,epochs=100, validation_data=(X_cnn_test_reshape, y_cnn_test))\n",
        "\n",
        "prediction0 = CNN_SMOTE.predict(X_cnn_test_reshape)\n",
        "prediction_cnn = [1 if p > 0.5 else 0 for p in prediction0]\n",
        "\n",
        "print(classification_report(y_cnn_test, prediction_cnn))\n",
        "accuracy_score(y_cnn_test, prediction_cnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKZWT1IH9--8",
        "outputId": "60f6dc92-220e-4b05-ef2f-5bcd12c9f63f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_26 (Conv1D)          (None, 6, 64)             192       \n",
            "                                                                 \n",
            " max_pooling1d_26 (MaxPooli  (None, 6, 64)             0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_27 (Conv1D)          (None, 5, 128)            16512     \n",
            "                                                                 \n",
            " max_pooling1d_27 (MaxPooli  (None, 5, 128)            0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 640)               0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 128)               82048     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 98881 (386.25 KB)\n",
            "Trainable params: 98881 (386.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "828/828 [==============================] - 12s 11ms/step - loss: 0.5667 - accuracy: 0.6855 - val_loss: 0.5261 - val_accuracy: 0.5485\n",
            "Epoch 2/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.5283 - accuracy: 0.7122 - val_loss: 0.5346 - val_accuracy: 0.5532\n",
            "Epoch 3/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.5118 - accuracy: 0.7225 - val_loss: 0.6759 - val_accuracy: 0.4992\n",
            "Epoch 4/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.4860 - accuracy: 0.7455 - val_loss: 0.6676 - val_accuracy: 0.5393\n",
            "Epoch 5/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.4649 - accuracy: 0.7678 - val_loss: 0.5444 - val_accuracy: 0.6425\n",
            "Epoch 6/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.4455 - accuracy: 0.7781 - val_loss: 0.5184 - val_accuracy: 0.6672\n",
            "Epoch 7/100\n",
            "828/828 [==============================] - 4s 4ms/step - loss: 0.4217 - accuracy: 0.7956 - val_loss: 0.6707 - val_accuracy: 0.6117\n",
            "Epoch 8/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.4133 - accuracy: 0.7994 - val_loss: 0.5253 - val_accuracy: 0.7257\n",
            "Epoch 9/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.3979 - accuracy: 0.8093 - val_loss: 0.5097 - val_accuracy: 0.7134\n",
            "Epoch 10/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.3805 - accuracy: 0.8337 - val_loss: 0.5685 - val_accuracy: 0.7026\n",
            "Epoch 11/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.3597 - accuracy: 0.8395 - val_loss: 0.4547 - val_accuracy: 0.7843\n",
            "Epoch 12/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.3481 - accuracy: 0.8429 - val_loss: 0.6046 - val_accuracy: 0.6918\n",
            "Epoch 13/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.3313 - accuracy: 0.8611 - val_loss: 0.5221 - val_accuracy: 0.7550\n",
            "Epoch 14/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.3255 - accuracy: 0.8546 - val_loss: 0.4748 - val_accuracy: 0.7920\n",
            "Epoch 15/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.3079 - accuracy: 0.8693 - val_loss: 0.4872 - val_accuracy: 0.8028\n",
            "Epoch 16/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.2919 - accuracy: 0.8752 - val_loss: 0.5153 - val_accuracy: 0.8105\n",
            "Epoch 17/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.2868 - accuracy: 0.8806 - val_loss: 0.5532 - val_accuracy: 0.7858\n",
            "Epoch 18/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.2677 - accuracy: 0.8925 - val_loss: 0.5499 - val_accuracy: 0.8089\n",
            "Epoch 19/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.2648 - accuracy: 0.8927 - val_loss: 0.5435 - val_accuracy: 0.8274\n",
            "Epoch 20/100\n",
            "828/828 [==============================] - 4s 4ms/step - loss: 0.2545 - accuracy: 0.8977 - val_loss: 0.5801 - val_accuracy: 0.7935\n",
            "Epoch 21/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.2394 - accuracy: 0.9058 - val_loss: 0.6022 - val_accuracy: 0.8028\n",
            "Epoch 22/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.2363 - accuracy: 0.9052 - val_loss: 0.6398 - val_accuracy: 0.7951\n",
            "Epoch 23/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.2274 - accuracy: 0.9078 - val_loss: 0.6282 - val_accuracy: 0.8151\n",
            "Epoch 24/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.2241 - accuracy: 0.9114 - val_loss: 0.6522 - val_accuracy: 0.8398\n",
            "Epoch 25/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.2146 - accuracy: 0.9148 - val_loss: 0.5936 - val_accuracy: 0.8613\n",
            "Epoch 26/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.2043 - accuracy: 0.9190 - val_loss: 0.8473 - val_accuracy: 0.7504\n",
            "Epoch 27/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.2201 - accuracy: 0.9152 - val_loss: 0.6499 - val_accuracy: 0.8475\n",
            "Epoch 28/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.2012 - accuracy: 0.9213 - val_loss: 0.6911 - val_accuracy: 0.8444\n",
            "Epoch 29/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1986 - accuracy: 0.9225 - val_loss: 0.7054 - val_accuracy: 0.8382\n",
            "Epoch 30/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1802 - accuracy: 0.9285 - val_loss: 0.7157 - val_accuracy: 0.8690\n",
            "Epoch 31/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.1870 - accuracy: 0.9297 - val_loss: 0.7480 - val_accuracy: 0.8336\n",
            "Epoch 32/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.1871 - accuracy: 0.9299 - val_loss: 0.6967 - val_accuracy: 0.8582\n",
            "Epoch 33/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1769 - accuracy: 0.9327 - val_loss: 0.7899 - val_accuracy: 0.8213\n",
            "Epoch 34/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1663 - accuracy: 0.9374 - val_loss: 0.7539 - val_accuracy: 0.8798\n",
            "Epoch 35/100\n",
            "828/828 [==============================] - 4s 4ms/step - loss: 0.1695 - accuracy: 0.9342 - val_loss: 0.7982 - val_accuracy: 0.8320\n",
            "Epoch 36/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.1688 - accuracy: 0.9372 - val_loss: 0.8187 - val_accuracy: 0.8320\n",
            "Epoch 37/100\n",
            "828/828 [==============================] - 4s 4ms/step - loss: 0.1690 - accuracy: 0.9342 - val_loss: 0.8203 - val_accuracy: 0.8536\n",
            "Epoch 38/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1625 - accuracy: 0.9396 - val_loss: 0.9357 - val_accuracy: 0.8074\n",
            "Epoch 39/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.1643 - accuracy: 0.9356 - val_loss: 0.8357 - val_accuracy: 0.8706\n",
            "Epoch 40/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.1585 - accuracy: 0.9394 - val_loss: 0.8595 - val_accuracy: 0.8567\n",
            "Epoch 41/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1596 - accuracy: 0.9424 - val_loss: 0.8901 - val_accuracy: 0.8490\n",
            "Epoch 42/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1520 - accuracy: 0.9430 - val_loss: 0.8611 - val_accuracy: 0.8844\n",
            "Epoch 43/100\n",
            "828/828 [==============================] - 5s 6ms/step - loss: 0.1502 - accuracy: 0.9454 - val_loss: 0.8647 - val_accuracy: 0.8798\n",
            "Epoch 44/100\n",
            "828/828 [==============================] - 4s 4ms/step - loss: 0.1454 - accuracy: 0.9452 - val_loss: 0.9325 - val_accuracy: 0.8382\n",
            "Epoch 45/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1412 - accuracy: 0.9478 - val_loss: 0.9210 - val_accuracy: 0.8598\n",
            "Epoch 46/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1414 - accuracy: 0.9462 - val_loss: 0.9664 - val_accuracy: 0.8536\n",
            "Epoch 47/100\n",
            "828/828 [==============================] - 5s 6ms/step - loss: 0.1429 - accuracy: 0.9458 - val_loss: 0.9347 - val_accuracy: 0.8798\n",
            "Epoch 48/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1392 - accuracy: 0.9482 - val_loss: 0.9772 - val_accuracy: 0.8721\n",
            "Epoch 49/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1398 - accuracy: 0.9509 - val_loss: 0.9865 - val_accuracy: 0.8752\n",
            "Epoch 50/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1313 - accuracy: 0.9537 - val_loss: 0.9154 - val_accuracy: 0.8690\n",
            "Epoch 51/100\n",
            "828/828 [==============================] - 5s 6ms/step - loss: 0.1435 - accuracy: 0.9470 - val_loss: 0.9891 - val_accuracy: 0.8644\n",
            "Epoch 52/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1331 - accuracy: 0.9501 - val_loss: 0.9889 - val_accuracy: 0.8921\n",
            "Epoch 53/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1326 - accuracy: 0.9525 - val_loss: 0.9959 - val_accuracy: 0.8829\n",
            "Epoch 54/100\n",
            "828/828 [==============================] - 4s 4ms/step - loss: 0.1277 - accuracy: 0.9525 - val_loss: 1.0022 - val_accuracy: 0.8983\n",
            "Epoch 55/100\n",
            "828/828 [==============================] - 5s 6ms/step - loss: 0.1227 - accuracy: 0.9537 - val_loss: 1.0254 - val_accuracy: 0.8875\n",
            "Epoch 56/100\n",
            "828/828 [==============================] - 4s 4ms/step - loss: 0.1261 - accuracy: 0.9567 - val_loss: 1.0609 - val_accuracy: 0.8952\n",
            "Epoch 57/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1264 - accuracy: 0.9505 - val_loss: 1.1081 - val_accuracy: 0.8814\n",
            "Epoch 58/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.1261 - accuracy: 0.9565 - val_loss: 1.0535 - val_accuracy: 0.8921\n",
            "Epoch 59/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.1237 - accuracy: 0.9541 - val_loss: 1.0869 - val_accuracy: 0.8844\n",
            "Epoch 60/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1213 - accuracy: 0.9549 - val_loss: 1.1078 - val_accuracy: 0.8521\n",
            "Epoch 61/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1130 - accuracy: 0.9597 - val_loss: 1.0898 - val_accuracy: 0.8921\n",
            "Epoch 62/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.1256 - accuracy: 0.9529 - val_loss: 1.1890 - val_accuracy: 0.8998\n",
            "Epoch 63/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.1129 - accuracy: 0.9583 - val_loss: 1.1546 - val_accuracy: 0.8737\n",
            "Epoch 64/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1148 - accuracy: 0.9585 - val_loss: 1.1169 - val_accuracy: 0.8798\n",
            "Epoch 65/100\n",
            "828/828 [==============================] - 4s 4ms/step - loss: 0.1224 - accuracy: 0.9543 - val_loss: 1.1524 - val_accuracy: 0.8906\n",
            "Epoch 66/100\n",
            "828/828 [==============================] - 5s 6ms/step - loss: 0.1203 - accuracy: 0.9551 - val_loss: 1.1281 - val_accuracy: 0.8783\n",
            "Epoch 67/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1188 - accuracy: 0.9581 - val_loss: 1.1452 - val_accuracy: 0.8675\n",
            "Epoch 68/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1246 - accuracy: 0.9553 - val_loss: 1.1694 - val_accuracy: 0.9014\n",
            "Epoch 69/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1068 - accuracy: 0.9629 - val_loss: 1.2046 - val_accuracy: 0.8998\n",
            "Epoch 70/100\n",
            "828/828 [==============================] - 5s 6ms/step - loss: 0.1130 - accuracy: 0.9615 - val_loss: 1.2045 - val_accuracy: 0.9029\n",
            "Epoch 71/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1084 - accuracy: 0.9625 - val_loss: 1.1754 - val_accuracy: 0.8860\n",
            "Epoch 72/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1055 - accuracy: 0.9629 - val_loss: 1.2005 - val_accuracy: 0.8798\n",
            "Epoch 73/100\n",
            "828/828 [==============================] - 4s 4ms/step - loss: 0.1092 - accuracy: 0.9587 - val_loss: 1.2037 - val_accuracy: 0.8952\n",
            "Epoch 74/100\n",
            "828/828 [==============================] - 5s 6ms/step - loss: 0.1020 - accuracy: 0.9638 - val_loss: 1.2283 - val_accuracy: 0.8921\n",
            "Epoch 75/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1116 - accuracy: 0.9597 - val_loss: 1.2520 - val_accuracy: 0.9029\n",
            "Epoch 76/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1061 - accuracy: 0.9617 - val_loss: 1.3048 - val_accuracy: 0.8613\n",
            "Epoch 77/100\n",
            "828/828 [==============================] - 4s 4ms/step - loss: 0.1063 - accuracy: 0.9613 - val_loss: 1.2796 - val_accuracy: 0.8814\n",
            "Epoch 78/100\n",
            "828/828 [==============================] - 5s 6ms/step - loss: 0.1012 - accuracy: 0.9640 - val_loss: 1.3064 - val_accuracy: 0.8690\n",
            "Epoch 79/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1058 - accuracy: 0.9617 - val_loss: 1.3082 - val_accuracy: 0.8952\n",
            "Epoch 80/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1165 - accuracy: 0.9595 - val_loss: 1.2648 - val_accuracy: 0.8921\n",
            "Epoch 81/100\n",
            "828/828 [==============================] - 4s 4ms/step - loss: 0.1006 - accuracy: 0.9640 - val_loss: 1.2388 - val_accuracy: 0.8844\n",
            "Epoch 82/100\n",
            "828/828 [==============================] - 5s 5ms/step - loss: 0.1025 - accuracy: 0.9629 - val_loss: 1.3243 - val_accuracy: 0.8937\n",
            "Epoch 83/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1017 - accuracy: 0.9646 - val_loss: 1.3161 - val_accuracy: 0.8968\n",
            "Epoch 84/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1098 - accuracy: 0.9631 - val_loss: 1.3050 - val_accuracy: 0.8998\n",
            "Epoch 85/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.0950 - accuracy: 0.9660 - val_loss: 1.3666 - val_accuracy: 0.8937\n",
            "Epoch 86/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.1056 - accuracy: 0.9652 - val_loss: 1.3568 - val_accuracy: 0.9091\n",
            "Epoch 87/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.0970 - accuracy: 0.9642 - val_loss: 1.3819 - val_accuracy: 0.8983\n",
            "Epoch 88/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.0984 - accuracy: 0.9670 - val_loss: 1.3312 - val_accuracy: 0.8860\n",
            "Epoch 89/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.1001 - accuracy: 0.9642 - val_loss: 1.3727 - val_accuracy: 0.8829\n",
            "Epoch 90/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.0935 - accuracy: 0.9656 - val_loss: 1.4545 - val_accuracy: 0.8998\n",
            "Epoch 91/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.1002 - accuracy: 0.9646 - val_loss: 1.4245 - val_accuracy: 0.8814\n",
            "Epoch 92/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.0929 - accuracy: 0.9670 - val_loss: 1.4132 - val_accuracy: 0.8891\n",
            "Epoch 93/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.0978 - accuracy: 0.9644 - val_loss: 1.5375 - val_accuracy: 0.8998\n",
            "Epoch 94/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.0965 - accuracy: 0.9652 - val_loss: 1.4842 - val_accuracy: 0.9060\n",
            "Epoch 95/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.0861 - accuracy: 0.9682 - val_loss: 1.4131 - val_accuracy: 0.8921\n",
            "Epoch 96/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.0940 - accuracy: 0.9644 - val_loss: 1.3726 - val_accuracy: 0.8968\n",
            "Epoch 97/100\n",
            "828/828 [==============================] - 4s 4ms/step - loss: 0.0945 - accuracy: 0.9668 - val_loss: 1.4666 - val_accuracy: 0.8937\n",
            "Epoch 98/100\n",
            "828/828 [==============================] - 4s 5ms/step - loss: 0.0900 - accuracy: 0.9682 - val_loss: 1.4645 - val_accuracy: 0.9137\n",
            "Epoch 99/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.0860 - accuracy: 0.9672 - val_loss: 1.4220 - val_accuracy: 0.8952\n",
            "Epoch 100/100\n",
            "828/828 [==============================] - 3s 4ms/step - loss: 0.0909 - accuracy: 0.9670 - val_loss: 1.4280 - val_accuracy: 0.8860\n",
            "21/21 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94       622\n",
            "           1       0.02      0.04      0.03        27\n",
            "\n",
            "    accuracy                           0.89       649\n",
            "   macro avg       0.49      0.48      0.48       649\n",
            "weighted avg       0.92      0.89      0.90       649\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8859784283513097"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3-3 SOMs**"
      ],
      "metadata": {
        "id": "TSewFlWUx1uF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install MiniSom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K46YF3Ou--qE",
        "outputId": "7d9a778e-8fa8-40b6-d172-67e57fd11f67"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting MiniSom\n",
            "  Downloading MiniSom-2.3.1.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: MiniSom\n",
            "  Building wheel for MiniSom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for MiniSom: filename=MiniSom-2.3.1-py3-none-any.whl size=10589 sha256=28de5b13dc4aefd9912fe798032b818c4646506697269ee70a8087af5ae86648\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/92/d2/33bbda5f86fd8830510b16aa98c8dd420129b5cb24248fd6db\n",
            "Successfully built MiniSom\n",
            "Installing collected packages: MiniSom\n",
            "Successfully installed MiniSom-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#apply smote\n",
        "smote_som = SMOTE(sampling_strategy='minority', random_state=16)\n",
        "X_som_smote, y_som_smote = smote_som.fit_resample(x, y)\n",
        "\n",
        "#normalization\n",
        "X_som_norm = sc.fit_transform(X_som_smote)"
      ],
      "metadata": {
        "id": "geY4OJLg2A4m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from minisom import MiniSom\n",
        "\n",
        "som = MiniSom(x=7,y=7, input_len=7, sigma=1, learning_rate= 0.5)\n",
        "som.random_weights_init(X_som_norm)\n",
        "som.train_random(data=X_som_norm, num_iteration=100 )"
      ],
      "metadata": {
        "id": "B3G01GUwEKur"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import colors\n",
        "from pylab import bone, pcolor, colorbar,plot,show\n",
        "\n",
        "bone()\n",
        "pcolor(som.distance_map().T)\n",
        "colorbar()\n",
        "markers=['o','s']\n",
        "colors=['r','g']\n",
        "\n",
        "for i in range(len(X_som_norm)):\n",
        "  #w=som.winner(X_som_norm)\n",
        "  w = som.winner(X_som_norm[i].reshape(1, -1))\n",
        "  plot(w[0]+0.5,\n",
        "       w[1]+0.5,\n",
        "       marker= markers[y_som_smote[i]],\n",
        "       markeredgecolor=colors[y_som_smote[i]],\n",
        "       markerfacecolor='None',\n",
        "       markersize=10,\n",
        "       markeredgewidth=2)\n",
        "show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "X3Hie-RXH4z4",
        "outputId": "e123bbea-50b0-4215-bc8f-53b4401b6019"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "Mj9O_oLXwA0U"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = som.win_map(X_som_norm)\n",
        "predicted_label = np.concatenate([np.array(mapping[(2, 4)])])\n",
        "predicted_label= sc.inverse_transform(predicted_label)\n",
        "\n",
        "print(predicted_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojYwN974utUw",
        "outputId": "9ead9b96-41b4-4096-de97-9836df722cc6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 11.           2.57       155.600006   ...  15.290001     0.993\n",
            "   -4.5       ]\n",
            " [ 10.           1.23       160.699997   ...  21.269999     1.32\n",
            "   -3.2       ]\n",
            " [ 11.           1.22       230.         ...  46.93         2.417\n",
            "   -4.5       ]\n",
            " ...\n",
            " [ 10.           3.45755113 152.12755641 ...  17.00799233   0.75548532\n",
            "   -4.47947784]\n",
            " [  9.           0.83080104 168.95699694 ...  15.61600218   1.1408793\n",
            "   -3.9       ]\n",
            " [  9.           0.45072054 166.78073231 ...  15.06427212   1.39712712\n",
            "   -3.9       ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hybrid SOMs with ANN**\n",
        "\n"
      ],
      "metadata": {
        "id": "kkVTsR3Z3RLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_hybrid= final_df\n",
        "df_hybrid.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "T8NQ-Wb0ba2P",
        "outputId": "36758248-a904-49e9-8b9d-7b291fdc2cc2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 Residue Name  AT   DPX         ASA  Average Bfactor         CX  \\\n",
              "0           0          VAL   7  0.00   93.199997           27.312   6.890000   \n",
              "1           1          SER   6  0.00   45.600002           31.505   5.820000   \n",
              "2           2          ALA   5  2.69    4.800000           28.328   3.250000   \n",
              "3           3          TYR  12  1.47  118.199997           31.080  14.290001   \n",
              "4           4          LEU   8  8.08   33.299999           25.937   2.710000   \n",
              "\n",
              "    RMSF  kdHydrophobicity  label  \n",
              "0  0.819               4.2      0  \n",
              "1  0.525              -0.8      0  \n",
              "2  0.763               1.8      0  \n",
              "3  0.408              -1.3      0  \n",
              "4  0.426               3.8      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c98522a-1a93-4d5f-8faa-5f97cd7c5bf2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Residue Name</th>\n",
              "      <th>AT</th>\n",
              "      <th>DPX</th>\n",
              "      <th>ASA</th>\n",
              "      <th>Average Bfactor</th>\n",
              "      <th>CX</th>\n",
              "      <th>RMSF</th>\n",
              "      <th>kdHydrophobicity</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>VAL</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>93.199997</td>\n",
              "      <td>27.312</td>\n",
              "      <td>6.890000</td>\n",
              "      <td>0.819</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>SER</td>\n",
              "      <td>6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>45.600002</td>\n",
              "      <td>31.505</td>\n",
              "      <td>5.820000</td>\n",
              "      <td>0.525</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ALA</td>\n",
              "      <td>5</td>\n",
              "      <td>2.69</td>\n",
              "      <td>4.800000</td>\n",
              "      <td>28.328</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0.763</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>TYR</td>\n",
              "      <td>12</td>\n",
              "      <td>1.47</td>\n",
              "      <td>118.199997</td>\n",
              "      <td>31.080</td>\n",
              "      <td>14.290001</td>\n",
              "      <td>0.408</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>LEU</td>\n",
              "      <td>8</td>\n",
              "      <td>8.08</td>\n",
              "      <td>33.299999</td>\n",
              "      <td>25.937</td>\n",
              "      <td>2.710000</td>\n",
              "      <td>0.426</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c98522a-1a93-4d5f-8faa-5f97cd7c5bf2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9c98522a-1a93-4d5f-8faa-5f97cd7c5bf2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9c98522a-1a93-4d5f-8faa-5f97cd7c5bf2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fce4f438-805e-4f97-a73f-365ccfd6a203\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fce4f438-805e-4f97-a73f-365ccfd6a203')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fce4f438-805e-4f97-a73f-365ccfd6a203 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_hybrid= final_df\n",
        "#df_hybrid.drop('Residue Name', axis=1, inplace=True)\n",
        "df_hybrid= df_hybrid.rename(columns={'Unnamed: 0':'id'})\n",
        "df_hybrid.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2ijXKIHsZ8ye",
        "outputId": "54889355-412f-4dbf-87a4-333d8435c424"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  AT   DPX         ASA  Average Bfactor         CX   RMSF  \\\n",
              "0   0   7  0.00   93.199997           27.312   6.890000  0.819   \n",
              "1   1   6  0.00   45.600002           31.505   5.820000  0.525   \n",
              "2   2   5  2.69    4.800000           28.328   3.250000  0.763   \n",
              "3   3  12  1.47  118.199997           31.080  14.290001  0.408   \n",
              "4   4   8  8.08   33.299999           25.937   2.710000  0.426   \n",
              "\n",
              "   kdHydrophobicity  label  \n",
              "0               4.2      0  \n",
              "1              -0.8      0  \n",
              "2               1.8      0  \n",
              "3              -1.3      0  \n",
              "4               3.8      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0bf4c079-e75d-47df-9eae-5399225b6504\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>AT</th>\n",
              "      <th>DPX</th>\n",
              "      <th>ASA</th>\n",
              "      <th>Average Bfactor</th>\n",
              "      <th>CX</th>\n",
              "      <th>RMSF</th>\n",
              "      <th>kdHydrophobicity</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>93.199997</td>\n",
              "      <td>27.312</td>\n",
              "      <td>6.890000</td>\n",
              "      <td>0.819</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>45.600002</td>\n",
              "      <td>31.505</td>\n",
              "      <td>5.820000</td>\n",
              "      <td>0.525</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2.69</td>\n",
              "      <td>4.800000</td>\n",
              "      <td>28.328</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0.763</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>1.47</td>\n",
              "      <td>118.199997</td>\n",
              "      <td>31.080</td>\n",
              "      <td>14.290001</td>\n",
              "      <td>0.408</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>8.08</td>\n",
              "      <td>33.299999</td>\n",
              "      <td>25.937</td>\n",
              "      <td>2.710000</td>\n",
              "      <td>0.426</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bf4c079-e75d-47df-9eae-5399225b6504')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0bf4c079-e75d-47df-9eae-5399225b6504 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0bf4c079-e75d-47df-9eae-5399225b6504');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6d183b8d-0dbe-486a-9a37-133aba0bdb38\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d183b8d-0dbe-486a-9a37-133aba0bdb38')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6d183b8d-0dbe-486a-9a37-133aba0bdb38 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_hybrid= df_hybrid.iloc[: ,:8]\n",
        "y_hybrid= df_hybrid.iloc[:, -1]"
      ],
      "metadata": {
        "id": "WO8hBVCmdS92"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_hybrid_norm = sc.fit_transform(x_hybrid)\n"
      ],
      "metadata": {
        "id": "U5qcq0LHdtfP"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_hybrid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHfi-qqinrtz",
        "outputId": "0ff1f64a-54a3-47fd-f101-994b0c7e221e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        id  AT    DPX         ASA  Average Bfactor         CX   RMSF  \\\n",
            "0        0   7   0.00   93.199997           27.312   6.890000  0.819   \n",
            "1        1   6   0.00   45.600002           31.505   5.820000  0.525   \n",
            "2        2   5   2.69    4.800000           28.328   3.250000  0.763   \n",
            "3        3  12   1.47  118.199997           31.080  14.290001  0.408   \n",
            "4        4   8   8.08   33.299999           25.937   2.710000  0.426   \n",
            "...    ...  ..    ...         ...              ...        ...    ...   \n",
            "3236  3236   9   1.23  125.699997            0.529   7.790000  0.999   \n",
            "3237  3237   8  10.45   19.500000            0.421   2.100000  0.411   \n",
            "3238  3238   9   2.57  129.699997            0.409  12.480000  0.745   \n",
            "3239  3239   7   4.88   59.299999            0.500   7.470000  0.538   \n",
            "3240  3240   8   3.49   36.700001            0.471   2.420000  0.446   \n",
            "\n",
            "      kdHydrophobicity  \n",
            "0                  4.2  \n",
            "1                 -0.8  \n",
            "2                  1.8  \n",
            "3                 -1.3  \n",
            "4                  3.8  \n",
            "...                ...  \n",
            "3236              -3.5  \n",
            "3237               3.8  \n",
            "3238              -3.9  \n",
            "3239              -1.6  \n",
            "3240               4.2  \n",
            "\n",
            "[3241 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_hybrid_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQCXzm3knmKt",
        "outputId": "8e6b3e7f-c450-4ae0-9f87-4163d0a9b8e5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00000000e+00 2.00000000e-01 0.00000000e+00 ... 1.18283262e-01\n",
            "  1.24158923e-01 9.66666667e-01]\n",
            " [3.08641975e-04 1.33333333e-01 0.00000000e+00 ... 9.99141631e-02\n",
            "  7.70586351e-02 4.11111111e-01]\n",
            " [6.17283951e-04 6.66666667e-02 3.67235495e-02 ... 5.57939914e-02\n",
            "  1.15187440e-01 7.00000000e-01]\n",
            " ...\n",
            " [9.99382716e-01 3.33333333e-01 3.50853242e-02 ... 2.14248927e-01\n",
            "  1.12303749e-01 6.66666667e-02]\n",
            " [9.99691358e-01 2.00000000e-01 6.66211604e-02 ... 1.28240343e-01\n",
            "  7.91413009e-02 3.22222222e-01]\n",
            " [1.00000000e+00 2.66666667e-01 4.76450512e-02 ... 4.15450644e-02\n",
            "  6.44024351e-02 9.66666667e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from minisom import MiniSom\n",
        "\n",
        "som_hybrid = MiniSom(x=8,y=8, input_len=8, sigma=1, learning_rate= 0.5)\n",
        "som_hybrid.random_weights_init(x_hybrid_norm)\n",
        "som_hybrid.train_random(data=x_hybrid_norm, num_iteration=100 )"
      ],
      "metadata": {
        "id": "nLGQIZRFeETn"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import colors\n",
        "from pylab import bone, pcolor, colorbar,plot,show\n",
        "\n",
        "bone()\n",
        "pcolor(som.distance_map().T)\n",
        "colorbar()\n",
        "markers=['o','s']\n",
        "colors=['r','g']\n",
        "\n",
        "for i in range(len(x_hybrid_norm)):\n",
        "    w = som_hybrid.winner(x_hybrid_norm[i].reshape(1, -1))\n",
        "    plot(w[0]+0.5,\n",
        "       w[1]+0.5,\n",
        "       marker= markers[y_hybrid[i]],\n",
        "       markeredgecolor=colors[y_hybrid[i]],\n",
        "       markerfacecolor='None',\n",
        "       markersize=10,\n",
        "       markeredgewidth=2)\n",
        "show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "RxHBDufVeaes",
        "outputId": "2166d1d6-f614-4843-ed7c-cf19e22181a9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = som_hybrid.win_map(x_hybrid_norm)\n",
        "predicted_label = np.concatenate([np.array(mapping[(2, 4)])])\n",
        "predicted_label= sc.inverse_transform(predicted_label)\n",
        "\n",
        "print(predicted_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1eO9KpOgGp_",
        "outputId": "0faa5d22-fb60-476d-a426-25be572d059c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.4800000e+02 5.0000000e+00 1.4500000e+00 6.2399998e+01 1.5609000e+01\n",
            "  5.9400000e+00 8.9300000e-01 1.8000000e+00]\n",
            " [2.9900000e+02 8.0000000e+00 4.1400000e+00 6.9000000e+01 2.3862000e+01\n",
            "  6.4900000e+00 5.6200000e-01 1.9000000e+00]\n",
            " [3.1000000e+02 5.0000000e+00 4.9300000e+00 2.7900002e+01 2.6480000e+01\n",
            "  2.6900000e+00 1.0400000e-01 1.8000000e+00]\n",
            " [3.1100000e+02 5.0000000e+00 2.7200000e+00 4.8000000e+01 2.9010000e+01\n",
            "  2.3500000e+00 9.6000000e-02 1.8000000e+00]\n",
            " [3.3700000e+02 8.0000000e+00 1.1360001e+01 3.7799999e+01 2.7716000e+01\n",
            "  3.3700000e+00 4.2200000e-01 1.9000000e+00]\n",
            " [3.9700000e+02 5.0000000e+00 1.4600000e+00 2.5900000e+01 3.3267000e+01\n",
            "  2.4500000e+00 1.0300000e-01 1.8000000e+00]\n",
            " [5.3900000e+02 5.0000000e+00 5.0300000e+00 2.5500000e+01 2.9230000e+01\n",
            "  6.0200000e+00 4.5300000e-01 1.8000000e+00]\n",
            " [5.4800000e+02 5.0000000e+00 2.6900000e+00 2.4400000e+01 2.1957000e+01\n",
            "  4.9000000e-01 2.1600000e-01 1.8000000e+00]\n",
            " [6.9300000e+02 5.0000000e+00 1.4600000e+00 1.9299999e+01 2.6682000e+01\n",
            "  1.7000000e+00 4.9300000e-01 1.8000000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the matrix of features:\n",
        "samples = df_hybrid.iloc[: ,1:].values\n",
        "\n",
        "#creating the dependent variable:\n",
        "labeled_true = np.zeros(len(df_hybrid))\n",
        "\n",
        "for i in range(len(df_hybrid)):\n",
        "  if df_hybrid.iloc[i,0] in predicted_label:\n",
        "    labeled_true[i]= 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kHXGyw0hx48b"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train ANN\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "ann_hybrid = tf.keras.models.Sequential()\n",
        "ann_hybrid.add(tf.keras.layers.Dense(units=6,activation = 'relu'))\n",
        "#ann.add(Dropout(rate=0.3))\n",
        "ann_hybrid.add(tf.keras.layers.Dense(units=50,activation = 'relu'))\n",
        "#ann.add(Dropout(rate=0.3))\n",
        "ann_hybrid.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "#ann.add(Dropout(rate=0.3))\n",
        "ann_hybrid.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "ann_hybrid.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "ann_hybrid.fit(samples,labeled_true, batch_size=1,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubKMDHmDseMf",
        "outputId": "bbd1b329-3976-423f-9931-b6c3ba93d515"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3241/3241 [==============================] - 11s 3ms/step - loss: 0.0584 - accuracy: 0.9920\n",
            "Epoch 2/5\n",
            "3241/3241 [==============================] - 6s 2ms/step - loss: 0.0297 - accuracy: 0.9963\n",
            "Epoch 3/5\n",
            "3241/3241 [==============================] - 8s 3ms/step - loss: 0.0253 - accuracy: 0.9963\n",
            "Epoch 4/5\n",
            "3241/3241 [==============================] - 7s 2ms/step - loss: 0.0241 - accuracy: 0.9963\n",
            "Epoch 5/5\n",
            "3241/3241 [==============================] - 7s 2ms/step - loss: 0.0218 - accuracy: 0.9963\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x796edb2eef80>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# prediction the probility of being labeled 1:\n",
        "prediction_ann_hybrid = ann_hybrid.predict(samples)\n",
        "prediction_ann_hybrid = np.concatenate((df_hybrid.iloc[:, 0:1].values ,prediction_ann_hybrid), axis=1)\n",
        "prediction_ann_hybrid= prediction_ann_hybrid[prediction_ann_hybrid[:,1].argsort()]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQJ1HdLBoaUY",
        "outputId": "a00d5012-2655-43bd-8db9-8a97bec8df88"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102/102 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction_ann_hybrid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObItszAnv6vk",
        "outputId": "5a82dc51-589d-4dae-bb51-9077ca46a384"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.12700000e+03 4.27265948e-22]\n",
            " [2.27600000e+03 1.08833344e-16]\n",
            " [2.15400000e+03 5.31120532e-15]\n",
            " ...\n",
            " [1.52400000e+03 9.51760784e-02]\n",
            " [1.55900000e+03 9.61917713e-02]\n",
            " [5.48000000e+02 1.15416601e-01]]\n"
          ]
        }
      ]
    }
  ]
}